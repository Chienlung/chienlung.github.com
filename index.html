<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"chienlungcheung.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="programatrix">
<meta property="og:url" content="https://chienlungcheung.github.io/index.html">
<meta property="og:site_name" content="programatrix">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Chienlung Cheung">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://chienlungcheung.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>programatrix</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-177829579-1"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-177829579-1');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">programatrix</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Be the change you wish to see in the world.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://chienlungcheung.github.io/2021/03/03/mapreduce-design-and-implementation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chienlung Cheung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="programatrix">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/03/mapreduce-design-and-implementation/" class="post-title-link" itemprop="url">MapReduce: 分布式计算系统设计与实现</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-03-03 19:42:52 / Modified: 09:19:19" itemprop="dateCreated datePublished" datetime="2021-03-03T19:42:52+00:00">2021-03-03</time>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2021/03/03/mapreduce-design-and-implementation/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2021/03/03/mapreduce-design-and-implementation/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <!-- toc -->

<ul>
<li><a href="#1-%E7%AE%80%E8%A6%81%E4%BB%8B%E7%BB%8D">1 简要介绍</a></li>
<li><a href="#2-%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B">2 编程模型</a><ul>
<li><a href="#21-%E4%B8%BE%E4%BE%8B">2.1 举例</a></li>
<li><a href="#22-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%B1%BB%E5%9E%8B">2.2 输入输出类型</a></li>
<li><a href="#23-%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E4%B8%BE%E4%BE%8B">2.3 使用场景举例</a></li>
</ul>
</li>
<li><a href="#3-%E5%AE%9E%E7%8E%B0">3 实现</a><ul>
<li><a href="#31-%E6%89%A7%E8%A1%8C%E6%A6%82%E8%A7%88">3.1 执行概览</a></li>
<li><a href="#32-master-%E8%8A%82%E7%82%B9%E7%9A%84%E4%BD%9C%E7%94%A8">3.2 Master 节点的作用</a></li>
<li><a href="#33-%E5%AE%B9%E9%94%99">3.3 容错</a><ul>
<li><a href="#331-worker-%E6%95%85%E9%9A%9C">3.3.1 worker 故障</a></li>
<li><a href="#332-master-%E6%95%85%E9%9A%9C">3.3.2 master 故障</a></li>
<li><a href="#333-%E6%95%85%E9%9A%9C%E5%AD%98%E5%9C%A8%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E8%AF%AD%E4%B9%89%E4%BF%9D%E8%AF%81">3.3.3 故障存在场景下的语义保证</a></li>
</ul>
</li>
<li><a href="#34-%E6%95%B0%E6%8D%AE%E5%B1%80%E9%83%A8%E6%80%A7">3.4 数据局部性</a></li>
<li><a href="#35-%E4%BB%BB%E5%8A%A1%E9%A2%97%E7%B2%92%E5%BA%A6">3.5 任务颗粒度</a></li>
<li><a href="#36-%E5%90%8E%E5%A4%87%E4%BB%BB%E5%8A%A1">3.6 后备任务</a></li>
</ul>
</li>
<li><a href="#4-%E8%B0%83%E4%BC%98">4 调优</a><ul>
<li><a href="#41-%E5%88%86%E5%8C%BA%E5%87%BD%E6%95%B0">4.1 分区函数</a></li>
<li><a href="#42-%E9%A1%BA%E5%BA%8F%E4%BF%9D%E8%AF%81">4.2 顺序保证</a></li>
<li><a href="#43-%E5%90%88%E5%B9%B6%E5%87%BD%E6%95%B0combiner-function">4.3 合并函数(combiner function)</a></li>
<li><a href="#44-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%B1%BB%E5%9E%8B">4.4 输入输出类型</a></li>
<li><a href="#45-%E8%B7%B3%E8%BF%87%E5%9D%8F%E8%AE%B0%E5%BD%95">4.5 跳过坏记录</a></li>
<li><a href="#46-%E7%8A%B6%E6%80%81%E4%BF%A1%E6%81%AF">4.6 状态信息</a></li>
<li><a href="#49-%E5%85%A8%E5%B1%80%E8%AE%A1%E6%95%B0%E5%99%A8">4.9 全局计数器</a></li>
</ul>
</li>
<li><a href="#5-%E6%80%A7%E8%83%BD">5 性能</a></li>
</ul>
<!-- tocstop -->

<p>本文基于内部分享 &lt;”抄”能力养成系列 – MapReduce: 分布式计算系统设计与实现&gt; 整理.</p>
<p>2003 年开始 Google 陆续放出三套系统的设计(GFS/MapReduce/Bigtable), 在互联网届掀起云计算狂潮一直影响至今. MapReduce 作为老二出场, 因为它的实现依赖于之前分享的 GFS 作为存储. 该论文一出, 便直接催生了 Hadoop 另一个重量级同名框架 MapReduce 的诞生. 时光荏苒, 虽然后面又出现了 spark/flink, 但是 MapReduce 在批处理领域的地位至今牢固. 下面就让我们一起看看 MapReduce 的设计, 希望为各位后续系统研发提供灵感. (Salute to Jeff).</p>
<h1><span id="1-简要介绍">1 简要介绍</span></h1><p>这个模型说起来真是简单至极, 非常符合直觉, 就是说给非互联网行业的人, 也能听明白. 该模型跟函数式语言中的 map-reduce 理念基本一样, 不过这个是分布式的.</p>
<p>map 用于处理原始记录, 输出中间 <code>&lt;k, v&gt;</code>; reduce 基于 k 把中间数据合并, 输出 <code>&lt;k, List&lt;v&gt;&gt;</code>.</p>
<ul>
<li>并行化</li>
<li>容错</li>
<li>数据分发</li>
<li>负载均衡</li>
</ul>
<p>最主要的容错机制就是支持重跑任务.</p>
<h1><span id="2-编程模型">2 编程模型</span></h1><p>用户要写的就是 Map 函数和 Reduce 函数. Map 负责将输入加工成中间 kv; MapReduce 库负责将同一个 k 的全部 v 收集好发给 Reduce; Reduce 接收中间数据, 然后基于 k, 合并 v, 一般输出一个或零个值.</p>
<h2><span id="21-举例">2.1 举例</span></h2><p>以单词计数为例, 用户需要干的就是实现自己的 map 函数和 reduce 函数. 剩下的事情由框架负责.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// key: 文档名</span></span><br><span class="line"><span class="comment">// value: 文档内容</span></span><br><span class="line"><span class="built_in">map</span>(String key, String value):</span><br><span class="line">  <span class="comment">// 遍历文档, 每个词输出一个键值对</span></span><br><span class="line">  <span class="keyword">for</span> each word w in value:</span><br><span class="line">    EmitIntermediate(w, <span class="string">&quot;1&quot;</span>);</span><br><span class="line"><span class="comment">// key: 单词</span></span><br><span class="line"><span class="comment">// value: 计数值构成的列表   </span></span><br><span class="line">reduce(String key, Iterator values):</span><br><span class="line">  <span class="comment">// 累加器</span></span><br><span class="line">  <span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// 遍历每个计数值, 将其累加起来</span></span><br><span class="line">  <span class="keyword">for</span> each v in values:</span><br><span class="line">    result += ParseInt(v);</span><br><span class="line">  <span class="comment">// 得到每个单词出现的次数</span></span><br><span class="line">  Emit(AsString(result));</span><br></pre></td></tr></table></figure>
<h2><span id="22-输入输出类型">2.2 输入输出类型</span></h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 输入为两个参数, k1 类型的键, v1 类型的值; </span></span><br><span class="line"><span class="comment">// 返回值是一个键值对, 每个键值对是一个 &lt;k2 类型的键, v2 类型的值&gt;,</span></span><br><span class="line"><span class="comment">// 整体效果上看相当于输出了一个键值对列表.</span></span><br><span class="line"><span class="built_in">map</span>       (k1,v1)         →   <span class="built_in">list</span>(k2,v2)</span><br><span class="line"><span class="comment">// 输入为两个参数, k2 类型的键, 以及其对应的 v2 类型的值的列表;</span></span><br><span class="line"><span class="comment">// 返回值是 v2 类型的值, 效果上看相当于输出了一个列表.</span></span><br><span class="line">reduce    (k2,<span class="built_in">list</span>(v2))   →   <span class="built_in">list</span>(v2)</span><br></pre></td></tr></table></figure>

<h2><span id="23-使用场景举例">2.3 使用场景举例</span></h2><ul>
<li>分布式 grep <ul>
<li>map 函数处理模式匹配, 一旦匹配输出一行;</li>
<li>reduce 函数是一个等价函数(啥也不干), 将中间结果拷贝到输出.</li>
</ul>
</li>
<li>URL 访问计数<ul>
<li>map 函数负责处理每个页面的请求日志, 每处理一行便输出 <code>&lt;URL, 1&gt;</code>.</li>
<li>reduce 函数负责将 URL 一样的值累加, 返回的是 <code>&lt;URL, 累加值&gt;</code></li>
</ul>
</li>
<li>web 站点链接反转<ul>
<li>map 函数针对每个在叫 source 的页面中发现的链接 target, 输出 <code>&lt;target, source&gt;</code>.</li>
<li>reduce 将每个 target 对应的 source 收集为一个列表并输出, 形如 <code>&lt;target, list&lt;source&gt;&gt;</code>.</li>
</ul>
</li>
<li>Term-Vector per Host<ul>
<li>背景: 检索词向量是对一个文档或者文档集合中最重要的单词及其词频的统计, 形式为 <code>&lt;word, frequency&gt;</code> 列表.</li>
<li>map 函数针对每个输入文档, 输出 <code>&lt;hostname, term vector&gt;</code>, 其中 hostname 是从文档对应的 URL 中抽取得到.</li>
<li>reduce 函数负责处理给定 host 的每个文档的检索词向量, 它将这些词向量加在在一起去除低频检索词, 输出 <code>&lt;hostname, term vector&gt;</code> 键值对.</li>
</ul>
</li>
<li>倒排索引<ul>
<li>map 函数解析每个文档, 输出一各 <code>&lt;word, document ID&gt;</code> 序列.</li>
<li>reduce 函数接受给定单词的全部键值对, 将对应的 document IDs 排序, 输出一个 <code>&lt;word, list(document ID)&gt;</code> 键值对.</li>
</ul>
</li>
<li>分布式排序<ul>
<li>map 函数从每个 record 抽取 key, 输出一个 <code>&lt;key, record&gt;</code> 键值对.</li>
<li>reduce 函数原封不动地输出键值对.</li>
<li>该计算场景依赖于后面将要描述的分区设施和排序属性.</li>
</ul>
</li>
</ul>
<h1><span id="3-实现">3 实现</span></h1><p>模型很简单, 具体实现取决于硬件环境. 以 Google 为例(快二十年前的数据了):</p>
<ul>
<li>双核 x86 处理器, 运行 Linux, 2-4GB 内存.</li>
<li>普通商用网络, 100Mb/s.</li>
<li>几百上千台上述机器构成的集群.</li>
<li>数据就保存在计算节点上, 普通的 IDE 磁盘. 不过这些数据由 GFS 管理, 确保高可用.</li>
<li>用户将 job 提交到调度系统. 每个 job 由多个 tasks 构成, 每个 job 被调度器映射到集群内的一组机器.</li>
</ul>
<h2><span id="31-执行概览">3.1 执行概览</span></h2><p>系统自动将输入数据自动切割成 M 份, 然后在对应机器上部署多个 Mapper, 每个 Mapper 负责处理若干份数据. Mapper 处理输入生成中间数据, 通过分区函数(比如 hash(key) mod R)将中间数据的键空间分成 R 份, 并在其之上部署 Reducer. 具体的分区函数和分成几份, 由用户负责指定.</p>
<p><img src="/images/google-mapreduce-20210303/figure-1-execution-overview.png" alt="Figure 1 "></p>
<p>Figure 1 显示了一个 MapReduce 操作的执行概览. 用户程序调用 MapReduce 函数, 然后接下来框架内部陆续发生如下动作:</p>
<ol>
<li>MapReduce 将输入切分成 M 份, 并在一组机器上启动多个用户程序拷贝(fork).</li>
<li>上一步的 fork, 其中有 M 个 map workers, R 个 reduce workers, 还有一个特殊的作为 Master 负责分配任务.</li>
<li>map worker 负责读取和解析输入的 key/value 并传给用户定义的 Map 函数, 后者输出中间状态的 key’/value’, 这些中间数据起初被缓存到内存中.</li>
<li>map worker 缓存的中间数据会被周期性的写到本地磁盘, 同时会被划分成 R 个分区(如 hash(key’) mod R), 注意由于分区函数无法保证原空间和像空间一一映射, 所以每个分区的 key’ 可能不唯一(比如 R 为 7, 则 key’ 为 70 和 700 的落在同一个分区内). <strong>这些中间数据 key’/value’ 的位置会被上报给 Master, 它会负责把这些位置信息转发给 reduce workers, 每个 reduce worker 负责一个分区</strong>. 尤其注意一点, 这一步的中间数据会被写到 map tasks 的本地磁盘, 而不是 GFS.</li>
<li>当 reduce worker 收到上面提到的位置信息的时候, 它发起一个 RPC 读取那个 map workers 磁盘缓存的数据. 当数据都被读取过来之后, reduce worker 根据中间 key’ 对数据进行排序, 于是相同的 keys 就会被排列到一起. <strong>之所以需要排序, 是因为会有不同的 keys 落到同一个 reduce worker(毕竟像 hash(key’) mod R 这种算法无法保证原空间和像空间是一一映射)</strong>. 如果数据大到无法装进内存, reduce worker 就会采用外部排序算法.</li>
<li><strong>reduce worker 迭代排序后的数据, 针对每个唯一 key’, 它会把其连同对应的一组 value’ 传给用户编写的 Reduce 函数, 该函数输出会被追加到当前 reduce 分区的文件中</strong>. 注意, 不同于 map tasks, reduce worker 的输出是写到 GFS.</li>
<li>当全部 map tasks 和 reduce tasks 执行完成后, master 就会唤醒用户程序. MapReduce 调用返回至用户代码. 执行成功后, mapreduce 结果保存到了 R 个输出文件中(每个 reduce 任务一个输出文件). <strong>一般用户无需合并这 R 个文件, 因为这些文件会被作为下个阶段的 MapReduce 调用的输入, 或者作为其它可以处理多个输入文件的分布式应用的输入</strong>.</li>
</ol>
<h2><span id="32-master-节点的作用">3.2 Master 节点的作用</span></h2><p>master 保存着 map tasks 和 reduce tasks 的状态信息以及它们对应的机器 id. </p>
<p>master 是一个将中间文件位置信息从 map 传递到 reduce 的中介.</p>
<p>master 保存 map tasks 生成的 R 个中间文件区域的位置信息和大小, 因为 map task 成功完成而产生的这些信息的更新都会被 master 接收并增量推送给正在执行的 reduce tasks.</p>
<h2><span id="33-容错">3.3 容错</span></h2><h3><span id="331-worker-故障">3.3.1 worker 故障</span></h3><p>(这里的 worker 指的是机器.)</p>
<p>master 周期性 ping 各个 worker 来检活, 如果故障了, 则 master 会在其它机器上重新调度其上跑的 tasks.</p>
<p>故障机器上运行中的 map task 或者 reduce task 会被被重置为 idle 状态, 因此可以在其它 workers 上再次被调度.</p>
<p>失败的 map tasks 会在其它机器上调度重新执行一遍, 因为它们的输出都在故障机器本地磁盘上, 所以这些数据就丢了; 但是 reduce tasks 失败后在其它机器上被调度后无需从头重新执行, 因为它们的输出在类似 GFS 的分布式文件系统中, 继续从失败处继续运行即可.</p>
<p>如果 map task 换机器重新执行, 那么这个情况会被告知给全部 reduce workers, 毕竟这个 map task 输出的中间数据可能会覆盖全部 reduce workers 对应的分区.</p>
<p>MapReduce 可以容忍大批机器集体故障几分钟, 只需将故障机器上跑的任务重新在其它机器上重新调度执行就可以保证进度进行下去.</p>
<h3><span id="332-master-故障">3.3.2 master 故障</span></h3><p>除了心跳以外, 周期性 checkpoint 是提升容错的另一个利器. master 可以周期性的 checkpointing 自己的状态, 如果失效, 则从最后一个 checkpoint 重启新的 master 即可.</p>
<p>即使是单一 master 架构, 但也容易失效, 如果失效, 客户端可以选择重试 MapReduce 计算.</p>
<h3><span id="333-故障存在场景下的语义保证">3.3.3 故障存在场景下的语义保证</span></h3><p>当用户提供的 map 和 reduce 算子是其输入值的确定性函数时(绝大多数计算场景都这样)，即输入确定则输出也是确定的, 我们的分布式实现产生的输出与单体程序的无故障顺序执行所产生的输出相同。<strong>但达成这一点依赖于 map 和 reduce 的输出能原子化地提交</strong>, 下面详述.</p>
<p>每个进行中的 task 会生成自己的私有临时文件:</p>
<ul>
<li>每个 reduce task 会生成一个文件; </li>
<li>每个 map task 会生成 R 个文件, 每个文件对应一个 reduce task. </li>
</ul>
<p>其中, map task 被重新调度会丢弃之前的输出会重新从头计算, 成功完成后会将自己生成的 R 个文件的名字上报给 master, master 会将其记录到本地. </p>
<p>reduce task 完成后会将自己的临时输出文件重命名为最终输出文件, 这个重命名过程是原子化的, 看过之前 GFS 分享的应该很清楚. 如果同样的 reduce task 因为故障被在多个机器上先后执行, 那么同一个最终输出文件会被重命名多次. 但由于输出都一样, 所以文件内容也都一样. 我们依赖底层文件系统如 GFS 提供的原子化重命名操作来保证最终的文件状态与同样的 reduce task 只运行一次结果相同.</p>
<p>前面说的都是算子是确定性函数的情形, 如果算子具有不确定性呢?</p>
<p>针对不确定性情形, 我们提供了比较弱但是仍合理的语义. 当存在不确定算子时, 某个 reduce task $R_{1}$ 的输出等价于一个不确定程序顺序执行时的输出, 而另一个 reduce task $R_{2}$ 的输出可能对应前述不确定程序的另一个顺序执行的输出. 考虑 map task $M$ 和 reduce tasks $R_{1}$ 和 $R_{2}$, 令 $e(R_{i})$ 代表 $R_{i}$ 的执行过程(一次恰好仅有一个该执行过程, 因为只有 task 故障了才会执行另一个). 因为 $e(R_{1})$ 可能读取了 $M$ 某次执行的输出, 而 $e(R_{2})$ 可能读取了 $M$ 的另一次执行的输出, 所以弱语义就保证了.</p>
<h2><span id="34-数据局部性">3.4 数据局部性</span></h2><p>由 GFS 管理的输入数据就保存在 MapReduce 集群的磁盘上. MapReduce master 在调度 map 任务时会把输入文件的位置信息也考虑进来, 尽量把 map 任务调度到对应数据副本所在机器上, 如果该项尝试失败, 则将 map 任务调度到离着输入数据比较近的(同一局域网或同一个交换机连接的网络)机器上. </p>
<p>在大型 MapReduce 计算过程中, 数据局部性可以极大地减少网络消耗.</p>
<h2><span id="35-任务颗粒度">3.5 任务颗粒度</span></h2><p><strong>map 任务数 M 和 reduce 任务数 R 加起来要远大于 worker 机器数</strong>. 一般一个 worker 同时执行多个任务, 这可以提升动态负载均衡.</p>
<p>master 要做出 $O(M + R)$ 调度策略, 在内存中持有 $O(M * R)$ 个状态(每个 map/reduce 对对应状态大约一个字节).</p>
<p>用户一般想要控制 R 的大小, 因为每个 reduce 任务单独输出一个文件, <strong>控制 R 可以控制最终文件个数</strong>. <strong>我们倾向于选择大的 M 以使得每个 map 任务处理的数据量在 16MB 到 64MB 之间, 令 R 为 workers 的一个很小的倍数</strong>. 比如, 如果有 2,000 workers, 那么 R 选为 5,000, 而 M 选为 200,000.</p>
<h2><span id="36-后备任务">3.6 后备任务</span></h2><p>拖长 mapreduce 计算时间的就是最后完成 map 或者 reduce 任务的机器. 原因一般是机器某些硬件比较差, 比如磁盘 IO 很慢; 或者集群调度系统(除了调度 MR 任务也调度其它的)把很多任务调度到了最后几个任务所在机器上导致资源争用严重.</p>
<p>我们有一个通用的缓解拖后腿问题的机制: 当一个 mapreduce 操作接近完成的时候 master 就会针对仍处于执行阶段的任务调度对应的后备任务, 不管主任务还是后备任务结束, 相关任务就会被标记为完成. 该机制大幅减少了大型 mapreduce 任务的时间消耗, 而资源消耗仅增加几个点.</p>
<h1><span id="4-调优">4 调优</span></h1><p>尽管对大部分需求, 写写 Map 和 Reduce 函数就够了, 但还是发现了一些可以优化的地方.</p>
<h2><span id="41-分区函数">4.1 分区函数</span></h2><p>用户在指定 reduce tasks 个数(也即输出文件个数) R 的值的时候, 也可以指定分区函数, 即如何根据中间数据 key 将数据分散到这 R 个文件. 默认的分区函数就是 <code>hash(key) mod R</code>. </p>
<p>用户可以基于具体需求指定分区函数, 比如当中间 key 是 URL 时候, 如果想把同一个网站的数据刚到同一个文件, 则可以这样 <code>hash(Hostname(urlkey)) mod R</code>.</p>
<h2><span id="42-顺序保证">4.2 顺序保证</span></h2><p>前面讲了, reduce task 在调用 Reduce 函数之前会将本分区数据就行排序, 所以可以保证一个分区内的中间数据会按照升序处理. 这使得为每个分区生成有序输出文件变得简单, 而且也使得针对在每个分区文件进行随机 key 查询变得高效(有序就可以二分查找了).</p>
<h2><span id="43-合并函数combiner-function">4.3 合并函数(combiner function)</span></h2><p>在某些情况下, Reduce 函数满足交换性和结合性, 比如 word counting, 此时可以在每个中间 kv 通过网络传输给 Reduce 函数之前做一件事情, 即允许用户指定一个可选的 Combiner 函数, 它负责在<strong>网络传输前</strong>先对部分数据进行合并再发送, 这可以大幅减少网络数据交互量.</p>
<p>Combiner 函数在执行 map task 的机器上运行, 因为它针对的是 map 生成的数据. </p>
<p>一般情况下, Combiner 函数代码与 Reduce 函数代码就是同一份. 这两者唯一不同就是 MapReduce  库如何处理它们的输出上. Reduce 函数的输出被写到最终输出文件上, 但是 Combiner 函数输出被写到一个中间文件, 该文件内容将会被发给 reduce task.</p>
<h2><span id="44-输入输出类型">4.4 输入输出类型</span></h2><p>MapReduce 库支持读取多种不同的文件类型. 比如 “text” 类型, 把每一行当作一个 key/value 对: key 是文件偏移量, value 是偏移处一行文件内容. 不管哪种文件类型, 库里对应的代码都知道如何把数据切分成有意义的范围给对应的 map task 去处理. 当然用户也可以实现相应接口来定制支持特定的文件类型.</p>
<p>MapReduce 对输出类型的支持也像输入一样灵活.</p>
<h2><span id="45-跳过坏记录">4.5 跳过坏记录</span></h2><p>有时候用户编写的代码或者依赖的第三方库有 bugs, 导致 mapreduce 任务处理不了某些数据总是挂掉, 第一种情况还好说, 第三方库的就不好搞了. 这时候你可能希望能跳过这些记录. 怎么做到呢?</p>
<p>每个工作进程可以安装一个信号处理器用来捕获段错误或者总线错误. 在调用用户编写的 Map 或者 Reduce 之前, MapReduce 库存储一个序列号到全局变量中. 如果用户代码生成一个信号, 那么前面提到的信号处理器就会发送一个包含前述序列号的 UDP 包给 master. 如果 master 发现, 针对某个记录已经收到不止一次上报了, 它就会在重新执行挂掉的 Map/Reduce task 时跳过这条记录.</p>
<h2><span id="46-状态信息">4.6 状态信息</span></h2><p>master 除了做任务调度, 还提供了一个 HTTP server, 用户可以访问它来获取整个集群的状态统计信息. 比如计算进展, 每个 task 的输出等等.</p>
<h2><span id="49-全局计数器">4.9 全局计数器</span></h2><p>MapReduce 库提供了计数器设施, 用户可以利用它在 Map/Reduce 函数中针对一些事件进行统计, 比如在单词计数应用中针对大写的单词进行统计:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Counter* uppercase;</span><br><span class="line">uppercase = GetCounter(<span class="string">&quot;uppercase&quot;</span>);</span><br><span class="line"><span class="built_in">map</span>(String name, String contents):</span><br><span class="line">  <span class="keyword">for</span> each word w in contents:</span><br><span class="line">    <span class="comment">// 如果当前单词大写, 则将全局计数器加 1</span></span><br><span class="line">    <span class="keyword">if</span> (IsCapitalized(w)):</span><br><span class="line">      uppercase-&gt;Increment();</span><br><span class="line">    EmitIntermediate(w, <span class="string">&quot;1&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>这些计数值会周期性地随心跳响应传递到 master, 然后 master 进行聚合, 聚合时 master 会去重(比如重复调度执行的任务或为了加速完成而启动的后备任务都会造成重复计数). 用户可以从前面提到的 http server 页面查看值的变化.</p>
<h1><span id="5-性能">5 性能</span></h1><p>下面以排序程序为例, 说明下各阶段数据传输速率比较以及后备任务对性能的影响.</p>
<p><img src="/images/google-mapreduce-20210303/figure-2-data-transfer-rate-for-different-executions-of-sort.png" alt="Figure 2"></p>
<p>如上图所示, 横向分为三部分, 分别是正常执行情况, 无后备任务执行情况, 手动干掉 200 个进程的执行情况. 其中, 每种执行情况纵向列出三个指标, 分别是输入数据速率, 排序数据速率, 输出数据速率. 具体每个图, 横轴是时间, 纵轴是速率.</p>
<ol>
<li>a 列上图是数据读取速率, 显著快于下面的排序和输出, 这全都拜前面提到的数据局部性所赐.</li>
<li>a 列中图是排序, 可以看到第一个 map task 完成后即启动了排序. 第一个高峰是 1700 个 reduce tasks 执行盛况(这个 sort 程序用了 1700 台机器, 每个机器执行不超过 1 个 reduce task.), 大约 300 秒后第一批数据排序完成, 然后对剩下数据进行排序, 大约 600 秒时完成全部排序任务. 从该图可以看出数据传输速率高于下面的输出, 原因是下面输出要写到 GFS 多副本, 比较耗时.</li>
<li>a 列下图是输出, 输出就是 reduce tasks 将数据写入到 GFS. 可以看到第一批数据排序完成到开始输出有一个延迟, 原因是这段时间内机器忙着排序中间数据. </li>
<li>b 列下图显示最终完成时间要显著多余 a 列, 原因是最后 5 个 reduce tasks 严重拖后腿了, 整体耗时增长 44%. 这可以看出后备任务的对性能的显著提升.</li>
<li>c 列上图显示显示手动干掉 200 个进程(机器还正常运行)后速率变成负的了, 原因是部分 map tasks 丢了, 需要重跑. 集群调度器快速在这些机器上重新运行相关任务, 最后 c 列下图显示仅仅比正常情况多了 5% 耗时.</li>
</ol>
<p>–End–</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://chienlungcheung.github.io/2021/02/05/leveldb-annotations-4-iterator/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chienlung Cheung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="programatrix">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/02/05/leveldb-annotations-4-iterator/" class="post-title-link" itemprop="url">Leveldb 源码详解系列之四: 迭代器设计与实现</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-02-05 13:53:51" itemprop="dateCreated datePublished" datetime="2021-02-05T13:53:51+00:00">2021-02-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-03 09:19:19" itemprop="dateModified" datetime="2021-03-03T09:19:19+00:00">2021-03-03</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2021/02/05/leveldb-annotations-4-iterator/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2021/02/05/leveldb-annotations-4-iterator/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <!-- toc -->

<ul>
<li><a href="#1-%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1">1 迭代器接口设计</a><ul>
<li><a href="#11-%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%BE%8B">1.1 迭代器实现一例</a></li>
</ul>
</li>
<li><a href="#2-%E5%8F%8C%E5%B1%82%E8%BF%AD%E4%BB%A3%E5%99%A8%E8%AE%BE%E8%AE%A1">2 双层迭代器设计</a></li>
</ul>
<!-- tocstop -->

<p>迭代器的设计和实现是 leveldb 的精华之一. 前几篇文章都多少提到了迭代器的使用, 本篇让我们深入一下迭代器的设计实现, 也为接下来的几篇剖析打下基础.</p>
<h1><span id="1-迭代器接口设计">1 迭代器接口设计</span></h1><p>迭代器接口类为 <code>leveldb::Iterator</code>, 位于 <code>include/leveldb/iterator.h</code> 和 <code>table/iterator.cc</code>. (实现位于 table 目录, 是因为接下来要介绍的 sstable 是迭代器重度用户.)</p>
<p>迭代器接口定义比较简洁, 主要方法为指向合法性判断, 前后移动, 定位(开头/末尾/任意), 提取数据项 key/value 等等. </p>
<p>唯一的数据成员为清理函数列表头节点. </p>
<p>具体如下:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LEVELDB_EXPORT</span> <span class="title">Iterator</span> &#123;</span></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  Iterator();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 禁用复制构造</span></span><br><span class="line">  Iterator(<span class="keyword">const</span> Iterator&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  <span class="comment">// 禁用赋值构造</span></span><br><span class="line">  Iterator&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> Iterator&amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">virtual</span> ~Iterator();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 一个迭代器要么指向 key/value 对, 要么指向非法位置.</span></span><br><span class="line">  <span class="comment">// 当且仅当第一种情况才为 valid.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">bool</span> <span class="title">Valid</span><span class="params">()</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将迭代器移动到数据源的第一个 key/value 对.</span></span><br><span class="line">  <span class="comment">// 当前仅当数据源不空时, 调用完该方法再调用 Valid() 为 true.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">SeekToFirst</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将迭代器移动到数据源的最后一个 key/value 对.</span></span><br><span class="line">  <span class="comment">// 当前仅当数据源不空时, 调用完该方法再调用 Valid() 为 true.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">SeekToLast</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将迭代器指向移动到数据源 target 位置或之后的第一个 key.</span></span><br><span class="line">  <span class="comment">// 当且仅当移动后的位置存在数据项时, 调用 Valid() 才为 true.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Seek</span><span class="params">(<span class="keyword">const</span> Slice&amp; target)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 将迭代器移动到数据源下一个数据项.</span></span><br><span class="line">  <span class="comment">// 当且仅当迭代器未指向数据源最后一个数据项时, 调用完该方法后调用 Valid() 结果为 true.</span></span><br><span class="line">  <span class="comment">// 注意: 调用该方法前提是迭代器当前指向必须 valid.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Next</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将迭代器移动到数据源前一个数据项.</span></span><br><span class="line">  <span class="comment">// 当且仅当迭代器未指向数据源第一个数据项时, 调用完该方法后调用 Valid() 结果为 true.</span></span><br><span class="line">  <span class="comment">// 注意: 调用该方法前提是迭代器当前指向必须 valid.  </span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Prev</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 返回当前迭代器指向的数据项的 key, Slice 类型, 如果使用迭代器进行修改则会反映到</span></span><br><span class="line">  <span class="comment">// 已返回的 key 上面.</span></span><br><span class="line">  <span class="comment">// 注意: 调用该方法前提是迭代器当前执行必须 valid.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Slice <span class="title">key</span><span class="params">()</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 返回当前迭代器指向的数据项的 value, Slice 类型, 如果使用迭代器进行修改则会反映到</span></span><br><span class="line">  <span class="comment">// 已返回的 value 上面.</span></span><br><span class="line">  <span class="comment">// 注意: 调用该方法前提是迭代器当前执行必须 valid.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Slice <span class="title">value</span><span class="params">()</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 发生错误返回之; 否则返回 ok.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">status</span><span class="params">()</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 我们允许调用方注册一个带两个参数的回调函数, 当迭代器析构时该函数会被自动调用.</span></span><br><span class="line">  <span class="keyword">using</span> CleanupFunction = <span class="keyword">void</span> (*)(<span class="keyword">void</span>* arg1, <span class="keyword">void</span>* arg2);</span><br><span class="line">  <span class="comment">// 我们允许客户端注册 CleanupFunction 类型的回调函数, 在迭代器被销毁的时候会调用它们(可以注册多个). </span></span><br><span class="line">  <span class="comment">// 注意, 跟前面的方法不同, RegisterCleanup 不是抽象的, 客户端不应该覆写他们. </span></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">RegisterCleanup</span><span class="params">(CleanupFunction function, <span class="keyword">void</span>* arg1, <span class="keyword">void</span>* arg2)</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// 清理函数被维护在一个单向链表上, 其中头节点被 inlined 到迭代器中.</span></span><br><span class="line">  <span class="comment">// 该类用于保存用户注册的清理函数, 一个清理函数对应一个该类对象, 全部对象被维护在一个单向链表上. </span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">CleanupNode</span> &#123;</span></span><br><span class="line">    <span class="comment">// 清理函数及其两个参数</span></span><br><span class="line">    CleanupFunction function;</span><br><span class="line">    <span class="keyword">void</span>* arg1;</span><br><span class="line">    <span class="keyword">void</span>* arg2;</span><br><span class="line">    <span class="comment">// 下个清理函数</span></span><br><span class="line">    CleanupNode* next;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 判断清理函数是否为空指针.</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">IsEmpty</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> function == <span class="literal">nullptr</span>; &#125;</span><br><span class="line">    <span class="comment">// 运行调用方通过 Iterator::RegisterCleanup 注册的清理函数</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">Run</span><span class="params">()</span> </span>&#123; assert(function != <span class="literal">nullptr</span>); (*function)(arg1, arg2); &#125;</span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="comment">// 清理函数列表的头节点</span></span><br><span class="line">  CleanupNode cleanup_head_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>Iterator</code> 本身实现了三个方法, 分别是构造方法, 析构方法, 以及清理函数注册方法. 下面是非抽象方法的实现:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 构造方法, 初始化唯一数据成员</span></span><br><span class="line">Iterator::Iterator() &#123;</span><br><span class="line">  cleanup_head_.function = <span class="literal">nullptr</span>;</span><br><span class="line">  cleanup_head_.next = <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Iterator::~Iterator() &#123;</span><br><span class="line">  <span class="comment">// 析构时调用已注册的清理函数</span></span><br><span class="line">  <span class="keyword">if</span> (!cleanup_head_.IsEmpty()) &#123;</span><br><span class="line">    <span class="comment">// 线性的, 如果在该迭代器上注册的清理函数太多了应该会影响性能, 但总要做释放操作, 时间总归省不了.</span></span><br><span class="line">    cleanup_head_.Run();</span><br><span class="line">    <span class="keyword">for</span> (CleanupNode* node = cleanup_head_.next; node != <span class="literal">nullptr</span>; ) &#123;</span><br><span class="line">      node-&gt;Run();</span><br><span class="line">      CleanupNode* next_node = node-&gt;next;</span><br><span class="line">      <span class="keyword">delete</span> node;</span><br><span class="line">      node = next_node;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将用户定制的清理函数挂到单向链表上, 待迭代器销毁时挨个调用(见 ~Iterator()). </span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Iterator::RegisterCleanup</span><span class="params">(CleanupFunction func, <span class="keyword">void</span>* arg1, <span class="keyword">void</span>* arg2)</span> </span>&#123;</span><br><span class="line">  assert(func != <span class="literal">nullptr</span>);</span><br><span class="line">  CleanupNode* node;</span><br><span class="line">  <span class="keyword">if</span> (cleanup_head_.IsEmpty()) &#123;</span><br><span class="line">    node = &amp;cleanup_head_;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    node = <span class="keyword">new</span> CleanupNode();</span><br><span class="line">    <span class="comment">// 新节点插到 head 后面</span></span><br><span class="line">    node-&gt;next = cleanup_head_.next;</span><br><span class="line">    cleanup_head_.next = node;</span><br><span class="line">  &#125;</span><br><span class="line">  node-&gt;function = func;</span><br><span class="line">  node-&gt;arg1 = arg1;</span><br><span class="line">  node-&gt;arg2 = arg2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2><span id="11-迭代器实现一例">1.1 迭代器实现一例</span></h2><p>下面以 sstable 的 block 为例示意一下迭代器的实现. 关键部分就是将 block 作为迭代器数据源, 基于 block 构造和查询原理实现迭代器的前后移动, 定位等操作. 里面涉及了一些成员看不懂也不用管, 在介绍 sstable 时会解释.</p>
<p>具体类为 <code>leveldb::Block::Iter</code>, 代码位于 <code>table/block.cc</code> 文件:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Block</span>:</span>:Iter : <span class="keyword">public</span> Iterator &#123;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// 迭代时使用的比较器</span></span><br><span class="line">  <span class="keyword">const</span> Comparator* <span class="keyword">const</span> comparator_;</span><br><span class="line">  <span class="comment">// 指向 block 的指针</span></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">char</span>* <span class="keyword">const</span> data_;</span><br><span class="line">  <span class="comment">// block 的 restart 数组</span></span><br><span class="line">  <span class="comment">// (每个元素 32 位固定长度, 保存着每个 restart 在 block 里的偏移量)</span></span><br><span class="line">  <span class="comment">// 在 block 里的起始偏移量</span></span><br><span class="line">  <span class="keyword">uint32_t</span> <span class="keyword">const</span> restarts_;</span><br><span class="line">  <span class="comment">// restart 数组元素个数(每个元素都是 uint32_t 类型)</span></span><br><span class="line">  <span class="keyword">uint32_t</span> <span class="keyword">const</span> num_restarts_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// current_ 表示当前数据项在 data_ 里的偏移量, </span></span><br><span class="line">  <span class="comment">// 如果迭代器无效则该值大于等于 restarts_ </span></span><br><span class="line">  <span class="comment">// 即 restart array 在 block 的起始偏移量</span></span><br><span class="line">  <span class="comment">// (restart array 位于 block 后部, 数据项在 block 前半部分)</span></span><br><span class="line">  <span class="keyword">uint32_t</span> current_;</span><br><span class="line">  <span class="comment">// restart block 的索引值, current_ 指向的数据项落在该 block</span></span><br><span class="line">  <span class="keyword">uint32_t</span> restart_index_;</span><br><span class="line">  <span class="comment">// current_ 所指数据项的 key</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">string</span> key_; </span><br><span class="line">  <span class="comment">// current_ 所指数据项的 value</span></span><br><span class="line">  Slice value_; </span><br><span class="line">  <span class="comment">// 当前迭代器对应的状态</span></span><br><span class="line">  Status status_;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">Compare</span><span class="params">(<span class="keyword">const</span> Slice&amp; a, <span class="keyword">const</span> Slice&amp; b)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> comparator_-&gt;Compare(a, b);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 返回 current_ 所指数据项的下一个数据项的偏移量. </span></span><br><span class="line">  <span class="comment">// 根据 Block 布局我们可以知道, value 位于每个数据项最后, </span></span><br><span class="line">  <span class="comment">// 所以 value 之后第一个字节即为下一个数据项起始位置. </span></span><br><span class="line">  <span class="function"><span class="keyword">inline</span> <span class="keyword">uint32_t</span> <span class="title">NextEntryOffset</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (value_.data() + value_.size()) - data_;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 返回索引值为 index 的 restart 在 block 中的起始偏移量</span></span><br><span class="line">  <span class="function"><span class="keyword">uint32_t</span> <span class="title">GetRestartPoint</span><span class="params">(<span class="keyword">uint32_t</span> index)</span> </span>&#123;</span><br><span class="line">    assert(index &lt; num_restarts_);</span><br><span class="line">    <span class="keyword">return</span> DecodeFixed32(data_ + restarts_ + index * <span class="keyword">sizeof</span>(<span class="keyword">uint32_t</span>));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将迭代器移动到索引值为 index 的 restart 对应的偏移量位置.</span></span><br><span class="line">  <span class="comment">// 注意, 此方法只调整了 current_ 对应的 value_, 此时两者不再保持一致; </span></span><br><span class="line">  <span class="comment">// current_ 与 key_ 仍然保持一致性. </span></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">SeekToRestartPoint</span><span class="params">(<span class="keyword">uint32_t</span> index)</span> </span>&#123;</span><br><span class="line">    key_.clear();</span><br><span class="line">    restart_index_ = index;</span><br><span class="line">    <span class="comment">// current_ 和 key_ 指向后续会被 ParseNextKey() 校正.</span></span><br><span class="line">    <span class="comment">// ParseNextKey() 从 value_ 末尾开始, 所以这里需要设置好, 为何从 value_ </span></span><br><span class="line">    <span class="comment">// 末尾开始呢? 根据 Block 布局我们可以知道, value 位于每个数据项最后, </span></span><br><span class="line">    <span class="comment">// 所以 value 之后第一个字节即为下一个数据项起始位置.</span></span><br><span class="line">    <span class="keyword">uint32_t</span> offset = GetRestartPoint(index);</span><br><span class="line">    <span class="comment">// 将 value 数据起始地址设置为 offset 对应的 restart 起始位置, </span></span><br><span class="line">    <span class="comment">// value_ 这么设置是为了方便 ParseNextKey().</span></span><br><span class="line">    value_ = Slice(data_ + offset, <span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  Iter(<span class="keyword">const</span> Comparator* comparator,</span><br><span class="line">       <span class="keyword">const</span> <span class="keyword">char</span>* data,</span><br><span class="line">       <span class="keyword">uint32_t</span> restarts,</span><br><span class="line">       <span class="keyword">uint32_t</span> num_restarts)</span><br><span class="line">      : comparator_(comparator),</span><br><span class="line">        data_(data),</span><br><span class="line">        restarts_(restarts),</span><br><span class="line">        num_restarts_(num_restarts),</span><br><span class="line">        current_(restarts_),</span><br><span class="line">        restart_index_(num_restarts_) &#123;</span><br><span class="line">    assert(num_restarts_ &gt; <span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">bool</span> <span class="title">Valid</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> current_ &lt; restarts_; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">status</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> status_; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Slice <span class="title">key</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    assert(Valid());</span><br><span class="line">    <span class="keyword">return</span> key_;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Slice <span class="title">value</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    assert(Valid());</span><br><span class="line">    <span class="keyword">return</span> value_;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Next</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 向后移动前提是当前指向合法</span></span><br><span class="line">    assert(Valid());</span><br><span class="line">    ParseNextKey();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将 current 指向当前数据项前一个数据项. </span></span><br><span class="line">  <span class="comment">// 如果 current 指向的已经是 block 第 0 个数据项, 则无须移动了; </span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Prev</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 向前移动前提是当前指向合法</span></span><br><span class="line">    assert(Valid());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 倒着扫描, 直到 current_ 之前的一个 restart point.</span></span><br><span class="line">    <span class="comment">// current_ 大于等于所处 restart 段起始地址, 下面要做的</span></span><br><span class="line">    <span class="comment">// 是寻找 current_ 之前的一个 restart point. </span></span><br><span class="line">    <span class="comment">// 把 current_ 当前取值作为原点.</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">uint32_t</span> original = current_;</span><br><span class="line">    <span class="comment">// 下面循环干一件事, 定位 current_ 前一个数据项, 具体分两种情况：</span></span><br><span class="line">    <span class="comment">// - 如果 current_ 大于所处 restart 段起始地址, 不进行循环, </span></span><br><span class="line">    <span class="comment">//   到下面去直接定位 current_ 前一个数据项即可.</span></span><br><span class="line">    <span class="comment">// - 如果 current_ 等于所处 restart 段起始地址, </span></span><br><span class="line">    <span class="comment">//    - 如果当前 restart 不是 block 的首个 restart, </span></span><br><span class="line">    <span class="comment">//      则 current_ 前一个数据项肯定位于前一个 restart 最后一个位置</span></span><br><span class="line">    <span class="comment">//    - 如果当前 restart 是 block 的首个 restart, </span></span><br><span class="line">    <span class="comment">//      则 current_ 就是 block 首个数据项, 所以没有所谓前一个数据项了</span></span><br><span class="line">    <span class="comment">// - 没有其它情况. </span></span><br><span class="line">    <span class="comment">// 循环能够执行的唯一条件就是相等</span></span><br><span class="line">    <span class="keyword">while</span> (GetRestartPoint(restart_index_) &gt;= original) &#123; </span><br><span class="line">      <span class="comment">// 倒到开头的 restart point 了, 没法再向前倒了, 也就是没有 pre 了.</span></span><br><span class="line">      <span class="keyword">if</span> (restart_index_ == <span class="number">0</span>) &#123; </span><br><span class="line">        <span class="comment">// current_ 置为同 restarts_, </span></span><br><span class="line">        <span class="comment">// 即使得它位于 block 首个 restart 的首个数据项处.</span></span><br><span class="line">        current_ = restarts_;</span><br><span class="line">        <span class="comment">// 将 restart_index_ 置为 restart point 个数,</span></span><br><span class="line">        <span class="comment">// 这个索引是越界的.</span></span><br><span class="line">        restart_index_ = num_restarts_;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 倒车, 请注意.</span></span><br><span class="line">      restart_index_--;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 粗粒度移动, 即先将 current_ 移动到指定 restart 分段</span></span><br><span class="line">    SeekToRestartPoint(restart_index_);</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">      <span class="comment">// 细粒度移动, 将 current_ 移动到 original (current_ 移动之前的值)的前一个数据项</span></span><br><span class="line">    &#125; <span class="keyword">while</span> (ParseNextKey() &amp;&amp; NextEntryOffset() &lt; original);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 寻找 block 中第一个 key 大于等于 target 的数据项. </span></span><br><span class="line">  <span class="comment">// 先通过二分法在 restart 段级定位查找目标段, 存在</span></span><br><span class="line">  <span class="comment">// key &lt; target 且是最后一个 restart 段; </span></span><br><span class="line">  <span class="comment">// 然后在目标段进行线性查找找到第一个 key 大约等于 target 的数据项.</span></span><br><span class="line">  <span class="comment">// 如果存在则 current_ 指向该目标数据项; 否则 current_ 指向</span></span><br><span class="line">  <span class="comment">// 一个非法数据项. </span></span><br><span class="line">  <span class="comment">// 调用者需要检查返回结果以确认是否找到了. </span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Seek</span><span class="params">(<span class="keyword">const</span> Slice&amp; target)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 在 restart array 中进行二分查找, 找到最后一个</span></span><br><span class="line">    <span class="comment">// 存在 key 小于 target 的 restart, 注意是小于, </span></span><br><span class="line">    <span class="comment">// 这决定了后面二分查找时比较逻辑. </span></span><br><span class="line">    <span class="keyword">uint32_t</span> left = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">uint32_t</span> right = num_restarts_ - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (left &lt; right) &#123;</span><br><span class="line">      <span class="keyword">uint32_t</span> mid = (left + right + <span class="number">1</span>) / <span class="number">2</span>;</span><br><span class="line">      <span class="keyword">uint32_t</span> region_offset = GetRestartPoint(mid);</span><br><span class="line">      <span class="keyword">uint32_t</span> shared, non_shared, value_length;</span><br><span class="line">      <span class="keyword">const</span> <span class="keyword">char</span>* key_ptr = DecodeEntry(data_ + region_offset,</span><br><span class="line">                                        data_ + restarts_,</span><br><span class="line">                                        &amp;shared, &amp;non_shared, &amp;value_length);</span><br><span class="line">      <span class="comment">// 注意, 在 block 中, 每个位于 restart 起始处的数据项的 key 肯定</span></span><br><span class="line">      <span class="comment">// 是没有做过前缀压缩的, 所以 shared 肯定为 0.</span></span><br><span class="line">      <span class="comment">// 同时要注意, 这是异常情况, 不属于循环不变式的成立的条件. </span></span><br><span class="line">      <span class="keyword">if</span> (key_ptr == <span class="literal">nullptr</span> || (shared != <span class="number">0</span>)) &#123;</span><br><span class="line">        CorruptionError();</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="function">Slice <span class="title">mid_key</span><span class="params">(key_ptr, non_shared)</span></span>;</span><br><span class="line">      <span class="comment">// 因为 block 中 key 都是递增排列的, 所以每个 restart </span></span><br><span class="line">      <span class="comment">// 段位于 restart 首位置的那个 key 肯定是所在段最小的. </span></span><br><span class="line">      <span class="comment">// 如果最后存在这样的 restart, 肯定是由 left 指向：</span></span><br><span class="line">      <span class="comment">// - 因为 left 右移的条件是远小于 target</span></span><br><span class="line">      <span class="comment">// - 因为 right 左移的条件是大于等于 target</span></span><br><span class="line">      <span class="keyword">if</span> (Compare(mid_key, target) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// Key at &quot;mid&quot; is smaller than &quot;target&quot;.  Therefore all</span></span><br><span class="line">        <span class="comment">// blocks before &quot;mid&quot; are uninteresting.</span></span><br><span class="line">        left = mid;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// Key at &quot;mid&quot; is &gt;= &quot;target&quot;.  Therefore all blocks at or</span></span><br><span class="line">        <span class="comment">// after &quot;mid&quot; are uninteresting.</span></span><br><span class="line">        right = mid - <span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 即使初始 left == right 也会走到这</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 定位到目标 restart 段, 为下面线性查找打基础</span></span><br><span class="line">    SeekToRestartPoint(left);</span><br><span class="line">    <span class="comment">// 定位到 left 指向的 restart 段以后, 挨个 key 进行比较,</span></span><br><span class="line">    <span class="comment">// 寻找第一个大于等于 target 的 key</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!ParseNextKey()) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (Compare(key_, target) &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将迭代器移动到 block 第一个数据项</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">SeekToFirst</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 定位到第一个 restart 段</span></span><br><span class="line">    SeekToRestartPoint(<span class="number">0</span>);</span><br><span class="line">    <span class="comment">// 在之前基础上定位到第一个数据项</span></span><br><span class="line">    ParseNextKey();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将迭代器移动到 block 最后一个数据项</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">SeekToLast</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 定位到最后一个 restart 段</span></span><br><span class="line">    SeekToRestartPoint(num_restarts_ - <span class="number">1</span>);</span><br><span class="line">    <span class="comment">// 在之前基础上定位到最后一个数据项</span></span><br><span class="line">    <span class="keyword">while</span> (ParseNextKey() &amp;&amp; NextEntryOffset() &lt; restarts_) &#123;</span><br><span class="line">      <span class="comment">// Keep skipping</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// 如果出错, 则将各个成员置为非法值</span></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">CorruptionError</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    current_ = restarts_;</span><br><span class="line">    restart_index_ = num_restarts_;</span><br><span class="line">    status_ = Status::Corruption(<span class="string">&quot;bad entry in block&quot;</span>);</span><br><span class="line">    key_.clear();</span><br><span class="line">    value_.clear();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将 current_, key_, value_ 指向下一个数据项的</span></span><br><span class="line">  <span class="comment">// 起始偏移量、key 部分、value 部分, 同时保持</span></span><br><span class="line">  <span class="comment">// restart_index_ 与 current_ 新位置所处 restart 段一致. </span></span><br><span class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">ParseNextKey</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// current_ 指向接下来的数据项</span></span><br><span class="line">    current_ = NextEntryOffset(); </span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">char</span>* p = data_ + current_;</span><br><span class="line">    <span class="comment">// 数据部分之后紧接着就是 restart</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">char</span>* limit = data_ + restarts_; </span><br><span class="line">    <span class="keyword">if</span> (p &gt;= limit) &#123;</span><br><span class="line">      <span class="comment">// 数据部分到头了, 返回 false</span></span><br><span class="line">      current_ = restarts_;</span><br><span class="line">      restart_index_ = num_restarts_;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 解码下个数据项</span></span><br><span class="line">    <span class="keyword">uint32_t</span> shared, non_shared, value_length;</span><br><span class="line">    p = DecodeEntry(p, limit, &amp;shared, &amp;non_shared, &amp;value_length);</span><br><span class="line">    <span class="comment">// key_ 保存的还是前一个数据项的 key, </span></span><br><span class="line">    <span class="comment">// 而大小必然不小于接下来的数据项的 key 与其公共前缀部分大小</span></span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">nullptr</span> || key_.size() &lt; shared) &#123;</span><br><span class="line">      CorruptionError();</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 保留 key_ 与 key 公共前缀部分</span></span><br><span class="line">      key_.resize(shared); </span><br><span class="line">      <span class="comment">// 将当前数据项 key 的非公共部分追加进来, 得到一个完整的 key</span></span><br><span class="line">      key_.append(p, non_shared); </span><br><span class="line">      <span class="comment">// 当前数据项的 value 部分. 到此为止, </span></span><br><span class="line">      <span class="comment">// current_、key_、value_ 都已指向同一个数据项. </span></span><br><span class="line">      value_ = Slice(p + non_shared, value_length); </span><br><span class="line">      </span><br><span class="line">      <span class="comment">// 因为 current_ 已经指向新的数据项, 所以它所处的 restart 段可能也递增了, </span></span><br><span class="line">      <span class="comment">// 那就破坏了与 restart_index_ 的一致性, 所以需要调整. </span></span><br><span class="line">      <span class="comment">// 下面循环干的事情, 就是要保持 restart_index_ 与 current_ 一致, </span></span><br><span class="line">      <span class="comment">// 即让 restart_index_ 指向 current_ 所处 restart 在数组中的索引值. </span></span><br><span class="line">      <span class="comment">// restart_index_ 如果指向最后一个 restart, 那么 current_ </span></span><br><span class="line">      <span class="comment">// 此时肯定也在最后一个 restart 段. </span></span><br><span class="line">      <span class="keyword">while</span> (restart_index_ + <span class="number">1</span> &lt; num_restarts_ &amp;&amp;</span><br><span class="line">             GetRestartPoint(restart_index_ + <span class="number">1</span>) &lt; current_) &#123; </span><br><span class="line">        ++restart_index_;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 根据用户定制的 comparator 构造该 block 的一个迭代器</span></span><br><span class="line"><span class="function">Iterator* <span class="title">Block::NewIterator</span><span class="params">(<span class="keyword">const</span> Comparator* cmp)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// block 尾部 4 字节为 restart 个数, 最少 4 字节</span></span><br><span class="line">  <span class="keyword">if</span> (size_ &lt; <span class="keyword">sizeof</span>(<span class="keyword">uint32_t</span>)) &#123; </span><br><span class="line">    <span class="keyword">return</span> NewErrorIterator(Status::Corruption(<span class="string">&quot;bad block contents&quot;</span>));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">uint32_t</span> num_restarts = NumRestarts();</span><br><span class="line">  <span class="keyword">if</span> (num_restarts == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> NewEmptyIterator();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 将 block 作为数据源, 构造迭代器</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Iter(cmp, data_, restart_offset_, num_restarts);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从上面代码可以看出, 跟底层数据源相关的成员和方法都是 private 的, 迭代器接口方法实现都在 public 部分. 实现迭代器时依赖依赖两个重要的 private 方法, 一个是 <code>SeekToRestartPoint()</code> 一个是 <code>ParseNextKey()</code> 分别用于在迭代时实现先粗粒度后细粒度的目标定位.</p>
<h1><span id="2-双层迭代器设计">2 双层迭代器设计</span></h1><p>双层迭代器, 对应的类为 <code>class leveldb::&lt;unnamed&gt;::TwoLevelIterator</code>, 位于 <code>table/two_level_iterator.cc</code> 文件. 它的父类为 <code>leveldb::Iterator</code>, 所以表现出来的性质是一样的.</p>
<p>该类设计比较巧妙, 这主要是由 sstable 文件结构决定的. 具体地, 要想在 sstable 文件中找到某个 key/value 对, 肯定先要找到它所属的 data Block, 而要找到 data Block 就要先在 index block 找到其对应的 BlockHandle. 双层迭代器就是这个寻找过程的实现.</p>
<p>该类包含两个迭代器封装：</p>
<ul>
<li>一个是 index_iter_, 它指向 index block 数据项. 针对每个 data block 都有一个对应的 entry 包含在 index block 中, entry 包含一个 key/value 对, 其中：<ul>
<li>key 为大于等于对应 data block 最后(也是最大的, 因为排序过了)一个 key 同时小于接下来的 data block 的第一个 key 的(比较拗口)字符串; </li>
<li>value 是指向一个对应 data block 的 BlockHandle. </li>
</ul>
</li>
<li>另一个是 data_iter_, 它指向 data block 包含的数据项. 至于这个 data block 是否与 index_iter_ 所指数据项对应 data block 一致, 那要看实际情况, 不过即使不一致也无碍. </li>
</ul>
<p>示意图如下:</p>
<p><img src="/images/leveldb-annotations-4-iterator/1-two_level_iterator.png" alt="Figure 1"></p>
<p>这两个迭代器, 可以把 index_iter 看作钟表的时针, 指向具体小时, 可以把 data_iter_ 看作更精细的分针, 指向当前小时的具体分钟. 两个指针一起配合精确定位到我们要查询的数据. 这么说其实就能大体上猜出来, 迭代器前后移动, 定位等等这些方法是如何实现的了, 简单说就是先移动 <code>index_iter_</code> 再移动 <code>data_iter_</code>. 以 <code>Seek()</code> 方法举例来说:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 根据 target 将 index_iter 和 data_iter 移动到对应位置</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">TwoLevelIterator::Seek</span><span class="params">(<span class="keyword">const</span> Slice&amp; target)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 因为 index block 每个数据项的 key 是对应 data block 中最大的那个 key, </span></span><br><span class="line">  <span class="comment">// 所以 index block 数据项也是有序的, 不过比较&quot;宏观&quot; . </span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 先找到目标 data block</span></span><br><span class="line">  index_iter_.Seek(target);</span><br><span class="line">  <span class="comment">// 根据 index_iter_ 设置 data_iter_</span></span><br><span class="line">  InitDataBlock();</span><br><span class="line">  <span class="comment">// 然后在目标 data block 找到目标数据项</span></span><br><span class="line">  <span class="keyword">if</span> (data_iter_.iter() != <span class="literal">nullptr</span>) data_iter_.Seek(target); </span><br><span class="line">  <span class="comment">// data_iter_.iter() 为空则直接向前移动找到第一个不为空的</span></span><br><span class="line">  <span class="comment">// data block 的第一个数据项.</span></span><br><span class="line">  SkipEmptyDataBlocksForward(); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看出, 双层迭代器设计具有分形的思想, 迭代器是由迭代器构成的.</p>
<p>其它方法实现原理类似, 不再赘述.</p>
<p>–End–</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://chienlungcheung.github.io/2020/12/11/GFS-%E4%B8%80%E4%B8%AA%E9%AB%98%E5%8F%AF%E7%94%A8%E5%8F%AF%E6%89%A9%E5%B1%95%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chienlung Cheung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="programatrix">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/11/GFS-%E4%B8%80%E4%B8%AA%E9%AB%98%E5%8F%AF%E7%94%A8%E5%8F%AF%E6%89%A9%E5%B1%95%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/" class="post-title-link" itemprop="url">GFS: 一个高可用可扩展的分布式文件系统</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-12-11 21:44:47" itemprop="dateCreated datePublished" datetime="2020-12-11T21:44:47+00:00">2020-12-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-03 09:19:19" itemprop="dateModified" datetime="2021-03-03T09:19:19+00:00">2021-03-03</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/12/11/GFS-%E4%B8%80%E4%B8%AA%E9%AB%98%E5%8F%AF%E7%94%A8%E5%8F%AF%E6%89%A9%E5%B1%95%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/12/11/GFS-一个高可用可扩展的分布式文件系统/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <!-- toc -->

<ul>
<li><a href="#1-gfs-%E8%AF%9E%E7%94%9F%E8%83%8C%E6%99%AF">1 GFS 诞生背景</a></li>
<li><a href="#2-gfs-%E8%AE%BE%E8%AE%A1%E6%A6%82%E8%A7%88">2 GFS 设计概览</a><ul>
<li><a href="#21-%E5%87%A0%E7%82%B9%E5%81%87%E8%AE%BE">2.1 几点假设</a></li>
<li><a href="#22-%E6%8E%A5%E5%8F%A3">2.2 接口</a></li>
<li><a href="#23-%E6%9E%B6%E6%9E%84">2.3 架构</a></li>
<li><a href="#24-%E5%8D%95-master-%E9%9B%86%E7%BE%A4%E5%90%84%E7%BB%84%E4%BB%B6%E4%BA%A4%E4%BA%92%E9%87%8D%E7%82%B9">2.4 单 master 集群各组件交互重点</a></li>
<li><a href="#25-chunk-%E5%A4%A7%E5%B0%8F%E8%AE%BE%E8%AE%A1">2.5 chunk 大小设计</a></li>
<li><a href="#26-%E5%85%83%E4%BF%A1%E6%81%AF">2.6 元信息</a><ul>
<li><a href="#261-%E5%85%83%E4%BF%A1%E6%81%AF%E9%83%BD%E4%BF%9D%E5%AD%98%E5%9C%A8%E5%86%85%E5%AD%98%E4%B8%AD">2.6.1 元信息都保存在内存中</a></li>
<li><a href="#262-chunk-%E4%BD%8D%E7%BD%AE%E4%BF%A1%E6%81%AF">2.6.2 chunk 位置信息</a></li>
<li><a href="#263-%E6%93%8D%E4%BD%9C%E6%97%A5%E5%BF%97">2.6.3 操作日志</a></li>
</ul>
</li>
<li><a href="#27-gfs-%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E6%A8%A1%E5%9E%8B">2.7 GFS 的一致性模型</a><ul>
<li><a href="#271-gfs-%E6%8F%90%E4%BE%9B%E7%9A%84%E4%BF%9D%E8%AF%81">2.7.1 GFS 提供的保证</a></li>
<li><a href="#272-%E4%B8%80%E8%87%B4%E6%80%A7%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%BA%94%E7%94%A8%E7%AB%AF%E5%AE%9E%E7%8E%B0">2.7.2 一致性模型在应用端实现</a></li>
</ul>
</li>
<li><a href="#28-%E7%B3%BB%E7%BB%9F%E4%BA%A4%E4%BA%92">2.8 系统交互</a></li>
<li><a href="#281-lease-%E5%92%8C-mutation-%E9%A1%BA%E5%BA%8F">2.8.1 lease 和 mutation 顺序</a><ul>
<li><a href="#282-%E6%95%B0%E6%8D%AE%E6%B5%81">2.8.2 数据流</a></li>
<li><a href="#283-%E5%8E%9F%E5%AD%90%E5%8C%96%E7%9A%84%E8%AE%B0%E5%BD%95%E8%BF%BD%E5%8A%A0%E6%93%8D%E4%BD%9C">2.8.3 原子化的记录追加操作</a></li>
</ul>
</li>
<li><a href="#29-snapshot-%E5%BF%AB%E7%85%A7">2.9 Snapshot 快照</a></li>
</ul>
</li>
<li><a href="#3-master-%E8%A1%8C%E4%B8%BA">3 Master 行为</a><ul>
<li><a href="#31-%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86%E5%92%8C%E9%94%81%E6%9C%BA%E5%88%B6">3.1 命名空间管理和锁机制</a></li>
<li><a href="#32-chunk-%E5%89%AF%E6%9C%AC%E5%B8%83%E5%B1%80">3.2 chunk 副本布局</a></li>
<li><a href="#33-%E5%89%AF%E6%9C%AC%E7%9A%84%E6%96%B0%E5%BB%BA-%E9%87%8D%E5%A4%8D%E5%88%B6%E4%B8%8E%E5%86%8D%E5%B9%B3%E8%A1%A1">3.3 副本的新建, 重复制与再平衡</a><ul>
<li><a href="#331-%E5%89%AF%E6%9C%AC%E6%96%B0%E5%BB%BA">3.3.1 副本新建</a></li>
<li><a href="#332-%E5%89%AF%E6%9C%AC%E9%87%8D%E5%A4%8D%E5%88%B6">3.3.2 副本重复制</a></li>
<li><a href="#333-%E5%89%AF%E6%9C%AC%E9%87%8D%E5%B9%B3%E8%A1%A1">3.3.3 副本重平衡</a></li>
</ul>
</li>
<li><a href="#34-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6">3.4 垃圾回收</a><ul>
<li><a href="#341-%E6%83%B0%E6%80%A7%E5%9B%9E%E6%94%B6">3.4.1 惰性回收</a></li>
<li><a href="#342-%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6">3.4.2 回收机制</a></li>
<li><a href="#343-%E5%87%A0%E7%82%B9%E8%AE%A8%E8%AE%BA">3.4.3 几点讨论</a></li>
</ul>
</li>
<li><a href="#35-%E8%BF%87%E6%9C%9F%E5%89%AF%E6%9C%AC%E6%A3%80%E6%B5%8B">3.5 过期副本检测</a></li>
</ul>
</li>
<li><a href="#4-%E5%AE%B9%E9%94%99%E4%B8%8E%E6%A3%80%E6%B5%8B">4 容错与检测</a><ul>
<li><a href="#41-%E9%AB%98%E5%8F%AF%E7%94%A8">4.1 高可用</a><ul>
<li><a href="#411-%E4%BF%9D%E6%8C%81%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84%E4%B8%A4%E4%B8%AA%E6%89%8B%E6%AE%B5">4.1.1 保持高可用的两个手段</a></li>
<li><a href="#master-%E5%A4%8D%E5%88%B6">Master 复制</a></li>
</ul>
</li>
<li><a href="#42-%E6%95%B0%E6%8D%AE%E5%AE%8C%E5%A4%87%E6%80%A7">4.2 数据完备性</a></li>
<li><a href="#43-%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7">4.3 诊断工具</a></li>
</ul>
</li>
<li><a href="#5-%E6%B5%8B%E9%87%8F">5 测量</a><ul>
<li><a href="#51-%E6%B5%8B%E9%87%8F%E7%94%A8%E7%9A%84%E5%BE%AE%E5%9F%BA%E5%87%86">5.1 测量用的微基准</a><ul>
<li><a href="#511-reads-%E6%B5%8B%E8%AF%95">5.1.1 reads 测试</a></li>
<li><a href="#512-writes-%E6%B5%8B%E8%AF%95">5.1.2 writes 测试</a></li>
<li><a href="#513-record-appends-%E6%B5%8B%E8%AF%95">5.1.3 record appends 测试</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->

<p>本文基于内部分享 &lt;”抄”能力养成系列 – GFS 设计&gt; 整理.</p>
<p>2003 年开始 Google 陆续放出三套系统的设计(GFS/MapReduce/Bigtable), 在互联网届掀起云计算狂潮一直影响至今. 该论文一出, 便催生了 Hadoop 中的 HDFS 的诞生. GFS 作为发轫, 目前许多业界知名的分布式系统设计仍然有着它的影子. 下面就让我们一起看看 GFS 的设计, 希望为各位后续系统研发提供灵感。(Salute to Jeff).</p>
<h1><span id="1-gfs-诞生背景">1 GFS 诞生背景</span></h1><ul>
<li>1, 组件失效是常态而非例外</li>
<li>2, 按传统标准, 现实世界的文件太大了, 一般都几个 GB, 个数多了单机存不下.</li>
<li>3, 大多数文件通过 append 而非覆盖进行修改, 所以追加操作是性能优化和需要原子保证的焦点.</li>
<li>4, 将上层应用和文件系统 API 联合设计可增加灵活性, 让整个系统都受益. 比如通过放松 GFS 的一致性要求以大规模简化文件系统还不给应用增加负担. 同时也引入了一个原子化的 append 操作以让多个客户端针对同一个文件并发执行 append 操作而无需额外的同步措施.</li>
</ul>
<h1><span id="2-gfs-设计概览">2 GFS 设计概览</span></h1><h2><span id="21-几点假设">2.1 几点假设</span></h2><ul>
<li>硬件便宜爱故障, 监控完善恢复快.</li>
<li>文件个数适中, 以大文件为主, 支持但不优化小文件存储(tradeoff).</li>
<li>负载主要是大数据量的流式读取和小数据量的随机读取, 后者可以合并重排减少随机.</li>
<li>另一个重要负载是大数据量顺序 append 数据到文件, 也支持随机写但没做优化, 文件一旦写完几乎不再修改.</li>
<li>设计良好且高效实现的单文件并发 append 操作. GFS 文件经常用于生产者消费者队列或多路合并.</li>
<li>持续稳定的高带宽比时延更加重要. 大多数应用更看重高吞吐而非某个读写操作的响应时间. (long-fat network)</li>
</ul>
<h2><span id="22-接口">2.2 接口</span></h2><ul>
<li>GFS 支持 create/delete/open/close/read/write 操作但不支持 POSIX 规范(GlusterFS 支持).</li>
<li>Snapshot: 就是以一个很低的消耗创建一个文件或者目录树的拷贝.</li>
<li>record append 操作: 允许多个客户端并发地向同一个文件追加数据, 每个追加操作都是原子的, 这为实现生产者-消费者队列或者多路合并提供了便利, 因为多个客户端同时写同一个文件无需加锁.</li>
</ul>
<h2><span id="23-架构">2.3 架构</span></h2><p>Figure 1 为 GFS 架构一览.</p>
<ul>
<li>一个 GFS 集群由 1 个 master 和多个 chunkserver 构成, 集群可同时被多个 client 访问.</li>
<li>Client 代表应用和 master 还有 chunkserver 通信.</li>
</ul>
<p><img src="/images/google-gfs-20201211/figure-1-GFS-Architecture.png" alt="Figure 1"></p>
<p>其中文件相关的有:</p>
<ul>
<li>文件被切成固定大小的 chunks(每个 chunk 还会被切成 blocks, 后述). </li>
<li>每个chunk 都有一个全局不可变的 64 bit 的 chunk handle, 这个 handle 由 master 在 chunk 创建时分配.</li>
<li>读写 chunk 时需要指定 handle 和字节范围.</li>
<li>为了高可用, 每个 chunk 会被在多个 chunkserver 上保存各保存一个副本, 默认三副本.</li>
</ul>
<p>master 相关的有:</p>
<ul>
<li>master 保存整个文件系统的元信息, 包括命名空间/访问控制信息/从 files 到 chunks 的映射/chunks 当前位置.</li>
<li>master 也控制系统层面的活动如 chunk 租约管理/孤儿 chunks 的垃圾回收/chunkservers 之间的 chunk 迁移.</li>
<li>master 和各个 chunkservers 通信(心跳)以发送指令和收集状态信息.</li>
</ul>
<p>client 和 chunkserver 都不会缓存文件数据:</p>
<ul>
<li>就 client 而言, 一方面原因是应用程序一般流式拉取巨大文件或者数据太大无法进行缓存, 另一方面因为无需处理缓存一致性问题可以简化 client 和整个系统的复杂度. </li>
<li>针对 chunkserver 而言, 因为数据本来就存在 chunkserver 本地磁盘, 可以直接使用 linux 的 buffer 来实现经常被访问的数据的缓存, 单机的缓存就交给单机操作系统来处理了.</li>
</ul>
<h2><span id="24-单-master-集群各组件交互重点">2.4 单 master 集群各组件交互重点</span></h2><p>注意, GFS 一个集群只有一个 Master(关于它的高可用后面描述).</p>
<ul>
<li>master 和 chunkserver 之间周期性的心跳交互.</li>
<li>client 读取时先问 master 数据存在哪个 chunkserver, 拿到信息后缓存到本地(有超时时间限制), 然后直接和 chunkserver 通信.</li>
<li>client 把上层应用指定的文件名和偏移量翻译成 chunk index, 发给 master.</li>
<li>master 返回 handle 和 location, client 用文件名和 index 做 key 缓存该信息.</li>
<li>直到元信息缓存失效或者应用重新打开文件, client 都无需和 master 交互, 而是直接和 chunkserver 交互. 这可以大幅降低 master 负载.</li>
</ul>
<h2><span id="25-chunk-大小设计">2.5 chunk 大小设计</span></h2><ul>
<li>chunk 大小非常关键, GFS 选的是 64MB. 比传统的文件块大多了. 采用 lazy space 分配策略, 可以避免如此大的 chunk size 导致的空间浪费.</li>
<li>每个 chunk 都作为一个普通的文件存储在 chunkserver.</li>
<li>chunk size 选的大有如下好处: <ul>
<li>1, 大幅减少了 client 和 master 的交互, 因为典型的应用就是顺序读取大文件, chunk 大则要访问的 chunks 就少, 就不用频繁与 master交互. client 侧可以为数 TB 数据集数据缓存它们对应的 chunk 元信息. </li>
<li>2, 因为 chunk 很大,可以覆盖很多操作, 这样 client 跟其所在 chunkserver 长时间维持一个持久 TCP 连接而无需频繁与多个 chunkserver 新建链接, 这就减少了网络开销.</li>
<li>3, 因为 chunk 很大, 个数就会减少, 则对应的元信息也相应减少, 这样 master 可以在内存缓存全部元信息.</li>
</ul>
</li>
<li>这么大的 chunk size 也有缺点, 就是对小文件不友好:<ul>
<li>因为一个小文件可能只对应一个 chunk, 如果针对小文件并发操作很多, 那么它就会成为热点(redis hotkey 与之类似.). </li>
<li>因为实际应用中以大文件读写为主所以问题不严重. </li>
<li>目前解决办法就是针对热点小文件提升其副本因子, 并且把访问该文件的客户端交错启动. 长远的解决办法是允许客户端能从其它客户端而不仅仅是从 chunkserver 读取同样的数据.</li>
</ul>
</li>
</ul>
<h2><span id="26-元信息">2.6 元信息</span></h2><p>master 保存三种类型的元信息:</p>
<ul>
<li>文件和 chunk 命名空间</li>
<li>file-to-chunk mapping</li>
<li>每个 chunk 副本的位置信息</li>
</ul>
<p>master 把全部元信息都保存在的内存中:</p>
<ul>
<li>前两种元信息会被 master 通过本地日志持久化变更同时备份到远程机器确保可用性.</li>
<li>chunk 位置信息不会被持久化, 而是在 master 启动以及 chunkserver 加入集群时询问 chunkserver 有关 chunk 的位置信息.</li>
</ul>
<p>chunkserver 保存的元信息有两个: 每个 block 的校验和, 以及 chunk 版本号.</p>
<p>在 master 上, 每个文件对应的元信息大约 100 字节, 这也符合 master 内存不会成为系统容量瓶颈的预期. 而且这 100 字节大部分是文件名(已经过前缀压缩). 其它元信息还有文件归属/权限, 从文件到 chunks 的映射, chunk 副本的位置信息, 每个 chunk 的当前版本. 针对 chunk 还会保存一个引用计数用于实现 COW(copy-on-write).</p>
<p>master 和 chunkserver 每个都保存大约 50 到 100 MB 数据, 加载非常快, 但是由于 master 启动时要拉取chunk location 所以启动需要额外 30 到 60 秒.</p>
<p>自从 master 内存结构改成二叉搜索树以后, 命名空间搜索不再是瓶颈.</p>
<h3><span id="261-元信息都保存在内存中">2.6.1 元信息都保存在内存中</span></h3><p>master 把元信息存在内存, 操作就会很快.</p>
<p>master 可以在后台高效地周期性扫描整个状态空间以实现:</p>
<ul>
<li>chunk GC, </li>
<li>应对 chunkserver 失效重新分配副本, </li>
<li>为实现负载和磁盘空间均衡在 chunkservers 间迁移 chunks.</li>
</ul>
<p>master 把全部信息保存到内存有个不好的地方就是集群数据量受限于 master 内存大小.  不过因为每个 chunk(64MB 大) 对应元信息不超过 64 字节, 所以实践中不是啥问题.</p>
<p>大多数 chunks 都是满的因为大多数文件各自都包含多个 chunks, 可能仅每个文件对应的最后一个 chunk 不满, 这就让元信息性价比非常高. </p>
<p>同样, 针对每个文件, 它的文件命名空间数据也不超过 64 字节, 因为其存储的文件名通过使用前缀压缩非常紧凑.</p>
<p>当然, 想支持更大的数据集合, 给 master 加内存就行了, 便宜又快捷.</p>
<h3><span id="262-chunk-位置信息">2.6.2 chunk 位置信息</span></h3><p>虽然 master 不持久化 chunk 位置信息, 但是因为它负责 chunks 布局同时通过心跳监控 chunkserver, 所以它能保持这些位置信息时刻保持更新.</p>
<p>其实我们开始也尝试持久化 chunk 位置信息, 后来发现还是 master 启动后周期性拉取更简单.  这消除了因为 chunkserver 加入或离开集群/改名/失效/重启等等而保持 master 和 chunkservers 数据同步的问题.</p>
<h3><span id="263-操作日志">2.6.3 操作日志</span></h3><p>master 上的操作日志包含了关键元信息的变更历史.  这对 GFS来说至关重要. </p>
<p>这个日志作为逻辑时间线定义了并发操作的顺序. 文件和 chunks 以及它们的版本号, 可以永久通过它们被创建的逻辑时间被唯一识别.</p>
<p>元信息变更被持久化到本地和远程多台机器后, 相关变更才对客户端可见.</p>
<p>master 启动时会读取操作日志并进行重放以恢复系统状态, 所以操作日志不能太大否则启动时间会非常长.</p>
<p>为了避免日志文件过大, master 会在日志文件超过一定大小后 checkpoint 自己当前状态, 这样下次启动时只需从本地磁盘加载和重放最近一次 checkpoint 就可以恢复到最新状态.</p>
<p>因为构造 checkpoint 需要花时间, 为了避免阻塞后续处理, 方法如下: </p>
<ul>
<li>master 切换到新的日志文件并在一个单独的线程中创建 checkpoint. </li>
<li>新的 checkpoint 包含日志切换前的全部变更.</li>
<li>大约一分钟左右就可以为一个拥有几百万文件的集群创建一个 checkpoint.</li>
<li>创建完成后它将被写入本地和远程磁盘.</li>
</ul>
<p>master 恢复过程只需最近的 checkpoint 和创建该 checkpoint 后的日志文件. 老的 checkpoints 和日志文件都会被删除.</p>
<h2><span id="27-gfs-的一致性模型">2.7 GFS 的一致性模型</span></h2><p>GFS 提供了一个弱一致性模型, 相对简单且容易高效实现.</p>
<h3><span id="271-gfs-提供的保证">2.7.1 GFS 提供的保证</span></h3><p>文件命名空间变更, 如创建文件, 是原子的. 它们均仅由 master 处理.  master 的操作日志为这些操作定义了全局顺序. </p>
<p><strong>consistent</strong>: 针对某个文件区域, 如果全部客户端看到的数据是一致的, 不管它们是从哪个副本读取的数据, 我们就说这个文件区域数据是一致的.</p>
<p><strong>defined</strong>: 针对经历过数据变更的某个文件区域, 如果它是 consistent 的, 并且客户端能看到前述变更的完整内容, 即可预测, 不会因并发而随机那么我们就说这个文件区域是确定的.</p>
<p>注意, defined 和 consistent 是两个层面的东西, 只要写成功, 那么 GFS 的 2PC 能保证 consistent, 也就是 defined 包含了 consistent.  但如果发生了并发变更, 比如多个客户端针对某个文件区域同一个偏移并发写,  此时不同于追加, 这种写操作是互相覆盖的, 最终结果是 undefined 的, 即我们无法预先知晓该偏移处结果是什么, 但 GFS 可以保证各个副本都是同样的 undefined 状态.</p>
<p><img src="/images/google-gfs-20201211/table-1-%E5%8F%98%E6%9B%B4%E5%90%8E%E7%9A%84%E6%96%87%E4%BB%B6%E5%8C%BA%E5%9F%9F%E7%8A%B6%E6%80%81.png" alt="Table 1"></p>
<p>上面 Table 1 展示了 GFS 两种典型的变更操作 write(覆盖写) 和 record append(记录追加)在串行和并发情况下完成后对应的文件区域的状态.</p>
<p>数据变更包括 write(在指定偏移处写入, 如覆盖写)和 record append(即在文件尾部原子地追加记录).</p>
<p>GFS 会保证一系列成功变更后的文件是 defined 的, 措施如下:</p>
<ul>
<li>1, 以同样的顺序将变更应用到 chunk 全部副本.</li>
<li>2, 使用 chunk 版本号来检测过期的副本, 相关 chunkserver可能因为下过线错过某些变更.</li>
</ul>
<p>过期副本不会对外服务而是会被尽快 GC 掉.</p>
<p>master 借助心跳计算每个chunkserver 上数据的校验和以检测数据是否损坏.发现损坏后会尽快从好的副本恢复数据.</p>
<p>如果全部副本丢失, 那么chunk 就不可恢复了. 这种情况下应用得到的响应是数据丢失而非损坏.</p>
<h3><span id="272-一致性模型在应用端实现">2.7.2 一致性模型在应用端实现</span></h3><p>写</p>
<ul>
<li>依赖于追加而非覆写(相比于覆写, 追加更加高效同时对应用错误更富有弹性), 应用程序一般就是一个文件从头 append 到尾;</li>
<li>要么等数据写完后原子地将文件重命名为一个永久性的名字, 要么周期性地 checkpoint 写了多少字节了同时还可以附加一个应用层校验和. </li>
<li>checkpoint 让 writers 可以在重启后增量写入而不用重写全部数据, 同时避免 readers 处理已成功写入但不完整的内容(站在应用层角度).</li>
</ul>
<p>读</p>
<ul>
<li>只验证和处理最后一个 checkpoint 之前的文件区域, 这些区域处于 defined 状态.</li>
</ul>
<p>record-append 操作的 append-at-least-once 语义确保了不丢数据, 然后由 readers 负责处理重复数据.</p>
<p>由于 record 包含了一个附加的校验和, 所以 readers 可以此校验 records. </p>
<p>readers 还可以通过每个记录的唯一 ID 过滤掉重复的 records.</p>
<h2><span id="28-系统交互">2.8 系统交互</span></h2><p>GFS 在设计的时候就在尽量做到最小化 master 参与各种操作, 给 master 减负.</p>
<p>下面描述 client/master/chunkserver 三者之间如何交互以实现数据变更/原子化记录追加/快照.</p>
<h2><span id="281-lease-和-mutation-顺序">2.8.1 lease 和 mutation 顺序</span></h2><p>chunk 的每个变更都会反映到每个副本上, 具体如下:</p>
<ul>
<li>master 通过选择一个副本颁发一个 lease 将其指定为 primary.</li>
<li>然后 primary 为 chunk 的并发变更选择一个串行的顺序, 全部副本都遵循该顺序应用变更. </li>
<li>因此全局变更顺序首先由 master 授权 lease 的顺序以及每个 lease 生效期 primary 指定序列号时确定. </li>
</ul>
<p>lease 机制可以最小化 master 的管理开销, 因为针对 chunk 的一部分管理工作让 primary 承担了.</p>
<p>每个 lease 都有一个初始的 60 秒超时, 但是只要 chunk 仍在变更, primary 可以发送请求给 master 要求延长 lease 有效期, 这个过程是通过 heartbeat 实现的.</p>
<p>当然 master 可以在 lease 过期之前吊销它, 比如当 mast 想禁止对正在改名的文件进行变更时. 当 master 失去与primary 通信时, master 可以授权新的 lease 给另一个副本.</p>
<p><img src="/images/google-gfs-20201211/figure-2-write-control-and-data-flow.png" alt="Figure 2"></p>
<p>Figure 2 为执行写操作时的控制流, 具体如下:</p>
<ul>
<li>1, client 询问 master 哪个 chunkserver 持有要访问的 chunk 的 lease 以及其它副本的位置. 如果没人持有 lease, master 会选一个副本授权之.</li>
<li>2, master 返回 primary 的 id 以及和其它副本的位置, client 会缓存这些信息, 仅当 primary 不可用或者 primary 明确告知不再持有 lease 时再和 master 通信.</li>
<li>3, client 以任意顺序将数据推给全部副本. 每个 chunkserver 将数据首先保存到内部的 LRU 缓存.  图中将控制流和数据流解耦, 基于网络拓扑(该拓扑不关心谁是 primary)调度数据流可以改善性能, 具体后述.</li>
<li>4, 当全部副本确认收到数据后, client 再发送一个写请求给 primary,该请求标记了上一步推送给全部副本的数据, primary 会为(可能来自多个 clients 的)全部变更分配连续的序列号,然后 primary 按照此顺序应用这些变更.</li>
<li>5, 应用本次变更后, primary 将该写请求转发给全部 secondary 副本,这些副本以同样的顺序应用变更.</li>
<li>6, secondary 副本回复 primary 自己已完成操作.</li>
<li>7, primary 回复 client 本次写操作成功 or 失败. 如果只有 primary 和部分 secondary 成功, 则再返回第一步重试之前会尝试重复 3-7.</li>
</ul>
<p><strong>从 3 到 7 其实就是 2PC (two-phase commit).</strong></p>
<p>如果一个写操作跨多个 chunk, 那么客户端就会将这个写操作分裂成多个写操作. 它们都按照前面描述的步骤执行, 但是可能和其它客户端的写操作交织在一起并发执行. 因此同一个文件区域可能被多个客户端相互覆盖写入. 尽管这个文件区域的全部副本最终是 consistent, 但是最终结果我们无法预知是什么, 所以最终是 consistent 但 undefined.</p>
<h3><span id="282-数据流">2.8.2 数据流</span></h3><p>将数据流和控制流解耦, 让我们可以更高效地利用网络. 下面看看 GFS 是怎么做的.</p>
<p>就像控制流是从 client-&gt;primary-&gt;secondaries 管道化传输, 数据流从 client 到各个 replicas 也是管道化传输.</p>
<p>具体地, client 挑选离自己最近的 chunkserver (注意这里根本不管谁是 primary, 只关注网络拓扑), 将数据发给它, 然后</p>
<p>这个  chunk server 一边接收 client 的数据一边转发给离自己最近的 chunkserver, 依此类推  …  从而链式完成数据从 client 到每个副本所在 chunkserver  的发送. </p>
<p>最近距离计算: 这个管道化传输过程中, 各个节点通过 IP 地址计算前面提到的 “最近”距离的计算, 比如同一个局域网跟定比跨网段的要更近一些. </p>
<p>管道化传输好处: 这种管道化传输尽可能地利用了每个 chunkserver  的出站带宽, 也最小化了 TCP 连接的时延.</p>
<h3><span id="283-原子化的记录追加操作">2.8.3 原子化的记录追加操作</span></h3><p>传统的写操作, 需要指定要写入到的文件偏移量. 并发执行该类操作写同样的区域并不是串行化的, 被写入区域最后状态包含多个客户端的数据片段.</p>
<p>GFS 提供了原子化追加操作, 叫 record append, GFS 会确保至少一次写的语义, 将数据原子化地追加到文件末尾. 这类似于在 unix 编程中, 采用 O_APPEND 模式打开文件而且没有竟态条件.</p>
<p>record append 作为一种 mutation, 执行流程同 Figure 2, 但在 primary 那有些许不同: </p>
<ul>
<li>1, 首先 client 肯定是将数据 push 给文件的最后一个 chunk(因为是 appende 嘛).</li>
<li>2, primary 检查追加这个记录后 chunk 是否超过 64MB,<ul>
<li>2.1, 如果超过, 则将这个chunk 填满无效数据, 同时告诉 secondaries 也这么干, 然后告诉客户端说满了, 请将数据写入下个chunk. 为了避免产生过多这类因填充导致的空间碎片, 我们要求 record 大小最多为 chunk 的四分之一.</li>
<li>2.2, 如果不超过, primary 将数据写入本地副本,然后告知secondaries 将数据写入到同样的偏移处, 然后响应客户端. </li>
</ul>
</li>
<li>上述过程, 在任何副本写失败, 客户端就要重试该写入操作. 当然,这个重试会导致 chunk 不同副本数据不一致, 但是 GFS 保证的不是字节级别的一致性, 而是记录级别的, 它保证至少一次 append, 就能保证各副本数据一致, 虽然重复记录但是可以通过 id 去重.</li>
</ul>
<h2><span id="29-snapshot-快照">2.9 Snapshot 快照</span></h2><p>snapshot 操作用于制作当前文件和目录的快照, 速度非常快.</p>
<p>snapshot 用的是 COW (copy-on-write) 技术实现, 具体如下: </p>
<ul>
<li>当master 收到 snapshot 请求时, 它首先吊销要进行 snapshot 的文件相关 chunks 的 lease, 这样后续针对这些 chunks 的写操作强迫 client 先和 master 交互, 这就为创建快照争取了时间.</li>
<li>lease 吊销后, master 将 snapshot 操作记录到日志中, 然后将其应用到内存状态上制作快照.</li>
<li>新创建的 snapshot 文件指向源文件同样的 chunks, 计数加一. 此时如果客户端要写这些 chunks, master 就会察觉引用计数大于 1, 此时触发 COW 操作.</li>
<li>COW 过程: <ul>
<li>master 指示每个拥有 chunk C 副本的 chunkserver 都新建一个 chunk C‘, 而且 C’ 创建在同 C 一样的 server 上, 这可以使得 COW 在本地而非通过网络进行.</li>
<li>创建完 C‘ 并拷贝完数据后, 集群就有两组一样的 chunk 副本了, 剩下的处理流程就同之前一样了, master 针对 C’ 授权 lease 给某个副本并响应客户端, 客户端开始写入数据.</li>
</ul>
</li>
</ul>
<h1><span id="3-master-行为">3 Master 行为</span></h1><p>Master 执行全部和命名空间有关的操作. </p>
<p>另外, master 管理着整个系统的 chunk 复制: </p>
<ul>
<li>chunk 布局决策</li>
<li>创建新 chunks 和其副本</li>
<li>协调多种系统级别的活动以保障 chunks 副本健全, 各个 chunkserver 的负载均衡, 回收未使用的存储空间</li>
</ul>
<p>下面挨个讨论上述话题.</p>
<h2><span id="31-命名空间管理和锁机制">3.1 命名空间管理和锁机制</span></h2><p>GFS 允许多个操作并发, 通过锁来将其串行化.</p>
<ul>
<li>读锁, 防止目标被删除/重命名/snapshotted;</li>
<li>写锁, 防止并发创建同名目标文件.</li>
</ul>
<p>同 Unix 不同, GFS 没有为每个目录设计一个保存其文件列表的数据结构.</p>
<p>GFS 的命名空间可以看作一个速查表, 保存了从全路径名(文件名或目录名, 可以看作一个前缀树)到元数据的映射. </p>
<ul>
<li>通过前缀压缩, 可以使得整个表被保存到内存中. </li>
<li>命名空间树上面的每个节点都关联了一个读写锁.</li>
</ul>
<p>由于没有真正的目录结构, 所以这使得我们可以并发地在同一个目录下创建文件, 只要获取这个所谓的目录的读锁(防止目标被修改)同时获取目标文件的写锁(防止在同一个目录下生成同名文件)即可.</p>
<p>为避免死锁, 加锁顺序全局一致: 先按照命名空间树不同层次对锁排序, 如果在同一层则按照字典序对锁排序.</p>
<h2><span id="32-chunk-副本布局">3.2 chunk 副本布局</span></h2><p>GFS 的分布式体现了多个层次:</p>
<ul>
<li>1, 首先 GFS 集群一般涉及上百台 chunkservers</li>
<li>2, 这些 chunkservers 一般分布在多个机架.</li>
</ul>
<p>所以同一个 chunk 的副本布局不但要考虑多 chunkservers 还要考虑这些 chunkservers 不能集中在同一个机架, 这么做就为了实现: </p>
<ul>
<li>可靠性</li>
<li>可用性</li>
<li>最大化网络带宽使用率(机架进出带宽可能小于这个机架上的全部机器各自网卡带宽加总.), 比如热点副本集中到同一个 chunkserver 或者同一个机架, 并发读写就会出现瓶颈, 这在后面测量部分会再细述.</li>
</ul>
<h2><span id="33-副本的新建-重复制与再平衡">3.3 副本的新建, 重复制与再平衡</span></h2><h3><span id="331-副本新建">3.3.1 副本新建</span></h3><p>三种情况下新建副本:</p>
<ul>
<li>1, 新建 chunk 时</li>
<li>2, 重复制</li>
<li>3, 重平衡</li>
</ul>
<p>新建 chunk 时新副本安置在哪儿, 主要考虑下面几点: </p>
<ul>
<li>1, 尽量把新副本放在磁盘使用率低于平均水平的 chunkserver 上, 这样各个机器会逐渐平均.</li>
<li>2, 虽然副本创建操作本身消耗不多, 但它预示着大量的写流量即将到达. 所以新建副本时会尽量让每个 chunkserver 近期的副本(不区分 chunk)新建数尽量的差不多, 避免写流量涌入少数 chunkserver.</li>
<li>3, 就像前一节讨论的, 让副本尽量分布在多个机架上.</li>
</ul>
<h3><span id="332-副本重复制">3.3.2 副本重复制</span></h3><p>当 chunk 副本因子低于设定时, master 就会触发重复制. </p>
<p>如果有多个 chunk 满足条件, 则执行优先级就是:</p>
<ul>
<li>1, 哪个 chunk 距离目标副本因子越远就谁优先重复制;</li>
<li>2, 还有就是活跃的文件 chunks 优先级高于被删除文件的 chunks.</li>
<li>3, 另外就是优先那些当前阻塞住客户端的 chunks.</li>
</ul>
<p>重复制后的副本放到哪个 chunkserver, 原则同副本新建所描述: </p>
<ul>
<li>1, 让每个磁盘空间使用率尽量相同; </li>
<li>2, 限制同一个 chunkserver 上同时活跃的 clone 操作; </li>
<li>3, 另副本尽量分散到各个机架. </li>
</ul>
<p>为了避免副本 clone 流量压倒客户端流量, master 会限制同时活跃的 clone操作个数.  同时, 每个 chunkserver 会限制自己用于 clone 的带宽, 方法就是限制自己到其它源 chunkserver 的读请求数目.</p>
<h3><span id="333-副本重平衡">3.3.3 副本重平衡</span></h3><p>master 会为了更好的磁盘使用率和负载均衡而周期性地做副本 rebalance.</p>
<p>master 做 rebalance 时布局标准同重复制. </p>
<p>rebalance 选择要移除哪个 chunkserver 的副本时倾向于那些空闲空间低于平均值的 chunkserver, 目的也是最终拉平各个 chunkserver 的磁盘使用.</p>
<h2><span id="34-垃圾回收">3.4 垃圾回收</span></h2><h3><span id="341-惰性回收">3.4.1 惰性回收</span></h3><p>一个文件被删除后, GFS 不会立即回收它所占用地物理空间, 而是通过周期性地 GC 在文件和 chunk 两个层次进行惰性回收.  我们发现这么做使得整个系统更加简单也更加可靠.</p>
<h3><span id="342-回收机制">3.4.2 回收机制</span></h3><p>文件层面:</p>
<ul>
<li>同其他操作, 删除操作会先记录到 master 日志. </li>
<li>然后被删除文件被标记为包含删除时间戳的隐藏名. </li>
<li>master 周期性扫描文件系统命名空间时移除那些被标记超过三天(可配置)的文件. 真正移除之前这些文件仍可读, 甚至可以将名字改成正常名字表示不再删除. </li>
<li>当隐藏文件被移除后, 它对应的内存中的元数据也会被擦除, 这相当于断开了这个文件同其 chunks 的连接.</li>
</ul>
<p>Chunk 层面:</p>
<ul>
<li>同样地, 针对 chunk 命名空间的周期性扫描, master 会将从任何文件都不可达的 chunks 标记为孤儿 chunks. </li>
<li>chunkserver 在和 master 周期性的心跳消息中上报自己持有的 chunks, master 会回复那些不再存在的 chunks 标识, chunkserver 收到后自主删除这些 chunks 对应的副本.</li>
</ul>
<h3><span id="343-几点讨论">3.4.3 几点讨论</span></h3><p>虽然在编程语言中, 分布式垃圾回收非常难, 但是针对 GFS 却很简单:</p>
<ul>
<li>我们可以很容易地识别到 chunks 的引用: 它们就在 file-to-chunk mappings 中, 这些信息由 master 专门维护. </li>
<li>我们也可以很容易识别全部 chunk 副本: 它们就是 chunkserver 指定目录下的 linux 文件. 这些副本对 master 来说都不是垃圾.</li>
</ul>
<p>GC 相比 eager deletion 的好处: </p>
<ul>
<li>1, 在组件容易故障的分布式系统中更简单可靠. 如果发删除消息则可能丢失, 需要重发送, 维护起来很复杂. GC 提供了统一可靠的清理不再有用的副本的方式. </li>
<li>2, 将 GC 纳入到周期性后台任务(其它还有命名空间扫描和心跳), 批量处理摊销了消耗. 而且这种后台任务仅当 master 相对空闲时候才做可以保证对客户端的响应. </li>
<li>3, GC 的惰性也避免了因误删除(意外且不可逆)导致的数据安全问题.</li>
<li>最大的缺点: 不能在存储紧张时候及时回收. 但 GFS 支持连续两次删除立即回收空间.</li>
</ul>
<p>另外, GFS 支持为不同的命名空间指定副本策略(如副本因子)和删除策略.</p>
<h2><span id="35-过期副本检测">3.5 过期副本检测</span></h2><p>chunkserver 挂掉或者下线就会导致其上的 chunks 过期.</p>
<p>master 维护着一个 chunk 版本号来识别最新和过期副本. </p>
<p>master 授权一个新的 lease 时就会递增 chunk 版本号并通知其它副本, 并且 master 和这些副本会持久化这个版本号. 当某个副本挂掉重启后, 它会上报自己的 chunks 和版本号给 master, master就能检测到过期.</p>
<p>如果 master 发现有版本号比自己记录的还要大, 则认为自己授权 lease 时候出错并将该版本号作为最新版本号. </p>
<p>master 在响应客户端哪个 chunkserver 持有它所请求的 chunk 时会在响应中包含版本号以让客户端进行校验; master 在指示某个 chunkserver 去另一个 chunkserver 拷贝数据时也会告诉它当前的版本号, 供其校验.</p>
<h1><span id="4-容错与检测">4 容错与检测</span></h1><p>设计这个系统最大的挑战时应对频繁的组件失效.</p>
<h2><span id="41-高可用">4.1 高可用</span></h2><h3><span id="411-保持高可用的两个手段">4.1.1 保持高可用的两个手段</span></h3><ul>
<li>1, 快速恢复,不管之前如何下线的, master 和 chunkservers  可以几秒内即可重启并恢复数据.</li>
<li>2, 多副本, 默认三副本.</li>
</ul>
<h3><span id="master-复制">Master 复制</span></h3><p>master 的操作日志和 checkpoint 会被保存到多台机器. 一个更新操作仅当其被记录到 master 本地和远程机器上才算被提交.</p>
<p>master 挂了, 监控系统会立即在其它机器上启动一个 master 并快速从日志恢复状态. clients 用的是域名访问 master, 所以可以快速感知这个变化.</p>
<p>另外 GFS 还提供了影子 masters, 它们只提供了读操作, 而且数据可能会稍微落后 primary master 一秒. 针对那些不怎么变动的文件或者应用不太在乎稍微过期的数据的时候, 这些影子 masters 可以为 primary master 分担一些读请求. 影子 masters 会拉取日志副本并应用保持自己更新, 而且它们也会在启动时查询 chunkservers 获取 chunk 副本位置信息(因为这些信息不会被持久化到日志只能自己去主动去查), 也和 chunkservers 保持心跳交换信息以监控它们的状态. 当然副本布局/删除等等变更操作还是由 primary master 负责, 影子 masters 只读.</p>
<h2><span id="42-数据完备性">4.2 数据完备性</span></h2><p>chunkserver 靠<strong>校验和</strong>来检测数据是否损坏, 而不是靠比对各个副本,那不太可行.</p>
<p>每个 chunk 被切分成多个 64KB 大小的 blocks. 每个 block 都有一个对应的 32 bit 校验和. 校验和也会被保存到内存中同时会和日志一起持久化.</p>
<p>chunkserver 响应请求者数据之前会计算校验和(有点性能消耗)并和存储的校验和比对, 如果不一致则响应错误并上报给 master, 请求者会去其它副本读数据, 同时 master 会指示 chunkserver去从其他副本恢复数据, 然后删掉损坏的副本.</p>
<p>空闲时, chunkserver 会扫描和校验不活跃的 chunks, 检测损坏的 chunks 并上报.  master 就会指示创建新的 chunks 并删除损坏的 chunks.</p>
<h2><span id="43-诊断工具">4.3 诊断工具</span></h2><p>诊断问题只能<strong>靠日志</strong>, GFS 诊断日志记录了 chunkserver 上下线等重大事件和全部 RPC 请求响应.</p>
<p>可以通过日志来重建完整的交互历史来诊断问题.</p>
<p>日志的开销很小, 尤其和得到的好处比起来.</p>
<h1><span id="5-测量">5 测量</span></h1><p>接下来, 我们看看 GFS 架构和实现中的瓶颈, 以及真实集群中的若干数字.</p>
<p>注意, 这都是 2003 年的数据, 我们要观察的是 GFS 这么大系统的度量方法以及它如何在当年那种相比现在硬件条件那么差的情况下发挥其价值的.</p>
<h2><span id="51-测量用的微基准">5.1 测量用的微基准</span></h2><p>测试集群由 1 master, 2 master replicas, 16 chunkservers, 16 clients 构成. 这么搭就为了方便测试, 真实的集群有几百个 chunkservers 和几百个 clients 构成.</p>
<p>所有机器都是双核 1.4GHz, 2GB 内存, 两个每分钟 5400 转的 80GB 磁盘, 一个 100Mbps 的全双工以太网. master 和 chunkserver 共 19 台机器都连接到同一个 HP 2524 交换机上, 16 个 clients 连接到另一个交换机上, 两个交换机通过 1Gbps 链路连接.</p>
<h3><span id="511-reads-测试">5.1.1 reads 测试</span></h3><p>N 个 clients 同时从系统读写. 每个 client  从一个 320GB 的文件集合中读取一个随机选择的 4MB 区域. 全部 chunkservers 共 32GB 内存, 所以我们期待最多可以有 10% 的几率命中 linux buffer cache.</p>
<p><img src="/images/google-gfs-20201211/figure-3-a-reads-%E6%B5%8B%E8%AF%95.png" alt="Figure 3-a"></p>
<p>Figure 3.a 显示 N 个 clients 的读取速率聚合以及它的理论上限. </p>
<ul>
<li>当两个交换机之间的 1Gbps 跑满的时候达到理论上限 125MB/s; 当每个 client 的 100Mbps 跑满时, 单个 client 机器达到理论上限 12.5MB/s.</li>
<li>当仅有一个 client 读取时, 观察到的读取速率为 10MB/s, 大约是每个 client 上限的 80%(即 10/12.5).</li>
<li>当 16 个 clients 一起读取时, 观察到的聚合读取速率为 94MB/s, 大约为理论上限的 75%(即 94/125); 或者 每个 client 大约 6MB/s.</li>
<li>从 80% 降到 75% 的原因是: 当读取客户端变多, 多个客户端同时从同一个 chunkserver 读取的概率也变大, 从而导致 chunkserver 的网卡带宽被多个客户端争用的更厉害了.</li>
</ul>
<h3><span id="512-writes-测试">5.1.2 writes 测试</span></h3><p>N 个 clients 同时写多个 N 个不同的文件. </p>
<p><img src="/images/google-gfs-20201211/figure-3-b-writes-%E6%B5%8B%E8%AF%95.png" alt="Figure 3-b"></p>
<p>每个 client 写 1GB 数据到一个新文件, 每次写入 1MB. 聚合写入速率和理论上限如 3.b 所示.</p>
<ul>
<li>理论上限为 67MB/s, 因为我们需要将每个字节写到 16 个 chunkservers 中的 3 个里, 每个 chunkserver 入口带宽上限为 12.5MB/s.</li>
<li>如果单个 client 写入, 则观察到的写入速率为 6.3MB/s, 大约是上限的一半. 罪魁祸首是网络协议栈, 因为它与我们把数据 push 给 chunk 副本的管道化方案不太搭配. 数据从一个副本传播给另一个副本延迟降低了整体的写入速率.</li>
<li>如果是 16 个 clients 一起写入, 观察到的聚合写入速率为 35MB/s(每个 client 平均 2.2MB/s), 大约是理论上限的一半(即 35/67). 就像读取测试中, 随着执行写操作的 clients 增多, 则同一个 chunkserver 被多个 clients 并发写的几率增大, 此 chunkserver 的入口带宽被更多 clients 争用, 而且 16 个 clients 的写要比读竞争更激烈, 因为一个字节要写到三个 chunkserver. </li>
</ul>
<h3><span id="513-record-appends-测试">5.1.3 record appends 测试</span></h3><p>N 个 clients 同时从系统读写. 每个 client  从一个 320GB 的文件集合中读取一个随机选择的 4MB 区域. 全部 chunkservers 共 32GB 内存, 所以我们期待最多可以有 10% 的几率命中 linux buffer cache.</p>
<p><img src="/images/google-gfs-20201211/figure-3-c-record-appends-%E6%B5%8B%E8%AF%95.png" alt="Figure 3-c"></p>
<p>Figure 3.c 显示了记录追加操作的性能. N 个 clients 同时向同一个文件追加.<br>性能被存储最后一个 chunk 的 chunkservers 的网络带宽限制住了, 与 clients 个数无关.<br>当只有一个 client 写入时, 速率为 6.0MB/s, 当 16 个 clients 一起写入时, 速率降到了 4.8MB/s, 主要原因是网络拥塞和抖动.<br>实际使用中, 我们的应用程序倾向于并发生成若干前述文件而不是一个. 换句话说, N 个 clients 同时向 M 个共享文件追加, N 和 M 都是几千级别的. 因此前面提到的网络拥塞在实际中不是啥大问题, 因为 client 写入一个 chunkserver 时, 当一个文件忙的时候, 可以写另一个文件.</p>
<p>–End–</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://chienlungcheung.github.io/2020/12/05/Gorilla-%E4%B8%80%E4%B8%AA%E5%BF%AB%E9%80%9F-%E5%8F%AF%E6%89%A9%E5%B1%95%E7%9A%84-%E5%86%85%E5%AD%98%E5%BC%8F%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E5%BA%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chienlung Cheung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="programatrix">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/05/Gorilla-%E4%B8%80%E4%B8%AA%E5%BF%AB%E9%80%9F-%E5%8F%AF%E6%89%A9%E5%B1%95%E7%9A%84-%E5%86%85%E5%AD%98%E5%BC%8F%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E5%BA%93/" class="post-title-link" itemprop="url">Gorilla: 一个快速, 可扩展的, 内存式时序数据库</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-12-05 10:19:30" itemprop="dateCreated datePublished" datetime="2020-12-05T10:19:30+00:00">2020-12-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-03 09:19:19" itemprop="dateModified" datetime="2021-03-03T09:19:19+00:00">2021-03-03</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/12/05/Gorilla-%E4%B8%80%E4%B8%AA%E5%BF%AB%E9%80%9F-%E5%8F%AF%E6%89%A9%E5%B1%95%E7%9A%84-%E5%86%85%E5%AD%98%E5%BC%8F%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E5%BA%93/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/12/05/Gorilla-一个快速-可扩展的-内存式时序数据库/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <!-- toc -->

<ul>
<li><a href="#1-gorilla-%E8%AF%9E%E7%94%9F%E8%83%8C%E6%99%AF">1 Gorilla 诞生背景</a></li>
<li><a href="#2-gorilla-%E7%AE%80%E4%BB%8B">2 Gorilla 简介</a><ul>
<li><a href="#21-%E9%9C%80%E8%A6%81%E6%BB%A1%E8%B6%B3%E7%9A%84%E5%87%A0%E4%B8%AA%E9%99%90%E5%88%B6">2.1 需要满足的几个限制</a></li>
<li><a href="#22-%E7%8E%B0%E7%8A%B6%E6%B3%A8-2015">2.2 现状(注: 2015)</a></li>
<li><a href="#23-%E5%B7%B2%E6%9C%89%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98">2.3 已有监控系统的查询性能问题</a></li>
</ul>
</li>
<li><a href="#3-gorilla-%E7%9A%84%E8%AE%BE%E8%AE%A1%E7%9B%AE%E6%A0%87">3 Gorilla 的设计目标</a></li>
<li><a href="#4-gorilla-%E4%B8%8E%E7%8E%B0%E6%9C%89%E7%9A%84-tsdb-%E6%AF%94%E8%BE%83%E6%B3%A82015%E5%B9%B4">4 Gorilla 与现有的 TSDB 比较(注:2015年)</a><ul>
<li><a href="#41-opentsdb">4.1 OpenTSDB</a></li>
<li><a href="#42-whipergraphite">4.2 Whiper(Graphite)</a></li>
<li><a href="#43-influxdb">4.3 InfluxDB</a></li>
</ul>
</li>
<li><a href="#5-gorilla-%E6%9E%B6%E6%9E%84">5 Gorilla 架构</a><ul>
<li><a href="#51-%E6%A6%82%E5%86%B5">5.1 概况</a></li>
<li><a href="#52-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%8E%8B%E7%BC%A9">5.2 时间序列压缩</a><ul>
<li><a href="#521-%E6%97%B6%E9%97%B4%E6%88%B3%E5%8E%8B%E7%BC%A9">5.2.1 时间戳压缩</a></li>
<li><a href="#522-%E6%B5%8B%E9%87%8F%E5%80%BC%E5%8E%8B%E7%BC%A9">5.2.2 测量值压缩</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#6-gorilla-%E7%9A%84%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">6 Gorilla 的内存数据结构</a><ul>
<li><a href="#61-tsmap">6.1 TSmap</a><ul>
<li><a href="#611-tsmap-%E7%94%B1%E4%B8%A4%E9%83%A8%E5%88%86%E6%9E%84%E6%88%90">6.1.1 TSmap 由两部分构成</a></li>
<li><a href="#612-tsmap-%E7%9A%84%E5%B9%B6%E5%8F%91%E4%B8%8E%E6%80%A7%E8%83%BD">6.1.2 TSmap 的并发与性能</a></li>
</ul>
</li>
<li><a href="#62-shardmap">6.2 ShardMap</a></li>
<li><a href="#63-ts">6.3 TS</a></li>
</ul>
</li>
<li><a href="#7-gorilla-%E7%9A%84%E7%A3%81%E7%9B%98%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84">7 Gorilla 的磁盘存储结构</a></li>
<li><a href="#8-gorilla-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8">8 Gorilla 如何实现高可用</a></li>
<li><a href="#9-gorilla-%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%96%B0%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7">9 Gorilla 带来的新分析工具</a><ul>
<li><a href="#91-%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90%E5%BC%95%E6%93%8E">9.1 关联分析引擎</a></li>
<li><a href="#92-%E9%99%8D%E9%87%87%E6%A0%B7">9.2 降采样</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

<p>本文基于内部分享 &lt;”抄”能力养成系列 – Gorilla 的设计和实现&gt; 整理.</p>
<p>Gorilla 是 Facebook 于 2015 年开放的一个快速, 可扩展的, 内存式时序数据库. 它的一些设计理念影响了后来的 Prometheus. 本文就其设计和实现进行深入分析希望能为各位后续在系统研发中提供灵感.</p>
<h1><span id="1-gorilla-诞生背景">1 Gorilla 诞生背景</span></h1><ul>
<li>针对一个大型系统, 监控和分析上千万个打点数据(measurements)是一件很有挑战的事情. 解决这个事情, 一个有效手段就是将这些打点数据存储到时序数据库(TSDB) 中. 而<strong>设计一个 TSDB 的关键挑战是如何让效率(efficiency)/扩展性(scalability)/可靠性(reliability)三者达成一个有效平衡</strong>. Facebook 的 Gorilla 就是一个达成这种平衡的 TSDB. </li>
<li>Gorilla 的设计基于这样<strong>一个洞察: 监控系统的用户不会太关注一个个单独的数据点, 而是关注聚合分析; 对于分析一个现有的问题, 最近的数据点比老的数据更有价值</strong>. Gorilla 为了读写的高可用而优化, 即使以丢失部分写操作为代价. 为了提升查询效率, fb 激进地采用压缩技术, 如 delta-of-delta 和浮点数 XOR, 来压缩存储大小, 以实现将 Gorilla 数据保存到内存中.</li>
<li>最终效果是将<strong>查询时延减少 73X, 同时提升查询吞吐 14X</strong>, 两项均为和传统的基于 HBase 的时序数据库比较. 这个结果解锁了很多监控和调试功能, 比如可以在 Gorilla 上执行时序关联搜索.</li>
<li>Gorilla 也能很优雅地处理从单点到整个集群故障.</li>
</ul>
<h1><span id="2-gorilla-简介">2 Gorilla 简介</span></h1><p>Figure 1 是 Facebook 内部的监控系统, 名叫 ODS(Operational Data Store, fb 内部广泛使用的一个老的监控系统), <strong>其中 Gorilla 作为一个 write-through(即 cache 和 back store 同时修改保证多用户一致性) cache</strong>.</p>
<p><img src="/images/fb-gorilla-20201205/1-fb-ods-%E6%9E%B6%E6%9E%84%E5%9B%BE-gorilla%E4%BD%9C%E4%B8%BAwritethoughcache.png" alt="Figure 1"></p>
<h2><span id="21-需要满足的几个限制">2.1 需要满足的几个限制</span></h2><ul>
<li><strong>写密集</strong>. 每秒可以写入上千万数据点, 一个查询可以毫秒级响应. 读比写少几个数量级, 主要是一些自动化监控系统或者用户查询.</li>
<li><strong>快速识别系统的重大状态变迁</strong>. 出现任何问题时都会导致系统状态发生变化, Gorilla 支持针对很小的窗口(几十秒)进行聚合, 以快速识别重大状态变化并触发自动化修复.</li>
<li><strong>高可用</strong>. 即使多个数据中心通信断开, 每个 DC(位于不同 region 的 DataCenter, 下同) 都能本地实例读写.<br>容错. 写入数据被复制到多个 DC, 确保某个 DC 挂掉数据仍在.</li>
</ul>
<p><strong>以上限制 Gorilla 均满足, 而且可以做到绝大多数查询在几十个毫秒内返回</strong>.</p>
<p>另外, </p>
<ul>
<li>统计发现, 针对 ODS 的<strong>至少 85% 的查询涉及过去 26 个小时的数据</strong>. 这就暗示我们如果将之前基于磁盘的存储改为内存式将会更好地服务用户. 再进一步, 我们将这个内存式数据库作为持久性磁盘存储系统的 cache, 我们就<strong>既可以获得高速插入速率, 同时还能获得数据持久性</strong>.</li>
<li>2015 年春天, fb 的监控系统就生成了超过二十亿个 counter 类型的时间序列, <strong>每秒产生大约 1200 万个数据点, 每天产生 1 万亿个数据点. 每个数据点 16 字节, 那就占用 16TB 内存</strong>, 这太多了. 但是通过采用基于 XOR 的浮点数压缩技术, <strong>平均每个数据点 1.37 字节, 大小减少 12x</strong>.</li>
<li>为了满足可靠性, 我们在不同 region 的 DC 都部署了 Gorilla 实例, <strong>每个数据点都会写入每个 DC 的实例, 但是这多个副本并不保证一致性</strong>. 查询请求会被路由到最近的 DC. 以上基于<strong>一个观察, 即独立的数据点丢失不会对数据聚合结果产生大的影响, 除非不同 Gorilla 实例数据差异很大</strong>.</li>
<li>目前 Gorilla 在 fb 用于生产环境, 而且和其它系统如 hive/scuba 一起检测和分析问题.</li>
</ul>
<h2><span id="22-现状注-2015">2.2 现状(注: 2015)</span></h2><p>fb 内部有几百个系统, 分布在多个 DC, 这些系统的健康状况和性能是需要监测的, ODS 就是 fb 监控系统的重要组成部分. ODS 由 TSDB, 查询服务以及检测和告警服务构成; 其中 TSDB 是构建在 HBase 上的.</p>
<h2><span id="23-已有监控系统的查询性能问题">2.3 已有监控系统的查询性能问题</span></h2><p>早在 2013 年, fb 的监控团队就意识到基于 hbase 的 TSDB 无法扩展应对将来的查询负载. 其中 90 分位数长达几秒, 这对于依赖 tsdb 的自动化监控系统非常不友好. 一个针对稀疏数据的大点的查询甚至会超时, 因为 hbase 是针对写操作优化的. 虽然 hbase 表现不行, 但是也不能整个替换掉, 因为 ODS 的 hbase 存了 2PB 的数据. 而且 fb 的数据仓库, hive 也不能胜任, 因为它的查询比 ODS 还要慢几个数量级, 而查询时延和效率是我们主要关注的.<br>接下来能做的就是内存式 cache 了. (ODS 其实本来就有 write-through cache, 只不过是用于制图系统.) 开始也考虑过基于 Memcached 来做, 但是因为针对已有时间序列追加新数据需要一个读写周期, 会导致 memcached 服务器产生极其高的流量, 所以否掉了这个方案.</p>
<h1><span id="3-gorilla-的设计目标">3 Gorilla 的设计目标</span></h1><ul>
<li>通过唯一 key 可以识别 20 亿时间序列.</li>
<li>每分钟可追加 7 亿数据点(时间戳+具体值).</li>
<li>可保存 26 个小时的数据.</li>
<li>可支持每秒 4000 查询峰值.</li>
<li>一个毫秒内完成读操作.</li>
<li>支持 15 秒粒度的时间序列(即一分钟四个数据点).</li>
<li>两个内存式副本(不能部署在同一个地方, 以应对故障).</li>
<li>即使挂掉一个实例, 仍然可以正常支持查询.</li>
<li>可以快速扫描整个内存数据的能力.</li>
<li>支持每年至少 2x 的负载增长.</li>
</ul>
<p><strong>Gorilla 聚焦如何实时收集和存储海量数据. Gorilla 可以作为其它 tsdb 的 write-through cache.</strong></p>
<h1><span id="4-gorilla-与现有的-tsdb-比较注2015年">4 Gorilla 与现有的 TSDB 比较(注:2015年)</span></h1><h2><span id="41-opentsdb">4.1 OpenTSDB</span></h2><ul>
<li>它基于 HBase, 无降采样功能.</li>
<li>数据模型丰富, 针对一个时序有一组 key-value 对即 tags, <strong>Gorilla 仅有一个字符串 key</strong> 而且依赖更高级的工具抽取和识别时序的元数据.<h2><span id="42-whipergraphite">4.2 Whiper(Graphite)</span></h2></li>
<li>数据存储在本地磁盘, 所以查询速度不够快.</li>
<li>数据格式为 whisper, 即 RRD 风格. 该文件格式要求时间序列数据都带固定间隔的时间戳. 如果时间戳间隔固定, Gorilla 表现更好(压缩率更高), 但是 <strong>Gorilla 也可以处理随机变化的时间间隔</strong>.</li>
<li>每个时间序列保存到一个单独的文件中, 一段时间后新采集的数据会覆盖老的数据, 毕竟是 Round-Robin Database. <strong>Gorilla 也采用类似的方式, 仅在内存保存最近的数据</strong>.<h2><span id="43-influxdb">4.3 InfluxDB</span></h2></li>
<li>比 OpenTSDB 数据类型更加丰富, 每个数据点都有一组丰富的标签, 这也导致它更占磁盘.</li>
<li>无需 hbase/hadoop 就能做到水平扩展.</li>
<li>数据保存到本地磁盘, 所以查询不如内存式的快.</li>
</ul>
<h1><span id="5-gorilla-架构">5 Gorilla 架构</span></h1><h2><span id="51-概况">5.1 概况</span></h2><ul>
<li><strong>内存式</strong>, 作为后端 hbase 的 write-through cache.</li>
<li><strong>每个数据点是一个三元组</strong>&lt;字符串形式的 key, 64 比特的时间戳, 双精度浮点数类型的测量值&gt;.</li>
<li>所采用的压缩算法, 可以<strong>将 16 字节的数据点压缩到平均 1.37 字节</strong>, 减少 12x.</li>
<li>内存数据结构<strong>既支持快速的全量数据扫描, 也支持高效地查询单个时序</strong>.</li>
<li><strong>key 作为时序唯一标识, 写入时也是基于此在众多 Gorilla 实例之间做 sharding</strong>. 所以仅仅通过增加新机器就能实现 Gorilla 集群的水平扩展, 新写入的数据会被 sharding 到新机器上. 之所以这么简单, 就是因为 Gorilla 整体是一个 <strong>share-nothing 架构</strong>, 专注于水平扩展能力.(疑问, 一致性哈希咋做的? 论文没讲, 但提到了 ShardManager, 应该是它负责的).</li>
<li>Gorilla 可以处理单点故障, 网络分区甚至整个 DC 挂掉, <strong>方法就是每个时间序列都被写入到两个不同地理 regions 中的实例中</strong>. 一旦检测到宕机, 针对目标序列的全部查询会被自动切换到另一个 region 的实例, 这个过程用户感觉不出来.</li>
</ul>
<h2><span id="52-时间序列压缩">5.2 时间序列压缩</span></h2><p><strong>Gorilla 对压缩算法的诉求</strong>:</p>
<ul>
<li>支持针对浮点数进行压缩而非整数</li>
<li>支持在数据流上进行压缩, 而不是针对静态完整的数据集</li>
<li>无损, 保持整个时序精度不变</li>
</ul>
<p>Gorilla 的压缩算法受科学计算中的浮点数压缩方案启发, <strong>该方案利用当前值与前一个值的 XOR 比较来生成 delta 编码</strong>.</p>
<p><strong>Gorilla 不支持跨时间序列进行压缩, 而是在每个时序内进行压缩. 时间戳和具体数值各自独立进行压缩, 压缩时都用到了前一个数据点的信息</strong>.</p>
<p>Figure 2 是 Gorilla 的压缩过程图示.</p>
<p><img src="/images/fb-gorilla-20201205/2-%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%E5%8F%AF%E8%A7%86%E5%8C%96.png" alt="Figure 2"></p>
<ul>
<li>2.a 显示了一个数据流, <strong>每个点由两个 64 比特的数构成, 一个是时间戳一个是具体测量值</strong>. <strong>Gorilla 基于时间将数据流分成 block, 划分时会按照每两小时进行对齐</strong>. 可以看到<strong>每一个 block 以一个简单的 header 开始, 它含有所在 block 对齐的时间戳, 例子中是凌晨两点</strong>.</li>
<li>2.b 是<strong>基于 delta-of-delta 压缩后的数据</strong>, 可以看到 delta-of-delta 等于 60-62=-2, 用 ‘10’ 两个比特表示(后面详述表示规则), 接下来 7 个比特存储测量值, 一共用了 9 比特.</li>
<li>2.c 显示的是<strong>使用 XOR 算法压缩的浮点数</strong>, 可以看到当前值与前一个值 XOR 后的结果, 它有 11 个前导零, 整个结果仅有一个有效位 1, 这可以编码为 2 比特的 ‘11’. 存储当前浮点数测量值 24 共用了 14 比特. 具体编码细节后面详述.</li>
</ul>
<h3><span id="521-时间戳压缩">5.2.1 时间戳压缩</span></h3><ul>
<li>我们注意到, 在 ODS 中, <strong>绝大多数数据点都是以固定时间间隔到达的. 后面可以看到这是一个非常重要的洞察</strong>.</li>
<li>我们<strong>不会将时间戳完整存储, 而是采用 delta-of-delta</strong>. 假设一个 delta 序列为 60, 60, 59, 61, 那么 delta-of-delta 就是 0, -1, 2.</li>
<li>然后我们按照下面的算法使用<strong>变长编码</strong>来编码这些 delta-of-delta:<ul>
<li><strong>block header 存储起始时间戳, 记为 $t_{-1}$</strong>, 它以两小时时间窗口来对齐. <strong>当前 block 中第一个数据点的时间戳记为 $t_0$</strong>, 真正存储的是<strong>它减去 $t_{-1}$ 得到的 delta</strong>(只有第一个时间戳对应的存储值为 delta 而非 delta-of-delta, 因为前面就一个起始时间戳), 以 14 比特存储.</li>
<li>接下来针对每个时间戳 $t_n$:<ul>
<li><ol>
<li>计算其对应的 delta-of-delta: $D=(t_n-t_{n-1})-(t_{n-1}-t_{n-2})$</li>
</ol>
</li>
<li><ol start="2">
<li>如果 $D$ 为 0, 则用一个比特存储 ‘0’</li>
</ol>
</li>
<li><ol start="3">
<li>如果 $D$  在$[-63, 64]$ 之间, 用 2 个比特存储 ‘10’ , 然后接下来 7 比特存储 $D$ 的具体值.</li>
</ol>
</li>
<li><ol start="4">
<li>如果 $D$  在$[-255, 256]$ 之间, 用 3 个比特存储 ‘110’, 然后接下来 9 比特存储 $D$ 的具体值.</li>
</ol>
</li>
<li><ol start="5">
<li>如果 $D$  在$[-2047, 2048]$ 之间, 用 4 个比特存储 ‘1110’, 然后接下来 12 比特存储 $D$ 的具体值.</li>
</ol>
</li>
<li><ol start="6">
<li>其它情况, 用 4 个比特存储 ‘1111’, 然后接下来 32 比特存储 $D$ 的具体值.</li>
</ol>
</li>
</ul>
</li>
<li>上面的取值范围都是通过从生产系统统计出来的, <strong>这几个范围可以帮助达到最大压缩率</strong>.</li>
</ul>
</li>
</ul>
<p><img src="/images/fb-gorilla-20201205/3-%E6%97%B6%E9%97%B4%E6%88%B3%E5%8E%8B%E7%BC%A9%E5%8F%96%E5%80%BC%E8%8C%83%E5%9B%B4%E9%87%8F%E5%8C%96%E8%AF%B4%E6%98%8E%E5%9B%BE.png" alt="Figure 3"></p>
<p>从 Figure 3 观察压缩效果: 可以发现<strong>大约 96% 的时间戳可以压缩到 1 个比特</strong>.</p>
<h3><span id="522-测量值压缩">5.2.2 测量值压缩</span></h3><ul>
<li>Gorilla 只允许存储<strong>双精度浮点数</strong>的测量值. </li>
<li><strong>根据统计, 时间序列中相邻的数据点大多数时候相差不大</strong>, 如果相邻的数据点对应的<strong>测量值的符号部分/指数部分/小数部分前半截都差不多一样</strong>, 那么我们就可以计算当前值和前一个值的 XOR 来存储而不是采用 delta 编码方案.</li>
<li>当前值和前一个值进行 XOR 后按照下面变长编码方案来存储:<ul>
<li>第一个值不压缩</li>
<li>如果 XOR 结果为 0, 则仅存 1 比特的 ‘0’</li>
<li>如果 XOR 结果非 0, 计算其前导零和后缀零个数, 存储 1 比特 ‘1’, 然后后面跟着下面的 a 或者 b:<ul>
<li>a. 首先是 1 比特的控制位 ‘0’, 如果<strong>当前 XOR 结果的前导零个数和后缀零个数与前一个 XOR 结果的对应部分一样</strong>, 仅存储当前 XOR 结果的中间有效位部分(该部分开头和结尾都为 1). 正是因为前述的特性, 可以让我们省去存储前导零长度和后缀零长度的空间, <strong>根据前一个 XOR 结果就能复原当前这个</strong>.</li>
<li>b. 首先是 1 比特的控制位 ‘1’, 接下来 5 比特为前导零个数, 接下来 6 比特为当前 XOR 结果的有效位长度(该部分开头和结尾都为 1), 接下来为 XOR 结果的有效位部分.</li>
</ul>
</li>
</ul>
</li>
<li>从上面方案来看, <strong>测量值压缩不但用到了当前测量值和前一个测量值, 也用到了当前 XOR 结果和前一个 XOR 的结果</strong>, 因为计算出来的 XOR 序列, 相邻两个经常有相似的前导零和后缀零. 这可以通过 Figure 4 来观察.</li>
</ul>
<p><img src="/images/fb-gorilla-20201205/4-XOR%E5%BA%8F%E5%88%97%E5%89%8D%E5%AF%BC%E9%9B%B6%E5%92%8C%E5%90%8E%E7%BC%80%E9%9B%B6%E4%BB%A5%E5%8F%8A%E6%9C%89%E6%95%88%E9%83%A8%E5%88%86%E8%81%9A%E9%9B%86%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="Figure 4"></p>
<p>针对测量值的编码方案, 从 Figure 5 统计可以看到:</p>
<ul>
<li>大约 59.06% 数据点被压缩到仅剩 1 比特</li>
<li>大约 28.3% 以控制位 ‘10’ 开头, 平均长度为 26.6 比特</li>
<li>大约 12.64% 以控制位 ‘11’ 开头, 平均长度为 39.6 比特, <strong>相比控制位 ‘10’ 方案多出来的 13 比特用于存储前导零长度和有效位部分长度了</strong>.</li>
</ul>
<p><img src="/images/fb-gorilla-20201205/5-%E6%B5%8B%E9%87%8F%E5%80%BC%E5%8E%8B%E7%BC%A9%E5%90%8E%E5%90%84%E7%A7%8D%E6%A8%A1%E5%BC%8F%E9%95%BF%E5%BA%A6%E5%8F%8A%E5%85%B6%E5%8D%A0%E6%AF%94.png" alt="Figure 5"></p>
<p><strong>测量值方案潜在的问题</strong>: 就是时序对应的数据流<strong>按多大的窗口划分 block 才能更好的利用这个压缩方案</strong>. 由于中间每个值压缩都与自己的前驱密切相关, <strong>block 肯定越大越好, 如果不划分 block 是最佳的</strong>. 但是如果 block 太大, 但是用户<strong>只想查询一个很小的时间窗口的数据, 就会涉及非常大的计算量来解压缩</strong>. 这就牵扯到 trade-off.</p>
<p><img src="/images/fb-gorilla-20201205/6-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%92%E5%88%86%E6%88%90block%E7%9A%84%E5%A4%A7%E5%B0%8F%E6%9D%83%E8%A1%A1.png" alt="Figure 6"></p>
<p>从 Figure 6 可以看到 120 分钟也就是两个小时的 block 大小可以达到一个比较理想的压缩率, 平均每个数据点占 1.37 字节. 窗口再大, 压缩率变化不大了.</p>
<h1><span id="6-gorilla-的内存数据结构">6 Gorilla 的内存数据结构</span></h1><p>Figure 7 是针对 Gorilla 的内存数据结构相互关系和各个部分的图示.</p>
<p><img src="/images/fb-gorilla-20201205/7-gorilla%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="Figure 7"></p>
<h2><span id="61-tsmap">6.1 TSmap</span></h2><p>Gorilla 实现涉及的核心数据结构是 Timeseries Map(TSmap), 如 Figure 7 中间部分所示.</p>
<h3><span id="611-tsmap-由两部分构成">6.1.1 TSmap 由两部分构成</span></h3><ul>
<li>一个 C++ 标准库的 vector, 每个元素是一个 shared-pointer, 每个 shared-pointer 指向一个时间序列 TS. <strong>该结构主要用于针对全量数据进行高效地分页扫描</strong>.</li>
<li>一个从时间序列名称(大小写不敏感但是保留大小写)到指向时间序列 TS 的 shared-pointer 的无序 map. <strong>该结构主要是用于在常数时间内根据名称查询某个时间序列</strong>.</li>
</ul>
<h3><span id="612-tsmap-的并发与性能">6.1.2 TSmap 的并发与性能</span></h3><p>关于 TSmap 的并发控制:</p>
<ul>
<li>有一个专用的 Read-Write 锁保护 map 和 vector 的访问</li>
<li>每个 TS 有一个 1 字节的 spin lock, 由于每个时间序列写吞吐低(秒级或分钟级写一次), 所以针对 spin lock 的争用并不激烈.</li>
</ul>
<p>C++ shared-pointer 使得<strong>扫描操作可以在微秒时间内拷贝 vector</strong>, 这避免了长时间锁住临界区(critical section)从而影响写入数据流. <strong>当删除一个时间序列时, 其对应的在 vector 的元素会被标记为墓碑(相关内存不会返回系统而是等待重用), 对应的索引被放到池子里待新的时间序列重用之</strong>.</p>
<h2><span id="62-shardmap">6.2 ShardMap</span></h2><p>Gorilla 为了做到分布式存储采用了分片机制, 如 Figure 7 左边部分所示.</p>
<ul>
<li>ShardMap 名字里有 map, 但它实际是一个 vector, 每个元素是一个指向 TSmap 的 unique_ptr. </li>
<li>那它为什么叫 map 呢? 因为每个时间序列根据其名称先做 hash(具体算法同 TSmap 的 map 结构)后做 shard(即其被分到哪个 TSmap). </li>
<li>shards 即 TSmap 个数固定, 只有几千个. </li>
<li>就像 TSmap, 针对 ShardMap 的访问也由一个 read-write spin lock 控制. </li>
<li>因为 ShardMap 这一层做了 shard 了, 所以 TSmap 内部的 map 就比较小了, C++ 标准库里的 unordered-map 性能足够了.</li>
</ul>
<h2><span id="63-ts">6.3 TS</span></h2><p>说完了最外层的 ShardMap, 也说完了中间的 TSmap, 下面说说最里面的 TS 构成.</p>
<p>TS (即 time series), 为 Gorilla 存储每个时间序列的数据结构, 如 Figure 7 右边部分所示.</p>
<ul>
<li>每个时间序列的数据结构由一系列 closed blocks(每一个两个小时大小)和一个 open block (保存最近两个小时的数据). </li>
<li>open block 仅追加<strong>压缩过的</strong>(压缩算法前面讲过了) &lt;时间戳, 测量值&gt; 数据点. 超过 2 小时, open block 就会转成 closed block, 后者不可更改直至从内存被删除. </li>
<li>一旦 closed, block 就会被拷贝到另外的内存(这些内存从大块的 slabs 分配)从而<strong>减少内存碎片</strong>. open block 经常因大小变化而重分配内存, 前述的拷贝过程可以减少 Gorilla 整体的内存碎片.</li>
<li>当外部查询时, <strong>Gorilla 直接拷贝包含目标数据的 blocks 给客户端</strong>, 客户端自己去解压缩.</li>
</ul>
<h1><span id="7-gorilla-的磁盘存储结构">7 Gorilla 的磁盘存储结构</span></h1><p>Gorilla 其中一个设计目标就是高可用, 不能因为单个 host 挂掉而导致集群不可用.</p>
<p>Gorilla 通过 GlusterFS 实现数据持久性, 该分布式文件系统支持三副本, 并且兼容 POSIX. 当然你也可以用 Hadoop 或者其它分布式文件系统. 注意这里是单个 host 上数据的持久性, 它们对 host 内存数据对应. 这些数据不用于响应客户查询, 而是用于 host 内存数据持久化以便在 host 挂掉后被重新加载到内存恢复对应数据结构.</p>
<p>Gorilla 每个 host 持有多个 shards, 每个 shard 一个目录. 每个目录中保存着如下四类信息:</p>
<ul>
<li>key list 文件. key list 文件就是一个简单的 map, 即从时间序列的字符串类型的 key 到一个整数 ID 的映射. 这个整数 ID 就是对应时间序列在 Tsmap-&gt;vector 的索引. 新的 keys 会被追加到 key list 中, Gorilla 会周期性地扫描每个 shard 对应的全部 keys 以重写该文件. </li>
<li>一组 append-only logs. 每个 shard 一个 append-only log. 类似 WAL(write-ahead log), 但因为它不保障 ACID 所以不是真正的 WAL. <strong>新到达的数据点都是先写到这个文件</strong>. 由于<strong>每个 shard 一个 append-only log</strong>, 所以哈希到同一个 shard 的多个时间序列的数据点会交织在一起. 数据编码同内存格式, 但多了一个 32 比特的整数 ID 标识数据点属于哪个时间序列. 每当攒够 64KB 数据刷盘一次, 大约是一两秒的数据, 这可能因为宕机丢失一小部分数据, 不过为了获取更高的磁盘写入效率, 这个 trade-off 就不得不做了.</li>
<li>一组完整的 block 文件. <strong>每隔两小时 Gorilla 会拷贝内存中压缩过的 block 数据到磁盘</strong>, 它比 append-only log 文件小多了. 一个 block 文件就是两个小时的数据, <strong>它包含两段: 一组连续的 64kB slabs(就是它们在内存中的样子), 一个 <code>&lt;time series ID, data block pointer&gt;</code> 列表</strong>.</li>
<li>checkpoint 文件. <strong>每当一个完整的 block 文件生成, Gorilla 就会创建一个新的 checkpoint 文件同时删除对应的 append-only log</strong>. 这个 <strong>checkpoint 文件用于标记什么时候一个完整的 block 文件被刷入了磁盘</strong>. 如果因为进程崩溃导致 block 文件写入失败, 新进程启动后会发现对应的 checkpoint 文件不存在, 新进程就会认为这个 block 文件有问题, 转而仅从 append-only log 读取数据.</li>
</ul>
<h1><span id="8-gorilla-如何实现高可用">8 Gorilla 如何实现高可用</span></h1><p><strong>Gorilla 容忍两种故障</strong>:</p>
<ul>
<li>单机故障</li>
<li>单集群故障</li>
</ul>
<p>以上两种都可以通过多副本机制做到快速转移和处理, 也对频繁的版本升级很友好.</p>
<p>多副本机制: <strong>针对同一份数据, Gorilla 会在不同 region 的 DC 里面部署相互独立的集群, 每次写操作同时写到这两个地方</strong>, 当然这个<strong>双写不保证一致性</strong>(还是回到前面讲到的, 时序数据不太注重单个数据点或者一小块数据, 关注的是整体), 一个挂了另一个还能用, <strong>挂了的那个数据恢复到最近 26 个小时大小就继续对外提供服务</strong>.</p>
<p><strong>单机挂掉后 Gorilla 处理流程</strong>:</p>
<ul>
<li>ShardManager(一个基于 paxos 强一致系统)会将其负责的 shards 重分配给当前集群其它机器. </li>
<li>重分配期间, 写客户端会自己缓冲这些 shards 的数据<strong>一分钟</strong>.</li>
<li>一般 node 挂掉 30 秒后就启动重分配, 一分钟就可以完成, 如果超过一分钟, 缓冲的数据就会用新的覆盖老的. </li>
<li>shards 重分配时, 分到这些 shards 的 nodes 会去 GlusterFS 拉取数据, 一般五分钟内就可以全部恢复. </li>
<li>注意, 前述过程可能会丢失部分数据, 这是可以容忍的.</li>
</ul>
<p>注意, node 失效期间, 因为部分 shards 不可用, 读响应可能会被标记为 partial, 客户端转而请求另一个 DC 的同样数据, 如果两个 DC 相关均不可用, 则两个 DC 的部分结果和一个表示错误的标识会被返回给客户端.</p>
<p><strong>最后, 如果 Gorilla 都挂了怎么办?</strong> 这时就靠 HBase 的 long-term 存储来响应客户请求了, 直到 Gorilla 集群恢复.</p>
<h1><span id="9-gorilla-带来的新分析工具">9 Gorilla 带来的新分析工具</span></h1><h2><span id="91-关联分析引擎">9.1 关联分析引擎</span></h2><ul>
<li>Gorilla 提供的关联搜索功能支持用户一次在一百万个时间序列上做交互式地暴力搜索.</li>
<li>关联分析引擎支持针对某个序列和一组其它时间序列做 PPMCC(皮尔逊积矩相关系数), 从而找出形状相似地时间序列, 进而帮助做根因分析(root-cause analysis).</li>
<li>计算 PPMCC 时, 测试时间序列会被广播到多个机器, 这些机器基于目标时序的 key 来确定, 每个机器独立计算相关时序, 然后基于 PPMCC 绝对值排序求出 topN. 最后返回结果.</li>
</ul>
<h2><span id="92-降采样">9.2 降采样</span></h2><p>在 Gorilla 上线之前, fb 在 hbase 上允许 map-reduce 任务来计算降采样数据. 有了 Gorilla, 后台进程每两个小时扫一遍全量数据来计算降采样, 不用再去全表扫描 HBase 了.</p>
<p>–End–</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://chienlungcheung.github.io/2020/10/01/leveldb-annotations-3-memtable/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chienlung Cheung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="programatrix">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/01/leveldb-annotations-3-memtable/" class="post-title-link" itemprop="url">Leveldb 源码详解系列之三: MemTable 设计与实现</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-10-01 21:47:36" itemprop="dateCreated datePublished" datetime="2020-10-01T21:47:36+00:00">2020-10-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-03 09:19:19" itemprop="dateModified" datetime="2021-03-03T09:19:19+00:00">2021-03-03</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/10/01/leveldb-annotations-3-memtable/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/10/01/leveldb-annotations-3-memtable/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <!-- toc -->

<ul>
<li><a href="#1-%E6%A0%B8%E5%BF%83%E6%96%87%E4%BB%B6%E5%92%8C%E6%A0%B8%E5%BF%83%E7%B1%BB">1 核心文件和核心类</a></li>
<li><a href="#2-memtable-%E6%A0%B8%E5%BF%83%E6%88%90%E5%91%98%E5%8F%98%E9%87%8F">2 MemTable 核心成员变量</a></li>
<li><a href="#3-memtable-%E6%A0%B8%E5%BF%83%E6%96%B9%E6%B3%95">3 MemTable 核心方法</a><ul>
<li><a href="#31-memtable-%E5%86%99%E6%96%B9%E6%B3%95">3.1 MemTable 写方法</a></li>
<li><a href="#32-memtable-%E8%AF%BB%E6%96%B9%E6%B3%95">3.2 MemTable 读方法</a></li>
<li><a href="#33-memtable-%E8%BF%AD%E4%BB%A3%E5%99%A8">3.3 MemTable 迭代器</a></li>
<li><a href="#34-memtable-%E5%86%85%E5%AD%98%E4%BC%B0%E8%AE%A1">3.4 MemTable 内存估计</a></li>
</ul>
</li>
<li><a href="#4-memtable-%E6%AF%94%E8%BE%83%E5%99%A8%E4%B9%8B-keycomparator">4 MemTable 比较器之 KeyComparator</a></li>
<li><a href="#5-memtable-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B9%8B-arena">5 MemTable 内存管理之 Arena</a><ul>
<li><a href="#51-%E5%A6%82%E4%BD%95%E5%90%91-arena-%E7%94%B3%E8%AF%B7%E6%8C%87%E5%AE%9A%E5%A4%A7%E5%B0%8F%E7%9A%84%E5%86%85%E5%AD%98">5.1 如何向 Arena 申请指定大小的内存</a></li>
<li><a href="#52-%E5%A6%82%E4%BD%95%E5%90%91-arena-%E7%94%B3%E8%AF%B7%E5%AF%B9%E9%BD%90%E5%90%8E%E7%9A%84%E5%86%85%E5%AD%98">5.2 如何向 Arena 申请对齐后的内存</a></li>
</ul>
</li>
<li><a href="#6-memtable-%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E4%B9%8B-skiplist">6 MemTable 底层存储之 SkipList</a><ul>
<li><a href="#61-skiplist-%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B">6.1 SkipList 原理简介</a></li>
<li><a href="#62-skiplist-%E5%AE%9E%E7%8E%B0">6.2 SkipList 实现</a><ul>
<li><a href="#621-skiplist-%E6%A0%B8%E5%BF%83%E6%95%B0%E6%8D%AE%E6%88%90%E5%91%98">6.2.1 SkipList 核心数据成员</a></li>
<li><a href="#622-skiplist-%E6%A0%B8%E5%BF%83%E6%96%B9%E6%B3%95">6.2.2 SkipList 核心方法</a><ul>
<li><a href="#6223-%E8%BE%85%E5%8A%A9%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-node">6.2.2.3 辅助数据结构 Node</a></li>
<li><a href="#6224-%E7%94%A8%E4%BA%8E%E4%B8%BA%E6%96%B0%E6%95%B0%E6%8D%AE%E5%88%86%E9%85%8D%E5%AD%98%E5%82%A8%E7%9A%84-newnode-%E6%96%B9%E6%B3%95">6.2.2.4 用于为新数据分配存储的 NewNode 方法</a></li>
<li><a href="#6225-%E7%94%A8%E4%BA%8E%E7%A1%AE%E5%AE%9A%E6%9F%90%E4%B8%AA%E8%8A%82%E7%82%B9%E7%B4%A2%E5%BC%95%E5%B1%82%E6%95%B0%E7%9A%84-randomheight-%E6%96%B9%E6%B3%95">6.2.2.5 用于确定某个节点索引层数的 RandomHeight 方法</a></li>
<li><a href="#6226-%E7%94%A8%E4%BA%8E%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE%E7%9A%84-insert-%E6%96%B9%E6%B3%95">6.2.2.6 用于插入数据的 Insert 方法</a></li>
<li><a href="#6226-%E7%94%A8%E4%BA%8E%E6%9F%A5%E6%89%BE%E6%95%B0%E6%8D%AE%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%E7%9A%84-contains-%E6%96%B9%E6%B3%95">6.2.2.6 用于查找数据是否存在的 Contains 方法</a></li>
<li><a href="#6227-%E8%AF%BB%E5%86%99%E9%83%BD%E8%A6%81%E4%BE%9D%E8%B5%96%E7%9A%84%E8%BE%85%E5%8A%A9%E6%96%B9%E6%B3%95-findgreaterorequal">6.2.2.7 读写都要依赖的辅助方法 FindGreaterOrEqual</a></li>
<li><a href="#6228-%E8%BE%85%E5%8A%A9%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-iterator">6.2.2.8 辅助数据结构 Iterator</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#7-%E7%95%AA%E5%A4%96-c-%E7%9A%84%E5%86%85%E5%AD%98%E6%8E%92%E5%BA%8F">7 番外: C++ 的内存排序</a></li>
</ul>
<!-- tocstop -->

<p>memtable 可以看作是 log 文件的内存形式, 但是格式不同. 每个 log 文件在内存有一个对应的 memtable, 它和正在压实的 memtable(所以可能同时有两个 memtable 存在) 以及磁盘上的各个 level 包含的文件构成了数据全集. memtable 的本质就是一个 SkipList.</p>
<h1><span id="1-核心文件和核心类">1 核心文件和核心类</span></h1><table>
<thead>
<tr>
<th align="center">核心类</th>
<th align="center">所在文件</th>
<th align="center">用途</th>
</tr>
</thead>
<tbody><tr>
<td align="center">leveldb::MemTable</td>
<td align="center">db/memtable.cc; db/memtable.h</td>
<td align="center">本文主角</td>
</tr>
<tr>
<td align="center">leveldb::Arena</td>
<td align="center">util/arena.cc; util/arena.h</td>
<td align="center">负责内存管理(仅分配和释放, 无回收)</td>
</tr>
<tr>
<td align="center">leveldb::SkipList&lt;Key, Comparator&gt;</td>
<td align="center">db/skiplist.h</td>
<td align="center">作为 MemTable 类底层存储(基于内存)</td>
</tr>
</tbody></table>
<h1><span id="2-memtable-核心成员变量">2 MemTable 核心成员变量</span></h1><table>
<thead>
<tr>
<th align="center">字段</th>
<th align="center">类型</th>
<th align="center">用途</th>
</tr>
</thead>
<tbody><tr>
<td align="center">comparator_</td>
<td align="center">struct leveldb::MemTable::KeyComparator</td>
<td align="center">用于 SkipList 比较 key</td>
</tr>
<tr>
<td align="center">refs_</td>
<td align="center">int</td>
<td align="center">该 memtable 引用计数, memtable 的拷贝构造和赋值构造都是禁用的, 只能通过增加引用计数复用</td>
</tr>
<tr>
<td align="center">arena_</td>
<td align="center">class leveldb::Arena</td>
<td align="center">内存池, 给 SkipList 分配 Node 时候使用</td>
</tr>
<tr>
<td align="center">table_</td>
<td align="center">typedef leveldb::SkipList&lt;const char *, leveldb::MemTable::KeyComparator&gt; leveldb::MemTable::Table</td>
<td align="center">SkipList, 存储 memtable 里的数据</td>
</tr>
</tbody></table>
<h1><span id="3-memtable-核心方法">3 MemTable 核心方法</span></h1><table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">用途</th>
</tr>
</thead>
<tbody><tr>
<td align="center">explicit MemTable(const InternalKeyComparator&amp; comparator)</td>
<td align="center">传入一个自定义或数据库提供的比较器, 生成一个 MemTable 实例.</td>
</tr>
<tr>
<td align="center">void Ref()</td>
<td align="center">递增引用计数, MemTable 是基于引用计数的, 每个 MemTable 实例初始引用计数为 0, 调用者必须至少调用一次 Ref() 方法.</td>
</tr>
<tr>
<td align="center">void Unref()</td>
<td align="center">递减引用计数, 计数变为 0 后删除该 MemTable 实例.</td>
</tr>
<tr>
<td align="center">size_t ApproximateMemoryUsage()</td>
<td align="center">返回当前 memtable 中数据字节数的估计值, 当 memtable 被修改时调用该方法也是安全的, 该方法底层实现直接用的 arena_ 持有内存的字节数.</td>
</tr>
<tr>
<td align="center">Iterator* NewIterator()</td>
<td align="center">返回一个迭代器, 该迭代器可以用来遍历整个 memtable 的内容.</td>
</tr>
<tr>
<td align="center">void Add(SequenceNumber seq, ValueType type, const Slice&amp; key, const Slice&amp; value)</td>
<td align="center">根据指定的序列号和操作类型将 user_key 转换为 internal_key 然后和 value 一起向 memtable 新增一个数据项. 该数据项是 key 到 value 的映射, 如果操作类型 type==kTypeDeletion 则 value 为空. 最后数据项写入了底层的 SkipList 中. 每个数据项编码格式为 [varint32 类型的 internal_key_size, internal_key, varint32 类型的 value_size, value] internal_key 由 [user_key, tag] 构成.</td>
</tr>
<tr>
<td align="center">bool Get(const LookupKey&amp; key, std::string* value, Status* s)</td>
<td align="center">如果 memtable 包含 key 对应的 value, 则将 value 保存在 *value 并返回 true. 如果 memtable 包含 key 对应的 deletion, 则将 NotFound 错误存在 *status, 并返回 true; 其它情况返回 false.</td>
</tr>
</tbody></table>
<h2><span id="31-memtable-写方法">3.1 MemTable 写方法</span></h2><p>当需要向 memtable 加入一个 &lt;key, value&gt; 时, 可以调用 <code>void Add(SequenceNumber seq, ValueType type, const Slice&amp; key, const Slice&amp; value)</code> 达成目标.</p>
<p>该方法负责将用户 key 转换为一个 InternalKey, 然后连同 value 一起进行编码, 组成一个形如下述的数据项:</p>
<pre><code>+------------------------------+---------+--------+--------+---------------+-----+
|     internal key size        | seq num |op type |user key|  value size   |value|
|      (varint32 type)         |(7 bytes)|(1 byte)|        |(varint32 type)|     |
|(user key + seq num + op type)|         |        |        |               |     |
+------------------------------+---------+--------+--------+---------------+-----+</code></pre>
<p>其中该数据项前四个部分构成了 InternalKey, 该结构是 MemTable 做排序的依据. 最后将该数据项插入到底层的 SkipList 中. 具体处理流程见下面代码注释:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">MemTable::Add</span><span class="params">(SequenceNumber s, ValueType type,</span></span></span><br><span class="line"><span class="function"><span class="params">                   <span class="keyword">const</span> Slice&amp; key,</span></span></span><br><span class="line"><span class="function"><span class="params">                   <span class="keyword">const</span> Slice&amp; value)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 插入到 memtable 的数据项的数据格式为</span></span><br><span class="line">  <span class="comment">// (注意, memtable key 的构成与 LookupKey 一样, 即 user_key + 序列号 + 操作类型):</span></span><br><span class="line">  <span class="comment">// [varint32 类型的 internal_key_size, </span></span><br><span class="line">  <span class="comment">//  user_key, </span></span><br><span class="line">  <span class="comment">//  序列号 + 操作类型, </span></span><br><span class="line">  <span class="comment">//  varint32 类型的 value_size, </span></span><br><span class="line">  <span class="comment">//  value]</span></span><br><span class="line">  <span class="comment">// 其中, internal_key_size = user_key size + 8</span></span><br><span class="line">  <span class="keyword">size_t</span> key_size = key.size();</span><br><span class="line">  <span class="keyword">size_t</span> val_size = value.size();</span><br><span class="line">  <span class="keyword">size_t</span> internal_key_size = key_size + <span class="number">8</span>;</span><br><span class="line">  <span class="comment">// 编码后的数据项总长度</span></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">size_t</span> encoded_len =</span><br><span class="line">      VarintLength(internal_key_size) + internal_key_size +</span><br><span class="line">      VarintLength(val_size) + val_size; </span><br><span class="line">  <span class="comment">// 分配用来存储数据项的内存    </span></span><br><span class="line">  <span class="keyword">char</span>* buf = arena_.Allocate(encoded_len); </span><br><span class="line">  <span class="comment">// 将编码为 varint32 格式的 internal_key_size 写入内存</span></span><br><span class="line">  <span class="keyword">char</span>* p = EncodeVarint32(buf, internal_key_size); </span><br><span class="line">  <span class="comment">// 将 user_key 写入内存</span></span><br><span class="line">  <span class="built_in">memcpy</span>(p, key.data(), key_size); </span><br><span class="line">  p += key_size;</span><br><span class="line">  <span class="comment">// 将序列号和操作类型写入内存.</span></span><br><span class="line">  <span class="comment">// 注意, 序列号为高 7 个字节;  </span></span><br><span class="line">  <span class="comment">// 将序列号左移 8 位, 空出最低 1 个字节写入操作类型 type. </span></span><br><span class="line">  EncodeFixed64(p, (s &lt;&lt; <span class="number">8</span>) | type); </span><br><span class="line">  p += <span class="number">8</span>;</span><br><span class="line">  <span class="comment">// 将编码为 varint32 格式的 value_size 写入内存</span></span><br><span class="line">  p = EncodeVarint32(p, val_size); </span><br><span class="line">  <span class="comment">// 将 value 写入内存</span></span><br><span class="line">  <span class="built_in">memcpy</span>(p, value.data(), val_size); </span><br><span class="line">  assert(p + val_size == buf + encoded_len);</span><br><span class="line">  <span class="comment">// 将数据项插入跳跃表</span></span><br><span class="line">  table_.Insert(buf); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到由于模块化抽象做得好, 整体来说还是比较简单的. 后面章节会重点说一下上述处理中有关内存分配(<code>arena_.Allocate()</code>)和数据项插入到 SkipList (<code>table_.Insert()</code>) 的相关操作.</p>
<h2><span id="32-memtable-读方法">3.2 MemTable 读方法</span></h2><p><code>bool Get(const LookupKey&amp; key, std::string* value, Status* s)</code> 用于实现针对 memtable 的读操作.</p>
<p>当用户调用 DB 的 <code>Get</code> 方法查询某个 key 的时候, 具体步骤是这样的(具体实现位于 <code>leveldb::Status leveldb::Version::Get(const leveldb::ReadOptions &amp;options, const leveldb::LookupKey &amp;k, string *value, leveldb::Version::GetStats *stats)</code>, DB 的 <code>Get</code> 方法会调用前述实现.):</p>
<ul>
<li>1 先查询当前在用的 memtable, 查到返回, 未查到下一步</li>
<li>2 查询正在转换为 sorted table 的 memtable 中寻找, 查到返回, 未查到下一步 </li>
<li>3 在磁盘上采用从底向上 level-by-level 的寻找目标 key. <ul>
<li>由于 level 越低数据越新, 因此, 当我们在一个较低的 level 找到数据的时候, 不用在更高的 levels 找了.</li>
<li>由于 level-0 文件之间可能存在重叠, 而且针对同一个 key, 后产生的文件数据更新所以先将包含 key 的文件找出来按照文件号从大到小(对应文件从新到老)排序查找 key; 针对 level-1 及其以上 level, 由于每个 level 内文件之间不存在重叠, 于是在每个 level 中直接采用二分查找定位 key.</li>
</ul>
</li>
</ul>
<p>其中上面 1,2 两步骤查询 memtable 使用的即为本节开头提到的 Get 方法.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如果 memtable 包含 key 对应的 value, 则将 value 保存在 *value 并返回 true. </span></span><br><span class="line"><span class="comment">// 如果 memtable 包含 key 对应的 deletion(memtable 的删除不是真的删除, 而是一个带有删除标记的 Add 操作, </span></span><br><span class="line"><span class="comment">// 而且 key 对应的 value 为空), 则将 NotFound 错误存在 *status, 并返回 true; </span></span><br><span class="line"><span class="comment">// 其它情况返回 false. </span></span><br><span class="line"><span class="comment">// LookupKey 就是 memtable 数据项的前半部分, 布局同 internal key. </span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">MemTable::Get</span><span class="params">(<span class="keyword">const</span> LookupKey&amp; key, <span class="built_in">std</span>::<span class="built_in">string</span>* value, Status* s)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// LookupKey 结构同 internal key.</span></span><br><span class="line">  <span class="comment">// 注意由于比较时, 当 userkey 一样时会继续比较序列号, </span></span><br><span class="line">  <span class="comment">// 而且序列号越大对应 key 越小, 所以外部调用 Get()</span></span><br><span class="line">  <span class="comment">// 方法前用户组装 LookupKey 的时候, 传入的序列号不能小于</span></span><br><span class="line">  <span class="comment">// MemTable 每个 key 的序列号. 外部具体实现是采用 DB 记录的最大</span></span><br><span class="line">  <span class="comment">// 序列号.</span></span><br><span class="line">  Slice memkey = key.memtable_key();</span><br><span class="line">  <span class="comment">// 为底层的 skiplist 创建一个临时的迭代器</span></span><br><span class="line">  <span class="function">Table::Iterator <span class="title">iter</span><span class="params">(&amp;table_)</span></span>;</span><br><span class="line">  <span class="comment">// 返回第一个大于等于 memkey 的数据项(数据项在 iter 内部存着),</span></span><br><span class="line">  <span class="comment">// 这里的第一个很关键, 当 userkey 相同但是序列号不同时, 序列号</span></span><br><span class="line">  <span class="comment">// 大的那个 key 对应的数据更新, 同时由于 internal key 比较规则</span></span><br><span class="line">  <span class="comment">// 是, userkey 相同序列号越大对应 key 越小, 所以 userkey 相同时</span></span><br><span class="line">  <span class="comment">// 序列号最大的那个 key 肯定是第一个.</span></span><br><span class="line">  iter.Seek(memkey.data()); </span><br><span class="line">  <span class="comment">// iter 指向有效 node, 即 node 不为 nullptr</span></span><br><span class="line">  <span class="keyword">if</span> (iter.Valid()) &#123; </span><br><span class="line">    <span class="comment">// 每个数据项格式如下:</span></span><br><span class="line">    <span class="comment">//    klength  varint32</span></span><br><span class="line">    <span class="comment">//    userkey  char[klength-8] // 源码注释这里有误, 应该是 klength - 8</span></span><br><span class="line">    <span class="comment">//    tag      uint64</span></span><br><span class="line">    <span class="comment">//    vlength  varint32</span></span><br><span class="line">    <span class="comment">//    value    char[vlength]</span></span><br><span class="line">    <span class="comment">// 通过比较 user_key 部分和 ValueType 部分来确认是否是我们要找的数据项. </span></span><br><span class="line">    <span class="comment">// 不去比较序列号的原因是上面调用 Seek() 的时候已经跳过了非常大的序列号</span></span><br><span class="line">    <span class="comment">// (internal_key 比较逻辑是序列号越大 internal_key 越小, 而我们</span></span><br><span class="line">    <span class="comment">// 通过 Seek() 寻找的是第一个大于等于某个 internal_key 的节点).  </span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// 注意, memtable 将底层的 SkipList 的 key(确切应该说是数据项)</span></span><br><span class="line">    <span class="comment">// 声明为了 char* 类型. 这里的 entry 是 SkipList.Node 里包含的整个数据项. </span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">char</span>* entry = iter.key();</span><br><span class="line">    <span class="keyword">uint32_t</span> key_length;</span><br><span class="line">    <span class="comment">// 解析 internal_key 长度</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">char</span>* key_ptr = GetVarint32Ptr(entry, entry+<span class="number">5</span>, &amp;key_length); </span><br><span class="line">    <span class="comment">// 比较 user_key. </span></span><br><span class="line">    <span class="comment">// 因为 internal_key 包含了 tag 所以任意两个 internal_key </span></span><br><span class="line">    <span class="comment">// 肯定是不一样的, 而我们真正在意的是 user_key, </span></span><br><span class="line">    <span class="comment">// 所以这里调用 user_comparator 比较 user_key. </span></span><br><span class="line">    <span class="keyword">if</span> (comparator_.comparator.user_comparator()-&gt;Compare(</span><br><span class="line">            Slice(key_ptr, key_length - <span class="number">8</span>),</span><br><span class="line">            key.user_key()) == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// 解析 tag, 包含 7 字节序列号和 1 字节操作类型(新增/删除)</span></span><br><span class="line">      <span class="keyword">const</span> <span class="keyword">uint64_t</span> tag = DecodeFixed64(key_ptr + key_length - <span class="number">8</span>);</span><br><span class="line">      <span class="comment">// 解析 tag 中的 ValueType. </span></span><br><span class="line">      <span class="comment">// leveldb 删除某个 user_key 的时候不是通过一个插入墓碑消息实现的吗? </span></span><br><span class="line">      <span class="comment">// 那怎么确保在 SkipList.Seek() 时候返回删除操作对应的数据项, </span></span><br><span class="line">      <span class="comment">// 而不是之前同样 user_key 对应的真正的插入操作对应的数据项呢? </span></span><br><span class="line">      <span class="comment">// 机巧就在于 internal_key 的比较原理 user_key 相等的时候, </span></span><br><span class="line">      <span class="comment">// tag 越大 internal_key 越小, </span></span><br><span class="line">      <span class="comment">// 这样后执行的删除操作的 tag(序列号递增了, 即使不递增, 但由于</span></span><br><span class="line">      <span class="comment">// 删除对应的 ValueType 大于插入对应的 ValueType 也可以确保</span></span><br><span class="line">      <span class="comment">// 后执行的删除操作的 tag 大于先执行的插入操作的 tag)</span></span><br><span class="line">      <span class="comment">// 这里有个比较技巧的地方. </span></span><br><span class="line">      <span class="keyword">switch</span> (<span class="keyword">static_cast</span>&lt;ValueType&gt;(tag &amp; <span class="number">0xff</span>)) &#123;</span><br><span class="line">        <span class="comment">// 找到了</span></span><br><span class="line">        <span class="keyword">case</span> kTypeValue: &#123;</span><br><span class="line">          Slice v = GetLengthPrefixedSlice(key_ptr + key_length);</span><br><span class="line">          value-&gt;assign(v.data(), v.size());</span><br><span class="line">          <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 找到了, 但是已经被删除了</span></span><br><span class="line">        <span class="keyword">case</span> kTypeDeletion:</span><br><span class="line">          *s = Status::NotFound(Slice());</span><br><span class="line">          <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>以上代码重要地方有如下几点:</p>
<ul>
<li>参数 LookupKey 结构如 internal key, 前文介绍过具体结构不再赘述. 要强调的是, 构造其实例时, user key 部分采用用户传入的, 但是序列号要用数据库目前最大值, 这样可以确保作为比较环节的序列号不会影响我们的查找过程.</li>
<li>在底层 SkipList 查找之前, 构造了一个临时的迭代器, 迭代器结构体待后文介绍 SkipList 时详细介绍.</li>
<li>迭代器的 Seek 方法返回的是第一个大于等于目标 key 的节点, 这个第一个非常非常重要, 这也是为什么我们前面强调 LookupKey 的序列号必须足够达到不污染查找过程.</li>
<li>Leveldb 的删除会插入一个墓碑消息, 其标识记录到 key 的 tag 部分, 所以查到数据的时候先不要高兴太早, 需要确认下 tag 的操作类型字段值.</li>
</ul>
<h2><span id="33-memtable-迭代器">3.3 MemTable 迭代器</span></h2><p>我们知道, MemTable 和磁盘上的 sstables 文件一起构成了数据全集, 而且 leveldb 支持迭代整个数据库. 这就要求 MemTable 也是可迭代的, 这样才能和磁盘文件迭代器串联在一起构成一个超级迭代器供用户迭代.</p>
<p>从 MemTable 实例返回一个迭代器的方法为:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Iterator* <span class="title">MemTable::NewIterator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> MemTableIterator(&amp;table_);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>MemTable 的迭代器实现很简单, 它提供了一个 <code>class leveldb::MemTableIterator</code>, 但整个类仅仅是一个 wrapper. 因为 MemTable 依赖的 SkipList 提供了一个完整的迭代器, MemTableIterator 仅仅在内部封装了一个 <code>leveldb::SkipList&lt;Key, Comparator&gt;::Iterator</code> 实例即实现了对 MemTable 的迭代, 所以它的实现就很简单了:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 该类全部方法都是对 leveldb::SkipList&lt;Key, Comparator&gt;::Iterator 方法的二次封装</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MemTableIterator</span>:</span> <span class="keyword">public</span> Iterator &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">MemTableIterator</span><span class="params">(MemTable::Table* table)</span> : <span class="title">iter_</span><span class="params">(table)</span> </span>&#123; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">bool</span> <span class="title">Valid</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> iter_.Valid(); &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Seek</span><span class="params">(<span class="keyword">const</span> Slice&amp; k)</span> </span>&#123; iter_.Seek(EncodeKey(&amp;tmp_, k)); &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">SeekToFirst</span><span class="params">()</span> </span>&#123; iter_.SeekToFirst(); &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">SeekToLast</span><span class="params">()</span> </span>&#123; iter_.SeekToLast(); &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Next</span><span class="params">()</span> </span>&#123; iter_.Next(); &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Prev</span><span class="params">()</span> </span>&#123; iter_.Prev(); &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Slice <span class="title">key</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> GetLengthPrefixedSlice(iter_.key()); &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Slice <span class="title">value</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    Slice key_slice = GetLengthPrefixedSlice(iter_.key());</span><br><span class="line">    <span class="keyword">return</span> GetLengthPrefixedSlice(key_slice.data() + key_slice.size());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 该迭代器默认返回 OK</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">status</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> Status::OK(); &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// 这个是真正干活的家伙</span></span><br><span class="line">  MemTable::Table::Iterator iter_;</span><br><span class="line">  <span class="comment">// 用于 EncodeKey 方法存储编码后的 internal_key</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">string</span> tmp_; </span><br><span class="line"></span><br><span class="line">  <span class="comment">// No copying allowed</span></span><br><span class="line">  MemTableIterator(<span class="keyword">const</span> MemTableIterator&amp;);</span><br><span class="line">  <span class="keyword">void</span> <span class="keyword">operator</span>=(<span class="keyword">const</span> MemTableIterator&amp;);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>下文介绍 SkipList 时会着重介绍迭代器.</p>
<h2><span id="34-memtable-内存估计">3.4 MemTable 内存估计</span></h2><p>MemTable 提供了一个方法 <code>ApproximateMemoryUsage()</code> 来返回当前 MemTable 占用的内存空间大小. 它的实现依托底层的 Arena, 实现很简单:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">size_t</span> <span class="title">MemTable::ApproximateMemoryUsage</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> arena_.MemoryUsage(); &#125;</span><br></pre></td></tr></table></figure>

<p>Arena 每次分配内存的时候, 都会将分配的内存字节数累加到计数器上.</p>
<h1><span id="4-memtable-比较器之-keycomparator">4 MemTable 比较器之 KeyComparator</span></h1><p>MemTable 既然是有序的, 那么任何操作就需要一个比较器. Memtable 内部定义了一个结构体 <code>struct leveldb::MemTable::KeyComparator</code>, 它封装了 MemTable 的比较逻辑, 具体如下:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 一个基于 internal_key 的比较器</span></span><br><span class="line"><span class="comment">// 注意下它的函数调用运算符重载方法的参数类型, 都是 char*, </span></span><br><span class="line"><span class="comment">// 原因就是 memtable 底层的 SkipList 的 key 类型就是 char*, </span></span><br><span class="line"><span class="comment">// 而类 KeyComparator 对象会被传给 SkipList 作为 key 比较器. </span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">KeyComparator</span> &#123;</span></span><br><span class="line">  <span class="keyword">const</span> InternalKeyComparator comparator;</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">KeyComparator</span><span class="params">(<span class="keyword">const</span> InternalKeyComparator&amp; c)</span> : <span class="title">comparator</span><span class="params">(c)</span> </span>&#123; &#125;</span><br><span class="line">  <span class="comment">// 注意, 这个操作符重载方法很关键, 该方法的会先从 char* 类型地址</span></span><br><span class="line">  <span class="comment">// 获取 internal_key, 然后对 internal_key 进行比较. </span></span><br><span class="line">  <span class="comment">// 该方法未在 memtable 直接调用, 而是被底层的 SkipList 使用了.</span></span><br><span class="line">  <span class="function"><span class="keyword">int</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* a, <span class="keyword">const</span> <span class="keyword">char</span>* b)</span> <span class="keyword">const</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>该结构体除了在 <code>MemTable::Get()</code> 直接使用比较 user key 以外, 还会被用于构造 SkipList 实例.</p>
<p>其中函数调用运算符的定义如下:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> MemTable::KeyComparator::<span class="keyword">operator</span>()(<span class="keyword">const</span> <span class="keyword">char</span>* aptr, <span class="keyword">const</span> <span class="keyword">char</span>* bptr)</span><br><span class="line">    <span class="keyword">const</span> &#123;</span><br><span class="line">  <span class="comment">// 提取数据项的前半部分, 即 internal_key</span></span><br><span class="line">  Slice a = GetLengthPrefixedSlice(aptr);</span><br><span class="line">  Slice b = GetLengthPrefixedSlice(bptr);</span><br><span class="line">  <span class="comment">// 对 internal_key 进行比较</span></span><br><span class="line">  <span class="keyword">return</span> comparator.Compare(a, b);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>代码注释中提到的 internal key 在前面章节介绍过了, 不再赘述. 该结构体真正干活的是其封装的 <code>comparator</code>, 它是一个 <code>class leveldb::InternalKeyComparator</code> 实例, 比较器很重要的有两点:</p>
<ul>
<li><ol>
<li>它有一个唯一的名字, 非后向兼容的比较器如果重名则会导致数据库混乱. 毕竟 leveldb 是有序数据库, 顺序至关重要, 一旦被破坏就会混乱.</li>
</ol>
</li>
<li><ol start="2">
<li>核心是 <code>Compare</code> 方法, 它决定了什么叫做顺序. <code>InternalKeyComparator</code> 用于比较 internal key, 而 internal key 包含 user key, 而 user key 是用户自己定义的所以比较器也由用户提供. 如果用户不提供, 则采用默认(见 <code>leveldb::Options::Options()</code> 定义)的 <code>class leveldb::&lt;unnamed&gt;::BytewiseComparatorImpl</code>, 它是一个基于字典序进行逐字节比较的内置 comparator 实现. <code>InternalKeyComparator</code> 比较时采用如下处理:</li>
</ol>
<ul>
<li>如果 user_key 相等, 则序列号越小 internal_key 越大;</li>
<li>如果序列号也相等, 则操作类型(更新/删除)越小 internal_key 越大(因为 leveldb 可以确保序列号单调递增且唯一, 所以实际上用不到该字段).</li>
</ul>
</li>
</ul>
<h1><span id="5-memtable-内存管理之-arena">5 MemTable 内存管理之 Arena</span></h1><p>Leveldb 专门为了管理内存定义了一个类 <code>class leveldb::Arena</code>, 可以把该类看作是 leveldb 的内存池实现, 但是它只负责对完分配, 并不会做回收重利用. 默认情况下, <code>Arena</code> 维护的内存块都是 4KB 大小.</p>
<p>注意, 同 <code>MemTable</code> 类一样, <code>Arena</code> 类全部操作需要调用者确保线程安全.</p>
<p>该类核心字段如下:</p>
<table>
<thead>
<tr>
<th align="center">字段</th>
<th align="center">类型</th>
<th align="center">用途</th>
</tr>
</thead>
<tbody><tr>
<td align="center">alloc_ptr_</td>
<td align="center">char*</td>
<td align="center">指向 arena 当前空闲字节起始地址</td>
</tr>
<tr>
<td align="center">alloc_bytes_remaining_</td>
<td align="center">size_t</td>
<td align="center">arena 当前空闲字节数</td>
</tr>
<tr>
<td align="center">blocks_</td>
<td align="center">std::vector&lt;char*&gt;</td>
<td align="center">存放通过 new[] 分配的全部内存块</td>
</tr>
<tr>
<td align="center">memory_usage_</td>
<td align="center">port::AtomicPointer</td>
<td align="center">arena 持有的全部内存字节数</td>
</tr>
</tbody></table>
<p>同 <code>MemTable</code>, <code>Arena</code> 也不支持拷贝构造和赋值构造.</p>
<p>该类核心方法如下:</p>
<table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">用途</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Arena()</td>
<td align="center">默认构造方法, 无任何限制.</td>
</tr>
<tr>
<td align="center">char* Allocate(size_t bytes)</td>
<td align="center">从该 arena 返回一个指向大小为 bytes 的内存的指针. bytes 必须大于 0, 具体见实现.</td>
</tr>
<tr>
<td align="center">char* AllocateAligned(size_t bytes)</td>
<td align="center">返回一个对齐后的可用内存的地址. 具体对齐逻辑见实现.</td>
</tr>
<tr>
<td align="center">size_t MemoryUsage() const</td>
<td align="center">返回该 arena 持有的全部内存的字节数的估计值(未采用同步设施).</td>
</tr>
<tr>
<td align="center">size_t MemoryUsage() const</td>
<td align="center">返回该 arena 持有的全部内存的字节数的估计值(未采用同步设施).</td>
</tr>
</tbody></table>
<h2><span id="51-如何向-arena-申请指定大小的内存">5.1 如何向 Arena 申请指定大小的内存</span></h2><p>可以通过方法 <code>Arena::Allocate</code> 申请指定大小的内存, 该方法会被 memtable 的 <code>Add()</code> 方法直接调用. 如果当前 <code>Arena</code> 内存池剩余内存足够则直接分配, 否则向操作系统进行申请. </p>
<p>具体处理流程如下:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">char</span>* <span class="title">Arena::Allocate</span><span class="params">(<span class="keyword">size_t</span> bytes)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 如果我们允许分配 0 字节内存, 那该方法返回什么的语义就有点乱, </span></span><br><span class="line">  <span class="comment">// 所以我们不允许返回 0 字节(我们内部也没这个需求). </span></span><br><span class="line">  assert(bytes &gt; <span class="number">0</span>);</span><br><span class="line">  <span class="comment">// arena 剩余内存够则直接分配</span></span><br><span class="line">  <span class="keyword">if</span> (bytes &lt;= alloc_bytes_remaining_) &#123; </span><br><span class="line">    <span class="keyword">char</span>* result = alloc_ptr_;</span><br><span class="line">    alloc_ptr_ += bytes;</span><br><span class="line">    alloc_bytes_remaining_ -= bytes;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// arena 可用内存不能满足用户需求, 向系统申请新内存</span></span><br><span class="line">  <span class="keyword">return</span> AllocateFallback(bytes);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面的 <code>AllocateFallback()</code> 根据用户需求决定向系统申请的内存大小, 具体处理如下:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 当 arena 可用内存不够时调用该方法来申请新内存</span></span><br><span class="line"><span class="function"><span class="keyword">char</span>* <span class="title">Arena::AllocateFallback</span><span class="params">(<span class="keyword">size_t</span> bytes)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 如果用户要申请的内存超过默认内存块大小(4KB)的 1/4, </span></span><br><span class="line">  <span class="comment">// 则单独按照用户指定大小分配一个内存块, 否则单独分配一个默认</span></span><br><span class="line">  <span class="comment">// 大小(4KB)的内存块给用户会造成太多空间浪费. </span></span><br><span class="line">  <span class="comment">// 新分配的内存块会被加入 arena 然后将其起始地址返回给用户,</span></span><br><span class="line">  <span class="comment">// 所分配的内存不会纳入 Arena 管理, 但是占用空间会被纳入计数. </span></span><br><span class="line">  <span class="keyword">if</span> (bytes &gt; kBlockSize / <span class="number">4</span>) &#123;</span><br><span class="line">    <span class="keyword">char</span>* result = AllocateNewBlock(bytes);</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 直接分配一个默认大小内存块给用户, 此处所分配</span></span><br><span class="line">  <span class="comment">// 内存会被纳入 Arena 管理, 等待用户后续内存申请.</span></span><br><span class="line">  <span class="comment">// alloc_ptr_ 被覆盖之前指向的空间被浪费了.</span></span><br><span class="line">  alloc_ptr_ = AllocateNewBlock(kBlockSize);</span><br><span class="line">  alloc_bytes_remaining_ = kBlockSize;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// result 是返回给用户的</span></span><br><span class="line">  <span class="keyword">char</span>* result = alloc_ptr_;</span><br><span class="line">  <span class="comment">// 移动 alloc_ptr_ 指向未被占用内存</span></span><br><span class="line">  alloc_ptr_ += bytes;</span><br><span class="line">  alloc_bytes_remaining_ -= bytes;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述处理中还涉及一个辅助方法 <code>AllocateNewBlock</code>, 它负责向系统申请固定大小内存并将其纳入 Arena 管理.</p>
<p>具体处理如下:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 分配一个大小为 block_bytes 的块并将其加入到 arena</span></span><br><span class="line"><span class="function"><span class="keyword">char</span>* <span class="title">Arena::AllocateNewBlock</span><span class="params">(<span class="keyword">size_t</span> block_bytes)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">char</span>* result = <span class="keyword">new</span> <span class="keyword">char</span>[block_bytes];</span><br><span class="line">  blocks_.push_back(result);</span><br><span class="line">  <span class="comment">// 调用者确保线程安全, 这里无需强制同步.</span></span><br><span class="line">  memory_usage_.NoBarrier_Store(</span><br><span class="line">      <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">void</span>*&gt;(MemoryUsage() + block_bytes + <span class="keyword">sizeof</span>(<span class="keyword">char</span>*)));</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2><span id="52-如何向-arena-申请对齐后的内存">5.2 如何向 Arena 申请对齐后的内存</span></h2><p>除了上面提到的 <code>Arena::Allocate(size_t bytes)</code> 方法, Arena 还提供另一个内存分配方法, 它支持按照特定字节大小将所分配的内存进行对齐, 它的签名为 <code>char* Arena::AllocateAligned(size_t bytes)</code>, 该方法没有被 memtable 代码直接调用, 而是由其底层依赖的 SkipList 所使用. 后面分析 SkipList 代码时还会再次说明.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 按照 8 字节或者指针长度进行内存对齐, 然后返回对齐后分配的内存起始地址</span></span><br><span class="line"><span class="function"><span class="keyword">char</span>* <span class="title">Arena::AllocateAligned</span><span class="params">(<span class="keyword">size_t</span> bytes)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 如果机器指针的对齐方式超过 8 字节则按照指针的对齐方式进行对齐; </span></span><br><span class="line">  <span class="comment">// 否则按照 8 字节进行对齐. </span></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> align = (<span class="keyword">sizeof</span>(<span class="keyword">void</span>*) &gt; <span class="number">8</span>) ? <span class="keyword">sizeof</span>(<span class="keyword">void</span>*) : <span class="number">8</span>;</span><br><span class="line">  <span class="comment">// 确保当按照指针大小对齐时, 机器的指针大小是 2 的幂</span></span><br><span class="line">  assert((align &amp; (align<span class="number">-1</span>)) == <span class="number">0</span>);</span><br><span class="line">  <span class="comment">// 求 alloc_ptr 与 align 的模运算的结果, </span></span><br><span class="line">  <span class="comment">// 以确认 alloc_ptr 是否恰好为 align 的整数倍. </span></span><br><span class="line">  <span class="keyword">size_t</span> current_mod = <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">uintptr_t</span>&gt;(alloc_ptr_) &amp; (align<span class="number">-1</span>);</span><br><span class="line">  <span class="comment">// 如果 alloc_ptr 的值恰好为 align 整数倍, </span></span><br><span class="line">  <span class="comment">// 则已经满足对齐要求, 可以从该地址直接进行分配; </span></span><br><span class="line">  <span class="comment">// 否则, 需要进行手工对齐, 比如 align 为 8, alloc_ptr 等于 15, </span></span><br><span class="line">  <span class="comment">// 则需要将 alloc_ptr 增加 align - current_mod = 8 - 7 = 1 个字节. </span></span><br><span class="line">  <span class="keyword">size_t</span> slop = (current_mod == <span class="number">0</span> ? <span class="number">0</span> : align - current_mod);</span><br><span class="line">  <span class="comment">// 虽然用户申请 bytes 个字节, 但是因为对齐要求, </span></span><br><span class="line">  <span class="comment">// 实际消耗的内存大小为 bytes + slop</span></span><br><span class="line">  <span class="keyword">size_t</span> needed = bytes + slop; </span><br><span class="line">  <span class="keyword">char</span>* result;</span><br><span class="line">  <span class="comment">// 如果 arena 空闲内存满足要求则直接分配</span></span><br><span class="line">  <span class="keyword">if</span> (needed &lt;= alloc_bytes_remaining_) &#123; </span><br><span class="line">    <span class="comment">// 将 result 指向对齐后的地址(对齐会导致前 slop 个字节被浪费掉)</span></span><br><span class="line">    result = alloc_ptr_ + slop; </span><br><span class="line">    alloc_ptr_ += needed;</span><br><span class="line">    alloc_bytes_remaining_ -= needed;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">    <span class="comment">// 否则从堆中申请新的内存块, 注意重新分配</span></span><br><span class="line">    <span class="comment">// 内存块时 malloc 会保证对齐, 无序再如上做手工对齐.</span></span><br><span class="line">    result = AllocateFallback(bytes);</span><br><span class="line">  &#125;</span><br><span class="line">  assert((<span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">uintptr_t</span>&gt;(result) &amp; (align<span class="number">-1</span>)) == <span class="number">0</span>);</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1><span id="6-memtable-底层存储之-skiplist">6 MemTable 底层存储之 SkipList</span></h1><p>MemTable 是有序的, 为了确保查询和插入迅速, 它采用了 SkipList 作为存储结构.</p>
<h2><span id="61-skiplist-原理简介">6.1 SkipList 原理简介</span></h2><p>开始之前先大体介绍下 SkipList 这个数据结构. 目前该数据结构在开源项目中用的越来越多代替红黑树等存在, 这里包括 Redis 都用到了该数据结构. </p>
<p>你在学校可能没学过这个数据结构, 但是你肯定在操作系统课上学过多级页表. SkipList 加速原理跟多级页表差不多, 当然后者如此设计也为了节省存储. 整个内存字节空间分成若干页面, 然后把全部页面分成若干组, 然后把上一步若干组进一步分为多个二级组 …; 查找时从最外层找起, 从外向里索引粒度逐渐减小, 最后一下子定位到内存空间某个字节位置, 这里虽然没说排序, 但是由于每个字节已经被编码所以其实也是有序的. </p>
<p>SkipList 与之类似, 每个元素所在节点在一个链表上按序排列, 如果我们把每个节点看作内存空间一个字节位置, 那么接下来我们就要为它们建索引了:</p>
<ul>
<li>第 0 级索引就是原始链表, 一个接一个, 共 $n$ 个节点</li>
<li>第 $1$ 级索引就是在上一级基础上间隔一个选取一个, 这样构成第 $1$ 级索引, 共 $\frac{n}{2}$ 个节点</li>
<li>第 $2$ 级索引也是在上一级基础设间隔一个取一个, 这样构成第 $2$ 级索引, 共 $\frac{n}{2^2}$ 个节点</li>
<li>… …</li>
<li>最后从上一级只能提取两个节点了, 这就是最后一级索引了因为没必要再往下分了, 假设共有 h 级, 那么这就是第 h-1 级索引, 该级索引共 $\frac{n}{2^{h-1}}$ 个节点</li>
</ul>
<p>我们调过头反着看, 每一层索引节点数都是其上一层索引的 $\frac{1}{2}$, 这不就是个平衡二叉树吗? 总的节点数为 $2n$ 个. 每次查询时, 从最外层索引向里找, 每次在每一层只需查询一次, 最多查询 h 次也就是 $\log_2^{2n} = 1 + \log_2^n \approx \log_2^n$ 即可找到或则确认不存在. 我们把最外层看作最高层, 最里层看作最底层, 则 SkipList 的高度为 h.</p>
<p>可以看出时间复杂度同平衡二叉树如红黑树是一样的, 只是空间复杂度要多一倍. 那为什么不用红黑树呢, 嘿嘿, 你手写一次就知道了. 那么 SkipList 是如何确保平衡的呢? 方法强大又朴素, 抛硬币, 五五分. 每次插入元素时, 自上而下定位到其插入位置, 在第 $0$ 级插入元素时, 通过抛硬币的办法决定是否将该元素拔擢到第 $1$ 级索引中, 如果拔擢成功则再次抛硬币决定是否将其继续拔擢到第 $2$ 级索引, 以此类推, 除非上一级拔擢成功则继续抛硬币, 否则停止拔擢过程, 索引插入的时间复杂度也是 $\log_2^n$. 删除类似, 从外层到内层, 查找到该元素后, 则从该层开始递进删除每一层中的该元素, 时间复杂度依然是 $\log_2^n$.</p>
<p>好了, 我们来看看 leveldb 是如何实现 SkipList 的.</p>
<h2><span id="62-skiplist-实现">6.2 SkipList 实现</span></h2><p>下面详细说明 SkipList 实现时的细节以及一些辅助的数据结构.</p>
<h3><span id="621-skiplist-核心数据成员">6.2.1 SkipList 核心数据成员</span></h3><p>该类核心字段如下:</p>
<table>
<thead>
<tr>
<th align="center">字段</th>
<th align="center">类型</th>
<th align="center">用途</th>
</tr>
</thead>
<tbody><tr>
<td align="center">compare_</td>
<td align="center">Comparator</td>
<td align="center">比较器, 用于比较 key, 初始化以后不可更改</td>
</tr>
<tr>
<td align="center">arena_</td>
<td align="center">Arena*</td>
<td align="center">用于分配 Node 所用的内存</td>
</tr>
<tr>
<td align="center">head_</td>
<td align="center">Node*</td>
<td align="center">dummy node</td>
</tr>
<tr>
<td align="center">max_height_</td>
<td align="center">port::AtomicPointer</td>
<td align="center">指向存储当前 skiplist 最大高度的变量的地址, max_height_ &lt;= kMaxHeight.</td>
</tr>
<tr>
<td align="center">rnd_</td>
<td align="center">Random</td>
<td align="center">指向存储当前 skiplist 最大高度的变量的地址, max_height_ &lt;= kMaxHeight.</td>
</tr>
</tbody></table>
<p>同 <code>MemTable</code>, <code>SkipList</code> 也不支持拷贝构造和赋值构造.</p>
<h3><span id="622-skiplist-核心方法">6.2.2 SkipList 核心方法</span></h3><p>该类核心方法如下:</p>
<table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">用途</th>
</tr>
</thead>
<tbody><tr>
<td align="center">explicit SkipList(Comparator cmp, Arena* arena)</td>
<td align="center">构造方法, cmp 用于比较 keys, arena 用做内存池.</td>
</tr>
<tr>
<td align="center">void Insert(const Key&amp; key)</td>
<td align="center">将 key 插入到 SkipList 实例中.</td>
</tr>
<tr>
<td align="center">bool Contains(const Key&amp; key) const</td>
<td align="center">当且仅当 sliplist 中存在与 key 相等的数据项时才返回 true.</td>
</tr>
</tbody></table>
<p>线程安全相关说明：</p>
<ul>
<li>写操作 <code>Insert</code> 需要外部同步设施, 比如 mutex. </li>
<li>读操作 <code>Contains</code> 需要一个保证, 即读操作执行期间, SkipList 不能被销毁; 只要保证这一点, 读操作不需要额外的同步措施. </li>
</ul>
<p>SkipList 运行不变式：</p>
<ul>
<li>(1) 已分配的 nodes 直到 SkipList 被销毁才能被删除. 这很容易保证, 因为我们不会删除任何 SkipList nodes. </li>
<li>(2) 一个 Node 一旦被链接到 SkipList 上, 那这个 Node 的内容, 除了 next/pre 指针以外, 都是 immutable 的. </li>
</ul>
<h4><span id="6223-辅助数据结构-node">6.2.2.3 辅助数据结构 Node</span></h4><p>SkipList 每个节点由类 <code>template&lt;class Key, class Comparator&gt; struct leveldb::Node&lt;Key, Comparator&gt;</code> 表示, 它包含两数据成员:</p>
<ul>
<li><code>key</code>, 其实叫 entry 更符合实际. 因为该成员其实不只包含 key, 还包含 value 部分. 但是只要涉及查询, 比较时仅比较前半部分即 internal key.</li>
<li><code>next_</code>, 默认是一个长度为 1 的 <code>port::AtomicPointer</code> 数组(但是我估计作者们想分配长度为 0 的数组, 但是标准 C/++ 不允许). 这个数组的最大长度取决于当前节点最大要做第几级索引(从 0 开始计数). 一旦确定第几级, 后续调用 <code>leveldb::SkipList&lt;Key, Comparator&gt;::NewNode(const Key &amp;key, int height)</code> 时就能把 Node 的 <code>key</code> 成员和当前数组分配到连续内存中, 这样对缓存友好, 而且释放时可以一次性释放. 如果 <code>next_</code> 是指向数组的指针则要分多次释放了.</li>
</ul>
<p>Node 的方法都比较简单, 共四个, 详细注释如下:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 自带 acquire 语义, 返回该 node 在第 n 级(计数从 0 开始) 索引层的后继节点的指针</span></span><br><span class="line"><span class="function">Node* <span class="title">Next</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">  assert(n &gt;= <span class="number">0</span>);</span><br><span class="line">  <span class="comment">// 采用 acquire 语义可以确保如下两点:</span></span><br><span class="line">  <span class="comment">// - 当前线程后续针对 next_[n] 节点的读写不会被重排序到此 load 之前;</span></span><br><span class="line">  <span class="comment">// - 其它线程在此 load 之前针对 next_[n] 节点的全部写操作此时均可见.</span></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">reinterpret_cast</span>&lt;Node*&gt;(next_[n].Acquire_Load());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 自带 release 语义, 设置该 node 在第 n 级(计数从 0 开始) 索引层的后继节点</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">SetNext</span><span class="params">(<span class="keyword">int</span> n, Node* x)</span> </span>&#123;</span><br><span class="line">  assert(n &gt;= <span class="number">0</span>);</span><br><span class="line">  <span class="comment">// 采用 release 语义可以确保如下两点:</span></span><br><span class="line">  <span class="comment">// - 在此 store 之前, 当前线程针对 next_[n] 节点的读写不会被重排序到此 store 之后;</span></span><br><span class="line">  <span class="comment">// - 在此 store 之后, 其它线程针对 next_[n] 节点的读写看到的都是此 store 写入的值.</span></span><br><span class="line">  next_[n].Release_Store(x);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 同 Next, 但无同步防护.</span></span><br><span class="line"><span class="function">Node* <span class="title">NoBarrier_Next</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">  assert(n &gt;= <span class="number">0</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">reinterpret_cast</span>&lt;Node*&gt;(next_[n].NoBarrier_Load());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 同 SetNext, 但无同步防护.</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">NoBarrier_SetNext</span><span class="params">(<span class="keyword">int</span> n, Node* x)</span> </span>&#123;</span><br><span class="line">  assert(n &gt;= <span class="number">0</span>);</span><br><span class="line">  next_[n].NoBarrier_Store(x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面提到的 acquire/release 语义, 将会在本文最后一节做详细介绍, 感兴趣可以阅读.</p>
<h4><span id="6224-用于为新数据分配存储的-newnode-方法">6.2.2.4 用于为新数据分配存储的 NewNode 方法</span></h4><p>该方法用于为 SkipList 执行 Insert 方法时为所插入数据分配一个节点. 传入的第一个参数为要存储的数据项(虽然它叫 key, 但只有前半截是所谓的 internal key, 后半截是 value size 和 value); 第二个参数是通过 <code>RandomHeight()</code> 方法预先计算的索引层数, 即该节点最多可以做第几级(从 0 开始计数)索引.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Key, <span class="class"><span class="keyword">class</span> <span class="title">Comparator</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">typename</span> <span class="title">SkipList</span>&lt;Key,Comparator&gt;:</span>:Node*</span><br><span class="line">SkipList&lt;Key,Comparator&gt;::NewNode(<span class="keyword">const</span> Key&amp; key, <span class="keyword">int</span> height) &#123;</span><br><span class="line">  <span class="comment">// 要分配的空间存储的是用户数据和当前节点在 SkipList 各个索引层的后向指针, </span></span><br><span class="line">  <span class="comment">// 其中后者是现算出来的.</span></span><br><span class="line">  <span class="keyword">char</span>* mem = arena_-&gt;AllocateAligned(</span><br><span class="line">      <span class="comment">// 为啥减 1? 因为 Node.next_ 已默认分配了一项</span></span><br><span class="line">      <span class="keyword">sizeof</span>(Node) + <span class="keyword">sizeof</span>(port::AtomicPointer) * (height - <span class="number">1</span>));</span><br><span class="line">  <span class="comment">// 此乃定位 new, 即在 mem 指向内存位置创建 Node 对象</span></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> (mem) Node(key); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里分配内存用到了我们前面介绍 <code>Arena</code> 类时分析的 <code>AllocateAligned</code> 方法. 该方法针对指针类型做了内存对齐(<code>AtomicPointer</code> 本身仅一个 <code>void*</code> 指针类型数据成员).</p>
<h4><span id="6225-用于确定某个节点索引层数的-randomheight-方法">6.2.2.5 用于确定某个节点索引层数的 RandomHeight 方法</span></h4><p>该方法对应前面讲述 SkipList 原理时如何确定一个节点要被拔擢到最高第几层. 那里说是抛硬币, 五五分. Leveldb 实现 SkipList 时采用更为保守的拔擢策略, 每次递进概率仅为 1/4.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 返回一个高度值, 返回值落于 [1, kMaxHeight], </span></span><br><span class="line"><span class="comment">// SkipList 实现默认索引层最多 12 个.</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Key, <span class="class"><span class="keyword">class</span> <span class="title">Comparator</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">int</span> <span class="title">SkipList</span>&lt;Key,Comparator&gt;:</span>:RandomHeight() &#123;</span><br><span class="line">  <span class="comment">// 以 1/kBranching 概率循环递增 height. </span></span><br><span class="line">  <span class="comment">// 每次拔擢都是在前一次拔擢成功的前提下再进行, 如果前一次失败则停止拔擢. </span></span><br><span class="line">  <span class="comment">// 假设 kBranching == 4, 则返回 1 概率为 1/4, 返回 2 概率为 1/16, .... </span></span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> kBranching = <span class="number">4</span>;</span><br><span class="line">  <span class="comment">// 每个节点最少有一层索引(就是原始链表)</span></span><br><span class="line">  <span class="keyword">int</span> height = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">while</span> (height &lt; kMaxHeight &amp;&amp; ((rnd_.Next() % kBranching) == <span class="number">0</span>)) &#123;</span><br><span class="line">    height++;</span><br><span class="line">  &#125;</span><br><span class="line">  assert(height &gt; <span class="number">0</span>);</span><br><span class="line">  assert(height &lt;= kMaxHeight);</span><br><span class="line">  <span class="keyword">return</span> height;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4><span id="6226-用于插入数据的-insert-方法">6.2.2.6 用于插入数据的 Insert 方法</span></h4><p>插入过程说起来也比较简单:</p>
<ol>
<li>查找待插入数据的前驱节点, 这个是通过从 SkipList 查找第一个不小于待插入数据的节点来做到的.</li>
<li>确定待插入节点的索引层数, 这个就是随机大法.</li>
<li>更新 SkipList 当前索引层数最大值</li>
<li>为待插入数据生成一个新节点</li>
<li>将新节点插入到前驱和后驱之间, 每一个索引层都要插入一遍.</li>
</ol>
<p>具体代码如下:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 该方法非线程安全, 需要外部同步设施. </span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Key, <span class="class"><span class="keyword">class</span> <span class="title">Comparator</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">void</span> <span class="title">SkipList</span>&lt;Key,Comparator&gt;:</span>:Insert(<span class="keyword">const</span> Key&amp; key) &#123;</span><br><span class="line">  <span class="comment">// pre 将用于存储 key 对应的各个索引层的前驱节点</span></span><br><span class="line">  Node* prev[kMaxHeight];</span><br><span class="line">  <span class="comment">// 找到第一个大约等于目标 key 的节点, 一会会把 key</span></span><br><span class="line">  <span class="comment">// 插到这个节点前面.</span></span><br><span class="line">  <span class="comment">// 如果为 nullptr 表示当前 SkipList 节点都比 key 小.</span></span><br><span class="line">  Node* x = FindGreaterOrEqual(key, prev); </span><br><span class="line"></span><br><span class="line">  <span class="comment">// 虽然 x 是我们找到的第一个大于等于目标 key 的节点, </span></span><br><span class="line">  <span class="comment">// 但是 leveldb 不允许重复插入 key 相等的数据项.</span></span><br><span class="line">  assert(x == <span class="literal">nullptr</span> || !Equal(key, x-&gt;key));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 确定待插入节点的最大索引层数</span></span><br><span class="line">  <span class="keyword">int</span> height = RandomHeight();</span><br><span class="line">  <span class="comment">// 更新 SkipList 实例维护的最大索引层数</span></span><br><span class="line">  <span class="keyword">if</span> (height &gt; GetMaxHeight()) &#123;</span><br><span class="line">    <span class="comment">// 如果最大索引层数有变, 则当前节点将是索引层数最多的节点,</span></span><br><span class="line">    <span class="comment">// 需要将前面求得的待插入节点的前驱节点高度补齐.</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = GetMaxHeight(); i &lt; height; i++) &#123;</span><br><span class="line">      <span class="comment">// 新生成了几个 level, key 对应的前驱节点肯定都是 dummy head</span></span><br><span class="line">      prev[i] = head_; </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//fprintf(stderr, &quot;Change height from %d to %d\n&quot;, max_height_, height);</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这里在修改 max_height_ 无需同步, 哪怕同时有多个并发读线程. </span></span><br><span class="line">    <span class="comment">// 其它并发读线程如果观察到新的 max_height_ 值, </span></span><br><span class="line">    <span class="comment">// 那它们将会要么看到 dummy head 新的索引层(注意 SkipList </span></span><br><span class="line">    <span class="comment">// 初始化时会把 dummy head 的索引高度直接初始化为最大, 默认是 12, </span></span><br><span class="line">    <span class="comment">// 所以不存在越界问题)的值都为 nullptr, 要么看到的是</span></span><br><span class="line">    <span class="comment">// 下面循环将要赋值的新节点 x. </span></span><br><span class="line">    max_height_.NoBarrier_Store(<span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">void</span>*&gt;(height));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 为待插入数据创建一个新节点</span></span><br><span class="line">  x = NewNode(key, height);</span><br><span class="line">  <span class="comment">// 将 x 插入到每一层前后节点之间, 注意是每一层, </span></span><br><span class="line">  <span class="comment">// 插入的时候都是先采用 no barrier 方式为 x 后继赋值, 此时 x 还不会被其它线程看到; </span></span><br><span class="line">  <span class="comment">// 然后插入一个 barrier, 则上面 no barrier 的修改针对全部线程都可见了(其中也包括</span></span><br><span class="line">  <span class="comment">// 了 NewNode 时可能发生的通过 NoBarrier_Store 方式修改的 arena_.memory_usage_), </span></span><br><span class="line">  <span class="comment">// 最后修改 x 前驱的后继为自己. </span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; height; i++) &#123;</span><br><span class="line">    <span class="comment">// 注意该循环就下面两步, 而且只有第二步采用了同步设施, 尽管如此,</span></span><br><span class="line">    <span class="comment">// 第一步的写操作对其它线程也是可见的. </span></span><br><span class="line">    <span class="comment">// 这是 Release-Acquire ordering 语义所保证的. </span></span><br><span class="line">    x-&gt;NoBarrier_SetNext(i, prev[i]-&gt;NoBarrier_Next(i));</span><br><span class="line">    prev[i]-&gt;SetNext(i, x);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4><span id="6226-用于查找数据是否存在的-contains-方法">6.2.2.6 用于查找数据是否存在的 Contains 方法</span></h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Key, <span class="class"><span class="keyword">class</span> <span class="title">Comparator</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">bool</span> <span class="title">SkipList</span>&lt;Key,Comparator&gt;:</span>:Contains(<span class="keyword">const</span> Key&amp; key) <span class="keyword">const</span> &#123;</span><br><span class="line">  Node* x = FindGreaterOrEqual(key, <span class="literal">nullptr</span>);</span><br><span class="line">  <span class="keyword">if</span> (x != <span class="literal">nullptr</span> &amp;&amp; Equal(key, x-&gt;key)) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>很简单有没有? 只需检查 <code>FindGreaterOrEqual</code> 返回的节点包含的 key 是否与目标 key 一致即可确认.</p>
<h4><span id="6227-读写都要依赖的辅助方法-findgreaterorequal">6.2.2.7 读写都要依赖的辅助方法 FindGreaterOrEqual</span></h4><p>上面提到的 <code>Insert()</code> 方法和 <code>Contains()</code> 方法都用到了 <code>FindGreaterOrEqual()</code> 方法, 下面马上要介绍的迭代器而用到了该方法. 有必要单独介绍一下.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 返回第一个大于等于目标 key 的 node 的指针; </span></span><br><span class="line"><span class="comment">// 返回 nullptr 意味着全部 nodes 的 key 都小于参数 key.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// 如果想获取目标节点的前驱, 则令参数 pre 非空, </span></span><br><span class="line"><span class="comment">// 所找到的 node 所在索引层的前驱节点将被保存到 pre[] 对应层.</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Key, <span class="class"><span class="keyword">class</span> <span class="title">Comparator</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">typename</span> <span class="title">SkipList</span>&lt;Key,Comparator&gt;:</span>:Node* </span><br><span class="line">SkipList&lt;Key,Comparator&gt;::FindGreaterOrEqual(<span class="keyword">const</span> Key&amp; key, Node** prev)</span><br><span class="line">    <span class="keyword">const</span> &#123;</span><br><span class="line">  <span class="comment">// head_ 为 SkipList 原始数据链表的起始节点,</span></span><br><span class="line">  <span class="comment">// 该节点不存储用户数据, 仅用作哨兵.</span></span><br><span class="line">  Node* x = head_;</span><br><span class="line">  <span class="comment">// 每次查找都是从最高索引层开始查找, 只要确认可能存在</span></span><br><span class="line">  <span class="comment">// 才会降到下一级更细致索引层继续查找.</span></span><br><span class="line">  <span class="comment">// 索引层计数从 0 开始, 所以这里减一才是最高层.</span></span><br><span class="line">  <span class="keyword">int</span> level = GetMaxHeight() - <span class="number">1</span>; </span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="comment">// 下面用的 Next 方法是带同步设施的, 其实由于 SkipList 对外开放的操作</span></span><br><span class="line">    <span class="comment">// 需要调用者自己提供同步, 所以这里可以直接用 NoBarrier_Next.</span></span><br><span class="line">    Node* next = x-&gt;Next(level);</span><br><span class="line">    <span class="keyword">if</span> (KeyIsAfterNode(key, next)) &#123;</span><br><span class="line">      <span class="comment">// key 大于 next, 在该索引层继续向后找</span></span><br><span class="line">      x = next; </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// key 可能存在.</span></span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      <span class="comment">// 如果 key 比 SkipList 中每个 node 的 key 都小, </span></span><br><span class="line">      <span class="comment">// 那么最后返回的 node 为 head_-&gt;Next(0), </span></span><br><span class="line">      <span class="comment">// 同时 pre 里面存的都是 dummy head; </span></span><br><span class="line">      <span class="comment">// 调用者需要使用返回的 node 与自己持有 key进一步进行对比,</span></span><br><span class="line">      <span class="comment">// 以确定是否找到目标节点. </span></span><br><span class="line">      <span class="keyword">if</span> (prev != <span class="literal">nullptr</span>) prev[level] = x;</span><br><span class="line">      <span class="keyword">if</span> (level == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 就是它！如果 key 比 SkipList 里每个 node 的都大, 则 next 最终为 nullptr.</span></span><br><span class="line">        <span class="keyword">return</span> next;  </span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 确定目标范围, 但是粒度太粗, 下沉一层继续找</span></span><br><span class="line">        level--;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h4><span id="6228-辅助数据结构-iterator">6.2.2.8 辅助数据结构 Iterator</span></h4><p>上面讲了好些方法, 怎么没有根据 key 查找 value 的方法呢? 别急, 因为实现这个功能依赖一个新的数据结构 <code>Iterator</code>.</p>
<p>它包含两个数据成员:</p>
<ul>
<li><code>list_</code>, 这是一个 <code>SkipList*</code>, 指向自己要迭代的 SkipList 实例.</li>
<li><code>node_</code>, 指向目前迭代到的位置, 即 SkipList 上的某个节点.</li>
</ul>
<p>要构造一个迭代器, 非常简单, 只需传入一个要迭代的 SkipList 实例, 剩下的交给迭代器:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Key, <span class="class"><span class="keyword">class</span> <span class="title">Comparator</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">inline</span> <span class="title">SkipList</span>&lt;Key,Comparator&gt;:</span>:Iterator::Iterator(<span class="keyword">const</span> SkipList* <span class="built_in">list</span>) &#123;</span><br><span class="line">  list_ = <span class="built_in">list</span>;</span><br><span class="line">  node_ = <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>下面就是我们之前提到的根据某个 key 查找对应 value 的方法了:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定位 key &gt;= target 的第一个 node</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Key, <span class="class"><span class="keyword">class</span> <span class="title">Comparator</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">inline</span> <span class="title">void</span> <span class="title">SkipList</span>&lt;Key,Comparator&gt;:</span>:Iterator::Seek(<span class="keyword">const</span> Key&amp; target) &#123;</span><br><span class="line">  <span class="comment">// 我们只是要查找, 后续不做插入, 所以第二个用于存储 target 前驱节点的数组为 nullptr</span></span><br><span class="line">  node_ = list_-&gt;FindGreaterOrEqual(target, <span class="literal">nullptr</span>); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实现也非常简单. 查找到的节点保存到迭代器的 <code>node_</code> 成员中.</p>
<p>说到迭代器不可避免要谈到向后/向前移动:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将迭代器移动到下个位置. </span></span><br><span class="line"><span class="comment">// 要求：当前迭代器有效.</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Key, <span class="class"><span class="keyword">class</span> <span class="title">Comparator</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">inline</span> <span class="title">void</span> <span class="title">SkipList</span>&lt;Key,Comparator&gt;:</span>:Iterator::Next() &#123;</span><br><span class="line">  assert(Valid());</span><br><span class="line">  <span class="comment">// 因为 level 0 存的是全部 nodes, 所以迭代整</span></span><br><span class="line">  <span class="comment">// 个 skiplist 时只访问 level 0 即可. </span></span><br><span class="line">  node_ = node_-&gt;Next(<span class="number">0</span>); </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将迭代器倒退一个位置. </span></span><br><span class="line"><span class="comment">// 要求：当前迭代器有效.</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Key, <span class="class"><span class="keyword">class</span> <span class="title">Comparator</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">inline</span> <span class="title">void</span> <span class="title">SkipList</span>&lt;Key,Comparator&gt;:</span>:Iterator::Prev() &#123;</span><br><span class="line">  <span class="comment">// 注意, Node 结构是没有 pre 指针的, 但因为 SkipList nodes 本来</span></span><br><span class="line">  <span class="comment">// 就是按序从左到右排列, 所以直接采用二分查找来定位最后一个 key 小于</span></span><br><span class="line">  <span class="comment">// 迭代器当前指向的 node 的 key 节点即可. </span></span><br><span class="line">  assert(Valid());</span><br><span class="line">  node_ = list_-&gt;FindLessThan(node_-&gt;key);</span><br><span class="line">  <span class="keyword">if</span> (node_ == list_-&gt;head_) &#123;</span><br><span class="line">    node_ = <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1><span id="7-番外-c-的内存排序">7 番外: C++ 的内存排序</span></h1><p>本节内容主要参考 <a target="_blank" rel="noopener" href="https://en.cppreference.com/w/cpp/atomic/memory_order">cppreference</a>. Leveldb 内部多处用到同步设施, 这一块内容比较多, 后续会单独开辟一片文章介绍 leveldb 的原子类型实现.</p>
<p><code>std::memory_order</code> 指定了如何围绕原子操作对内存访问（包括常规的、非原子的内存访问）进行排序。当无任何顺序限制的时候, 在多核系统中, 当多个线程同时读写多个变量时, 一个线程观测到的某个值的变化顺序可能与负责写的线程的写顺序不同. 实际上, 甚至多个读线程之间各自观测到的变化顺序也互不相同.  此类情况哪怕在单核系统上也会发生, 因为只要内存模型允许, 编译器会在编译程序时进行指令重排序. </p>
<p>库中的全部原子操作的默认行为提供了顺序一致的排序(具体见后文). 这可能会造成性能损失, 但是可以给库中的原子操作提供额外的 <code>std::memory_order</code> 参数来指定具体的顺序限制, 除了保障原子性, 编译器和处理器必须执行这类限制确保顺序性.</p>
<ul>
<li>memory_order_relaxed<ul>
<li>Relaxed 操作: 仅保证该操作的原子性, 不会针对其它读写操作施加同步或者顺序限制(此即 Relaxed ordering)</li>
</ul>
</li>
<li>memory_order_consume <ul>
<li>带有此限制的 load 操作针对受影响内存执行一个 consume 行为: 执行 load 操作的当前线程中后续针对该变量的读写操作不会被重排序到 load 操作之<strong>前</strong>, 从而确保后续读写用的都是最新加载的数据. 其它线程中, 如果先发生过针对同一个原子变量的写操作, 那么在它们 release 该原子变量之前针对该原子变量依赖的其它变量的写操作, 在当前线程 load 该原子变量时也都是可见的. 在大多数平台上, 这仅仅会影响编译器优化(此即 Release-Consume ordering).</li>
</ul>
</li>
<li>memory_order_acquire <ul>
<li>带有此限制的 load 操作针对受影响内存执行一个 acquire 行为: 执行 load 操作的当前线程中后续依赖该变量的读写操作不会被重排序到该 load 操作之<strong>前</strong>, 从而确保后续读写用的都是最新加载的数据. 其它线程中, 如果先发生过针对同一个原子变量的写操作, 那么在它们 release 该原子变量之前针对其它变量的写操作(<strong>无论该原子变量是否依赖这些变量, 这比 consume 语义更强烈</strong>), 在当前线程 load 该原子变量时都是可见的(此即 Release-Acquire ordering).</li>
</ul>
</li>
<li>memory_order_release <ul>
<li>带有此限制的 store 操作执行一个 release 行为: 执行 store 操作的当前线程中其它针对该变量的读写操作都不会被重排序到当前 store 操作之<strong>后</strong>, 从而确保之前的读写用的都是本次修改之前的值. 在此 store 之前的针对其它变量的全部写操作对 acquire 该原子变量的其它线程也都是可见的(此即 Release-Acquire ordering), 同时针对该原子变量所依赖的变量的写操作针对 consume 该原子变量的其它线程也都是可见的(此即 Release-Consume ordering).</li>
</ul>
</li>
<li>memory_order_acq_rel <ul>
<li>带有此限制的 read-modify-write 操作既是一个 acquire 操作也是一个 release 操作. 执行 read-modify-write 操作的当前线程针对同一个变量的其它读写操作不能被重排序到该 store 操作之前或之后. 其它线程中针对该原子变量的写操作在 release 之后针对当前线程的 modify 是可见的, 同理当前线程的 modify 在 release 之后对其它 acquire 该原子变量的其它线程也是可见的.</li>
</ul>
</li>
<li>memory_order_seq_cst<ul>
<li>带有此限制的 load 操作执行一个 acquire 行为, 带有此限制的 store 操作执行一个 release 行为, 带有此限制的 read-modify-write 操作既执行一个 acquire 行为也执行一个 release 行为, 此外, 该限制确保了一个单一全序, 也就是说, 全部线程观测道德全部修改行为都是一个顺序(此即 Sequentially-consistent ordering). 该限制语义最强.</li>
</ul>
</li>
</ul>
<p>–End–</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://chienlungcheung.github.io/2020/09/22/leveldb-annotations-2-log-read-write/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chienlung Cheung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="programatrix">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/09/22/leveldb-annotations-2-log-read-write/" class="post-title-link" itemprop="url">Leveldb 源码详解系列之二: log 读写</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-09-22 19:16:28" itemprop="dateCreated datePublished" datetime="2020-09-22T19:16:28+00:00">2020-09-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-03 09:19:19" itemprop="dateModified" datetime="2021-03-03T09:19:19+00:00">2021-03-03</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/09/22/leveldb-annotations-2-log-read-write/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/09/22/leveldb-annotations-2-log-read-write/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <!-- toc -->

<ul>
<li><a href="#log-%E6%96%87%E4%BB%B6%E7%AE%80%E4%BB%8B">log 文件简介</a></li>
<li><a href="#%E8%AF%BB-log">读 log</a><ul>
<li><a href="#%E6%A0%B8%E5%BF%83%E6%96%87%E4%BB%B6%E4%B8%8E%E6%A0%B8%E5%BF%83%E7%B1%BB">核心文件与核心类</a></li>
<li><a href="#reader-%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95">Reader 构造方法</a></li>
<li><a href="#reader-%E8%AF%BB%E5%8F%96%E6%96%B9%E6%B3%95">Reader 读取方法</a></li>
</ul>
</li>
<li><a href="#%E5%86%99-log">写 log</a><ul>
<li><a href="#%E6%A0%B8%E5%BF%83%E6%96%87%E4%BB%B6%E4%B8%8E%E6%A0%B8%E5%BF%83%E7%B1%BB-1">核心文件与核心类</a></li>
<li><a href="#writer-%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95">Writer 构造方法</a></li>
<li><a href="#writer-%E5%86%99%E6%96%B9%E6%B3%95">Writer 写方法</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

<h1><span id="log-文件简介">log 文件简介</span></h1><p>我们先简单回顾下 log 文件相关的基础知识点, 具体请见 <a href="/2020/09/11/leveldb-annotations-1-interfaces-and-files/" title="Leveldb 源码详解系列之一: 接口与文件">Leveldb 源码详解系列之一: 接口与文件</a>.</p>
<p>log 文件(*.log)保存着数据库最近一系列更新操作, 它相当于 leveldb 的 WAL(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Write-ahead_logging">write-ahead logging</a>). 当前在用的 log 文件内容同时也会被记录到一个内存数据结构中(即 <code>memtable</code> ). 每个更新操作都被追加到当前的 log 文件和 <code>memtable</code> 中. 当 log 文件大小达到一个预定义的大小时(默认大约 4MB), 这个 log 文件对应的 <code>memtable</code> 就会被转换为一个 sorted table 文件落盘然后一个新的 log 文件就会被创建以保存未来的更新操作. </p>
<p>log 文件内容是一系列 blocks, 每个 block 大小为 32KB(有时候最后一个 block 可能装不满). 每个 block 由一系列 records 构成, 具体定义如下(熟悉编译原理的应该对下述写法不陌生): </p>
<pre><code>// 即 0 或多个 records, 0 或 1 个 trailer.
// 最大为 32768 字节.
block := record* trailer?
record :=
  // 下面提到的 type 和 data[] 的 crc32c 校验和, 小端字节序
  checksum: uint32
  // 下面的 data[] 的长度, 小端字节序
  length: uint16
  // 类型, FULL、FIRST、MIDDLE、LAST 取值之一
  type: uint8
  // 用户数据
  data: uint8[length]</code></pre>
<p>type 取值如下:</p>
<pre><code>FULL == 1
FIRST == 2
MIDDLE == 3
LAST == 4</code></pre>
<p>FULL 类型的 record 包含了一个完整的用户 record 的内容. </p>
<p>FIRST、MIDDLE、LAST 这三个类型用于被分割成多个 fragments 的用户 record. FIRST 表示某个用户 record 的第一个 fragment, LAST 表示某个用户 record 的最后一个 fragment, MIDDLE 表示某个用户 record 的中间 fragments. </p>
<p>如果当前 block 恰好剩余 7 个字节(正好可以容纳 record 中的 checksum + length + type), 并且一个新的非 0 长度的 record 要被写入, 那么 writer 必须在此处写入一个 FIRST 类型的 record(但是 length 字段值为 0, data 字段为空. 用户数据 data 部分需要写入下个 block, 而且下个 block 起始还是要写入一个 header 不过其 type 为 middle)来填满该 block 尾部的 7 个字节, 然后在接下来的 blocks 中写入全部用户数据.</p>
<h1><span id="读-log">读 log</span></h1><p>下面分析读 log 相关的类和方法.</p>
<h2><span id="核心文件与核心类">核心文件与核心类</span></h2><p>与读 log 相关的代码定义在下面两个文件中:</p>
<pre><code>db/log_reader.h
db/log_reader.cc</code></pre>
<p>核心类为 <code>class leveldb::log::Reader</code>. 下面针对这个类核心方法进行分析.</p>
<h2><span id="reader-构造方法">Reader 构造方法</span></h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建一个 Reader 来从 file 中读取和解析 records, </span></span><br><span class="line"><span class="comment">// 读取的第一个 record 的起始位置位于文件 initial_offset 或其之后的物理地址. </span></span><br><span class="line"><span class="comment">// 如果 reporter 不为空, 则在检测到数据损坏时汇报要丢弃的数据估计大小. </span></span><br><span class="line"><span class="comment">// 如果 checksum 为 true, 则在可行的条件比对校验和. </span></span><br><span class="line"><span class="comment">// 注意, file 和 reporter 的生命期不能短于 Reader 对象. </span></span><br><span class="line">Reader(SequentialFile* file, Reporter* reporter, <span class="keyword">bool</span> checksum, <span class="keyword">uint64_t</span> initial_offset)</span><br></pre></td></tr></table></figure>

<h2><span id="reader-读取方法">Reader 读取方法</span></h2><p><code>bool ReadRecord(Slice* record, std::string* scratch)</code> 方法负责从 log 文件读取内容并反序列化为 Record. 该方法会在 db 的 <code>Open</code> 方法中调用, 负责将磁盘上的 log 文件转换为内存中 memtable. 其它数据库恢复场景也会用到该方法.</p>
<p>所做的事情, 概括地讲就是从文件读取下一个 record 到 <code>*record</code> 中. 如果读取成功, 返回 true; 遇到文件尾返回 false. 如果当前读取的 record 没有被分片, 那就用不到 <code>*scratch</code> 参数来为 <code>*record</code> 做底层存储了; 其它情况需要借助 <code>*scratch</code> 来拼装分片的 record data 部分, 最后封装为一个 Slice 赋值给 <code>*record</code>. </p>
<p>具体处理流程见下面详细注释:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">Reader::ReadRecord</span><span class="params">(Slice* record, <span class="built_in">std</span>::<span class="built_in">string</span>* scratch)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// last_record_offset_ 表示上一次调用 ReadRecord 方法返回的</span></span><br><span class="line">  <span class="comment">// record 的起始偏移量, 注意这个 record 是逻辑的. </span></span><br><span class="line">  <span class="comment">// initial_offset_ 表示用户创建 Reader 时指定的在文件中寻找第一个 record 的起始地址.</span></span><br><span class="line">  <span class="comment">// 如果条件成立, 表示当前方法是首次被调用.</span></span><br><span class="line">  <span class="keyword">if</span> (last_record_offset_ &lt; initial_offset_) &#123;</span><br><span class="line">    <span class="comment">// 跳到我们要读取的第一个 block 起始位置</span></span><br><span class="line">    <span class="keyword">if</span> (!SkipToInitialBlock()) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  scratch-&gt;clear();</span><br><span class="line">  record-&gt;clear();</span><br><span class="line">  <span class="comment">// 指示正在处理的 record 是否被分片了, </span></span><br><span class="line">  <span class="comment">// 除非逻辑 record 对应的物理 record 类型是 full, 否则就是被分片了.</span></span><br><span class="line">  <span class="keyword">bool</span> in_fragmented_record = <span class="literal">false</span>; </span><br><span class="line"></span><br><span class="line">  <span class="comment">// 记录我们正在读取的逻辑 record 的起始偏移量. 初值为 0 无实际意义仅为编译器不发警告. </span></span><br><span class="line">  <span class="comment">// 为啥叫逻辑 record 呢？</span></span><br><span class="line">  <span class="comment">// 因为 block 大小限制, 所以 record 可能被分成多个分片(fragment). </span></span><br><span class="line">  <span class="comment">// 我们管 fragment 叫物理 record, 一个或多个物理 record 构成一个逻辑 record. </span></span><br><span class="line">  <span class="keyword">uint64_t</span> prospective_record_offset = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  Slice fragment;</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="comment">// 从文件读取一个物理 record 并将其 data 部分保存到 fragment, </span></span><br><span class="line">    <span class="comment">// 同时返回该 record 的 type.</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> record_type = ReadPhysicalRecord(&amp;fragment);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算返回的当前 record 在 log file 中的起始地址</span></span><br><span class="line">    <span class="comment">//    = 当前文件待读取位置</span></span><br><span class="line">    <span class="comment">//      - buffer 剩余字节数</span></span><br><span class="line">    <span class="comment">//      - 刚读取的 record 头大小</span></span><br><span class="line">    <span class="comment">//      - 刚读取 record 数据部分大小</span></span><br><span class="line">    <span class="comment">// end_of_buffer_offset_ 表示 log file 待读取字节位置</span></span><br><span class="line">    <span class="comment">// buffer_ 表示是对一整个 block 数据的封装, 底层存储为 backing_store_, </span></span><br><span class="line">    <span class="comment">//    每次执行 ReadPhysicalRecord 时会移动 buffer_ 指针.</span></span><br><span class="line">    <span class="keyword">uint64_t</span> physical_record_offset =</span><br><span class="line">        end_of_buffer_offset_ - buffer_.size() - kHeaderSize - fragment.size(); </span><br><span class="line"></span><br><span class="line">    <span class="comment">// resyncing_ 用于跳过起始地址不符合 initial_offset_ 的 record,</span></span><br><span class="line">    <span class="comment">// 如果为 true 表示目前还在定位第一个满足条件的逻辑 record 中.</span></span><br><span class="line">    <span class="comment">// 与 initial_offset_ 的比较判断在上面 ReadPhysicalRecord 中进行.</span></span><br><span class="line">    <span class="keyword">if</span> (resyncing_) &#123;</span><br><span class="line">      <span class="comment">// 只要数据没有损坏或到达文件尾, 而且返回的 record_type 只要</span></span><br><span class="line">      <span class="comment">// 不是 kBadRecord(返回该类型其中一个情况就是起始地址不满足条件)</span></span><br><span class="line">      <span class="comment">// 就说明当前 record 起始地址已经大于 initial_offset_ 了,</span></span><br><span class="line">      <span class="comment">// 但是如果当前 record 的 type 为 middle 或者 last, </span></span><br><span class="line">      <span class="comment">// 那么逻辑上这个 record 仍然与不符合 initial_offset_ 的</span></span><br><span class="line">      <span class="comment">// 类型为 first 的 record 同属一个逻辑 record, </span></span><br><span class="line">      <span class="comment">// 所以当前 record 也不是我们要的.</span></span><br><span class="line">      <span class="keyword">if</span> (record_type == kMiddleType) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (record_type == kLastType) &#123;</span><br><span class="line">        resyncing_ = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 如果是 full 类型的 record, 而且这个 record 起始地址</span></span><br><span class="line">        <span class="comment">// 不小于 inital_offset_(否则 ReadPhysicalRecord 返回的</span></span><br><span class="line">        <span class="comment">//     类型就是 kBadRecord 而非 full), </span></span><br><span class="line">        <span class="comment">// 满足条件了, 关掉标识.</span></span><br><span class="line">        <span class="comment">// 如果返回 kBadRecord/kEof(没什么可读了)/</span></span><br><span class="line">        <span class="comment">// 未知类型(但是起始位置满足要求), 也会关掉该标识.</span></span><br><span class="line">        resyncing_ = <span class="literal">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 注意, 下面 switch 有的 case 是 return, 有的是 break.</span></span><br><span class="line">    <span class="keyword">switch</span> (record_type) &#123;</span><br><span class="line">      <span class="keyword">case</span> kFullType:</span><br><span class="line">        <span class="keyword">if</span> (in_fragmented_record) &#123;</span><br><span class="line">          <span class="comment">// 早期版本 writer 实现存在 bug. </span></span><br><span class="line">          <span class="comment">// 即如果上一个 block 末尾保存的是一个 FIRST 类型的 header, </span></span><br><span class="line">          <span class="comment">// 那么接下来 block 开头应该是一个 MIDDLE 类型的 record, </span></span><br><span class="line">          <span class="comment">// 但是早期版本写入了 FIRST 类型或者 FULL 类型的 record. </span></span><br><span class="line">          <span class="keyword">if</span> (!scratch-&gt;empty()) &#123;</span><br><span class="line">            ReportCorruption(scratch-&gt;size(), <span class="string">&quot;partial record without end(1)&quot;</span>);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        prospective_record_offset = physical_record_offset;</span><br><span class="line">        scratch-&gt;clear();</span><br><span class="line">        <span class="comment">// 赋值构造</span></span><br><span class="line">        <span class="comment">// FULL 类型 record 不用借助 scratch 拼装了</span></span><br><span class="line">        *record = fragment; </span><br><span class="line">        last_record_offset_ = prospective_record_offset;</span><br><span class="line">        <span class="comment">// 读取到一个完整逻辑 record, 完成任务.</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">      <span class="comment">// 注意, 只有 first 类型的 record 起始地址满足大于 inital_offset_ 的时候</span></span><br><span class="line">      <span class="comment">// 才会返回其真实类型 first, 其它情况哪怕是 first 返回也是 kBadRecord.</span></span><br><span class="line">      <span class="keyword">case</span> kFirstType:</span><br><span class="line">        <span class="keyword">if</span> (in_fragmented_record) &#123;</span><br><span class="line">          <span class="comment">// 早期版本 writer 实现存在 bug. </span></span><br><span class="line">          <span class="comment">// 即如果上一个 block 末尾保存的是一个 FIRST 类型的 header, </span></span><br><span class="line">          <span class="comment">// 那么接下来 block 开头应该是一个 MIDDLE 类型的 record, </span></span><br><span class="line">          <span class="comment">// 但是早期版本写入了 FIRST 类型或者 FULL 类型的 record. </span></span><br><span class="line">          <span class="keyword">if</span> (!scratch-&gt;empty()) &#123;</span><br><span class="line">            ReportCorruption(scratch-&gt;size(), <span class="string">&quot;partial record without end(2)&quot;</span>);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// FIRST 类型物理 record 起始地址也是对应逻辑 record 的起始地址</span></span><br><span class="line">        prospective_record_offset = physical_record_offset;</span><br><span class="line">        <span class="comment">// 非 FULL 类型 record 需要借助 scratch 拼装成一个完整的 record data 部分.</span></span><br><span class="line">        <span class="comment">// 注意只有 first 时采用 assign, first 后面的分片要用 append</span></span><br><span class="line">        scratch-&gt;assign(fragment.data(), fragment.size());</span><br><span class="line">        <span class="comment">// 除了 FULL 类型 record, 都说明当前读取的 record 被分片了, </span></span><br><span class="line">        <span class="comment">// 还需要后续继续读取.</span></span><br><span class="line">        in_fragmented_record = <span class="literal">true</span>; </span><br><span class="line">        <span class="comment">// 刚读了 first, 没读完, 继续.</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> kMiddleType:</span><br><span class="line">        <span class="comment">// 都存在 MIDDLE 了, 竟然还说当前 record 没分片, 报错. </span></span><br><span class="line">        <span class="keyword">if</span> (!in_fragmented_record) &#123; </span><br><span class="line">          ReportCorruption(fragment.size(),</span><br><span class="line">                           <span class="string">&quot;missing start of fragmented record(1)&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// 非 FULL 类型 record 需要借助 scratch 拼装成一个</span></span><br><span class="line">          <span class="comment">// 完整的 record data 部分, </span></span><br><span class="line">          <span class="comment">// FIRST 类型已经打底了, MIDDLE 直接追加即可. </span></span><br><span class="line">          scratch-&gt;append(fragment.data(), fragment.size());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 还是 middle, 没读完, 继续.</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> kLastType:</span><br><span class="line">        <span class="comment">// 都存在 LAST 了, 竟然还说当前 record 没分片, 矛盾. </span></span><br><span class="line">        <span class="keyword">if</span> (!in_fragmented_record) &#123; </span><br><span class="line">          ReportCorruption(fragment.size(),</span><br><span class="line">                           <span class="string">&quot;missing start of fragmented record(2)&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// 非 FULL 类型 record 需要借助 scratch </span></span><br><span class="line">          <span class="comment">// 拼装成一个完整的 record data 部分, </span></span><br><span class="line">          <span class="comment">// FIRST 类型已经打底了, LAST 直接追加即可. </span></span><br><span class="line">          scratch-&gt;append(fragment.data(), fragment.size());</span><br><span class="line">          *record = Slice(*scratch);</span><br><span class="line">          last_record_offset_ = prospective_record_offset;</span><br><span class="line">          <span class="comment">// 读完了, 完成任务.</span></span><br><span class="line">          <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> kEof:</span><br><span class="line">        <span class="comment">// 如果都读到文件尾部了, 逻辑 record 还没读全, 那就是文件损坏了. </span></span><br><span class="line">        <span class="keyword">if</span> (in_fragmented_record) &#123;</span><br><span class="line">          <span class="comment">// 可能由于 writer 写完一个物理 record 后挂掉了, </span></span><br><span class="line">          <span class="comment">// 我们不把这种情况作为数据损坏, 直接忽略整个逻辑 record.</span></span><br><span class="line">          <span class="comment">// 数据损坏, 丢掉之前可能已经解析的数据 </span></span><br><span class="line">          scratch-&gt;clear();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 文件尾了, 读到读不到都拜拜.</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> kBadRecord:</span><br><span class="line">        <span class="comment">// 逻辑 record 有分片已经被读取过了, 但是本次读取物理 record 遇到了错误</span></span><br><span class="line">        <span class="keyword">if</span> (in_fragmented_record) &#123; </span><br><span class="line">          ReportCorruption(scratch-&gt;size(), <span class="string">&quot;error in middle of record&quot;</span>);</span><br><span class="line">          in_fragmented_record = <span class="literal">false</span>;</span><br><span class="line">          <span class="comment">// 数据损坏, 丢掉之前可能已经解析的数据</span></span><br><span class="line">          scratch-&gt;clear();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 遇到错误也不中止, 继续读取数据进行解析直到读取完整逻辑 record 的目标达成</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">default</span>: &#123;</span><br><span class="line">        <span class="keyword">char</span> buf[<span class="number">40</span>];</span><br><span class="line">        <span class="built_in">snprintf</span>(buf, <span class="keyword">sizeof</span>(buf), <span class="string">&quot;unknown record type %u&quot;</span>, record_type);</span><br><span class="line">        ReportCorruption(</span><br><span class="line">            (fragment.size() + (in_fragmented_record ? scratch-&gt;size() : <span class="number">0</span>)),</span><br><span class="line">            buf);</span><br><span class="line">        in_fragmented_record = <span class="literal">false</span>;</span><br><span class="line">        scratch-&gt;clear();</span><br><span class="line">        <span class="comment">// 遇到错误也不中止, 继续读取数据进行解析直到读取完整逻辑 record 的目标达成</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面方法中, 最重要的一个辅助函数为 <code>ReadPhysicalRecord</code>, 该方法负责从文件读取 block, 然后再从 block(block 为空但还没读取到一个完整逻辑 record, 会继续从 log 文件读取 block) 读取并解析一个物理 record 并将其 data 部分保存到 result, 同时返回该物理 record 的 type. 返回的 type 为下面几种之一:</p>
<ul>
<li>kEof, 到达文件尾</li>
<li>kBadRecord, 当前 record 损坏, 或者当前物理 record 起始地址小于用户指定的起始地址 inital_offset_(此时其实际 type 可能为 first) </li>
<li>first/middle/last/full 之一(注意, 除了 first/full, 其它类型对应物理 record 起始地址虽然不小于用户指定的 inital_offset_, 但是其所归属的逻辑 record 的起始地址可能不满足要求, 所以此时这两类物理 record 也会被 <code>Reader::ReadRecord</code> 方法跳过.)</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">unsigned</span> <span class="keyword">int</span> <span class="title">Reader::ReadPhysicalRecord</span><span class="params">(Slice* result)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 跳出循环需要满足下面条件之一:</span></span><br><span class="line">  <span class="comment">// - 文件损坏</span></span><br><span class="line">  <span class="comment">// - 无有效数据(非 tailer)且到达文件尾</span></span><br><span class="line">  <span class="comment">// - 读到了一个有效 block(然后解析其中的 record)</span></span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="comment">// 先确认要不要读取一个新的 blcok.</span></span><br><span class="line">    <span class="comment">// buffer_ 底层指针会向前移动, 所以其 size 是动态的. </span></span><br><span class="line">    <span class="comment">// 如果 buffer 剩余内容字节数小于 kHeaderSize 且不为空, </span></span><br><span class="line">    <span class="comment">// 表示 buffer 里面剩余字节是个 trailer, 可以跳过它去读取解析下个 block 了;</span></span><br><span class="line">    <span class="comment">// 否则, 跳过 if 继续从该 block 解析 record.</span></span><br><span class="line">    <span class="keyword">if</span> (buffer_.size() &lt; kHeaderSize) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!eof_) &#123; <span class="comment">// 如果未到文件尾</span></span><br><span class="line">        <span class="comment">// Last read was a full read, so this is a trailer to skip</span></span><br><span class="line">        buffer_.clear();</span><br><span class="line">        <span class="comment">// 从 log file 读取一整个 block 放到 backing_store_, </span></span><br><span class="line">        <span class="comment">// 然后将 backing_store_ 封装到 buffer_ 中. </span></span><br><span class="line">        Status status = file_-&gt;Read(kBlockSize, &amp;buffer_, backing_store_);</span><br><span class="line">        <span class="comment">// 更新 end_of_buffer_offset_ 至迄今从 log 读取最大位置下一个字节</span></span><br><span class="line">        end_of_buffer_offset_ += buffer_.size(); </span><br><span class="line">        <span class="comment">// 如果 log 文件损坏</span></span><br><span class="line">        <span class="keyword">if</span> (!status.ok()) &#123;</span><br><span class="line">          buffer_.clear();</span><br><span class="line">          <span class="comment">// 一个 block 被丢掉</span></span><br><span class="line">          ReportDrop(kBlockSize, status);</span><br><span class="line">          <span class="comment">// 读文件失败我们认为到达文件尾; </span></span><br><span class="line">          <span class="comment">// 注意, file_-&gt;Read 读到文件尾不会报错因为这是正常情况.</span></span><br><span class="line">          <span class="comment">// 只有遇到错误才会报错. </span></span><br><span class="line">          eof_ = <span class="literal">true</span>; </span><br><span class="line">          <span class="keyword">return</span> kEof;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (buffer_.size() &lt; kBlockSize) &#123;</span><br><span class="line">          <span class="comment">// 如果读取的 block 数据小于 block 容量, </span></span><br><span class="line">          <span class="comment">// 则肯定到达 log 文件尾部了, 处理其中的 records.</span></span><br><span class="line">          eof_ = <span class="literal">true</span>; </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 注意, 如果 buffer_ 非空, 则其内容为一个</span></span><br><span class="line">        <span class="comment">// 位于文件尾的截断的 record header. </span></span><br><span class="line">        <span class="comment">// 这可能是因为 writer 写 header 时崩溃导致的. </span></span><br><span class="line">        <span class="comment">// 我们不会把这种情况当做错误, 而是当做读作文件尾来处理. </span></span><br><span class="line">        buffer_.clear();</span><br><span class="line">        <span class="keyword">return</span> kEof;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 注意, 一个 block 可以包含多个 records, </span></span><br><span class="line"><span class="comment">     * 但是 block 最后一个 record 可能只包含 </span></span><br><span class="line"><span class="comment">     * header(这是由于 block 最后只剩下 7 个字节)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">// 解析 record 的 header.</span></span><br><span class="line">    <span class="comment">// record header, 由 checksum (4 bytes), </span></span><br><span class="line">    <span class="comment">// length (2 bytes), type (1 byte) 构成. </span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">char</span>* header = buffer_.data(); </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 下面两步骤是解析 length 的两个字节, 小端字节序, 所以需要拼, </span></span><br><span class="line"><span class="comment">     * 具体见 Writer::EmitPhysicalRecord</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">// xxxx|(xx|x|x)xxxxx 将左边括号内容转换为无符号 32 位数,</span></span><br><span class="line">    <span class="comment">// 并取出最后 8 位即括号左起第一个 x</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">uint32_t</span> a = <span class="keyword">static_cast</span>&lt;<span class="keyword">uint32_t</span>&gt;(header[<span class="number">4</span>]) &amp; <span class="number">0xff</span>;</span><br><span class="line">    <span class="comment">// xxxx|x(x|x|xx)xxxx 将左边括号内容转换为无符号 32 位数,</span></span><br><span class="line">    <span class="comment">// 并取出最后 8 位即括号左起第一个 x</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">uint32_t</span> b = <span class="keyword">static_cast</span>&lt;<span class="keyword">uint32_t</span>&gt;(header[<span class="number">5</span>]) &amp; <span class="number">0xff</span>;</span><br><span class="line">    <span class="comment">// xxxx|xx|(x)|xxxxxx 读取左边括号内容即 record type</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> type = header[<span class="number">6</span>]; </span><br><span class="line">    <span class="comment">// b 和 a 拼接构成了 length</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">uint32_t</span> length = a | (b &lt;&lt; <span class="number">8</span>); </span><br><span class="line">    <span class="comment">// 如果解析出的 length 加上 header 长度大于 buffer_ 剩余数据长度, </span></span><br><span class="line">    <span class="comment">// 则说明数据损坏了, 比如 length 被篡改了. </span></span><br><span class="line">    <span class="keyword">if</span> (kHeaderSize + length &gt; buffer_.size()) &#123;</span><br><span class="line">      <span class="keyword">size_t</span> drop_size = buffer_.size();</span><br><span class="line">      buffer_.clear();</span><br><span class="line">      <span class="comment">// 如果未到文件尾, 报告 length 损坏. </span></span><br><span class="line">      <span class="keyword">if</span> (!eof_) &#123; </span><br><span class="line">        ReportCorruption(drop_size, <span class="string">&quot;bad record length&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> kBadRecord;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 如果已经到了文件尾, 即当前读取 block 为 log file 最后一个 block.</span></span><br><span class="line">      <span class="comment">// 由于 length  有问题我们也没必要也没办法读取 data 部分, </span></span><br><span class="line">      <span class="comment">// 我们假设这种情况原因是 writer 写数据时崩溃了. </span></span><br><span class="line">      <span class="comment">// 这种情况我们不作为错误去报告, 而是当做到达文件尾了. </span></span><br><span class="line">      <span class="keyword">return</span> kEof;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (type == kZeroType &amp;&amp; length == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// 跳过 0 长度的 record, 而且不会报告数据丢弃. </span></span><br><span class="line">      <span class="comment">// 因为这些 records 产生的原因是 env_posix.cc </span></span><br><span class="line">      <span class="comment">// 中基于 mmap 的写入代码在执行时会预分配文件区域. </span></span><br><span class="line">      buffer_.clear();</span><br><span class="line">      <span class="keyword">return</span> kBadRecord;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Check crc</span></span><br><span class="line">    <span class="keyword">if</span> (checksum_) &#123;</span><br><span class="line">      <span class="comment">// 读取 crc</span></span><br><span class="line">      <span class="keyword">uint32_t</span> expected_crc = crc32c::Unmask(DecodeFixed32(header)); </span><br><span class="line">      <span class="comment">// crc 是基于 type 和 data 来计算的</span></span><br><span class="line">      <span class="keyword">uint32_t</span> actual_crc = crc32c::Value(header + <span class="number">6</span>, <span class="number">1</span> + length); </span><br><span class="line">      <span class="keyword">if</span> (actual_crc != expected_crc) &#123;</span><br><span class="line">        <span class="comment">// crc 校验失败, 可能是 length 字段出错, 数据损坏,</span></span><br><span class="line">        <span class="comment">// 丢弃这个 block 的剩余部分</span></span><br><span class="line">        <span class="keyword">size_t</span> drop_size = buffer_.size();</span><br><span class="line">        buffer_.clear();</span><br><span class="line">        ReportCorruption(drop_size, <span class="string">&quot;checksum mismatch&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> kBadRecord;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// header 解析完毕, 将当前 record 从 buffer_ 中</span></span><br><span class="line">    <span class="comment">// 移除(通过向前移动 buffer_ 底层存储指针实现)</span></span><br><span class="line">    buffer_.remove_prefix(kHeaderSize + length); </span><br><span class="line"></span><br><span class="line">    <span class="comment">// 当前解析出的 record 起始地址小于用户指定的起始地址, </span></span><br><span class="line">    <span class="comment">// 则跳过这个 record(返回 kBadRecord 类型). </span></span><br><span class="line">    <span class="comment">// 注意, 此时真正的 record type 可能为 first 类型.</span></span><br><span class="line">    <span class="keyword">if</span> (end_of_buffer_offset_ - buffer_.size() - kHeaderSize - length</span><br><span class="line">        &lt; initial_offset_) &#123;</span><br><span class="line">      result-&gt;clear();</span><br><span class="line">      <span class="keyword">return</span> kBadRecord;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 将该 record 的 data 部分返回</span></span><br><span class="line">    *result = Slice(header + kHeaderSize, length); </span><br><span class="line">    <span class="keyword">return</span> type;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h1><span id="写-log">写 log</span></h1><p>下面分析写 log 相关的类和方法.</p>
<h2><span id="核心文件与核心类">核心文件与核心类</span></h2><p>与写 log 相关的代码定义在下面两个文件中:</p>
<pre><code>db/log_writer.h
db/log_writer.cc</code></pre>
<p>核心类为 <code>class leveldb::log::Writer</code>. 下面针对这个类核心方法进行分析.    </p>
<h2><span id="writer-构造方法">Writer 构造方法</span></h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建一个 writer 用于追加数据到 dest 指向的文件.</span></span><br><span class="line"><span class="comment">// dest 指向的文件初始必须为空文件; dest 生命期不能短于 writer.</span></span><br><span class="line"><span class="function"><span class="keyword">explicit</span> <span class="title">Writer</span><span class="params">(WritableFile *dest)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一个 writer 用于追加数据到 dest 指向的文件.</span></span><br><span class="line"><span class="comment">// dest 指向文件初始长度必须为 dest_length; dest 生命期不能短于 writer.</span></span><br><span class="line">Writer(WritableFile *dest, <span class="keyword">uint64_t</span> dest_length);</span><br></pre></td></tr></table></figure>

<h2><span id="writer-写方法">Writer 写方法</span></h2><p>如果用户想把数据写入 log, 则需要将这些数据封装为 <code>Slice</code>, 然后调用 <code>Writer::AddRecord</code> 将其写入 log 文件. </p>
<p>写入时, 这个 <code>Slice</code> 内容即为 record 的 data 部分, 如果数据量太大导致一个 block(默认 32KB) 装不下, 则这些数据会被分片写入. 也就是说, 这些数据属于一个逻辑 record, 但是因为太大, 被分为若干物理 record 写入到 log 文件.</p>
<p>具体写入流程见源码注释:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">Writer::AddRecord</span><span class="params">(<span class="keyword">const</span> Slice&amp; slice)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">char</span>* ptr = slice.data();</span><br><span class="line">  <span class="comment">// data 剩余部分长度, 初始值为其原始长度</span></span><br><span class="line">  <span class="keyword">size_t</span> left = slice.size(); </span><br><span class="line"></span><br><span class="line">  <span class="comment">// 如有必要则将 record 分片后写入文件. </span></span><br><span class="line">  <span class="comment">// 如果 slice 内容为空, 则我们仍将会写入一个长度为 0 的 record 到文件中. </span></span><br><span class="line">  Status s;</span><br><span class="line">  <span class="keyword">bool</span> begin = <span class="literal">true</span>;</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    <span class="comment">// 当前 block 剩余空间大小</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> leftover = kBlockSize - block_offset_; </span><br><span class="line">    assert(leftover &gt;= <span class="number">0</span>);</span><br><span class="line">    <span class="comment">// 如果当前 block 剩余空间不足容纳 record 的 header(7 字节) </span></span><br><span class="line">    <span class="comment">// 则剩余空间作为 trailer 填充 0, 然后切换到新的 block.</span></span><br><span class="line">    <span class="keyword">if</span> (leftover &lt; kHeaderSize) &#123; </span><br><span class="line">      <span class="keyword">if</span> (leftover &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        assert(kHeaderSize == <span class="number">7</span>);</span><br><span class="line">        <span class="comment">// 最终填充多少 0 由 leftover 决定, 最大 6 字节</span></span><br><span class="line">        dest_-&gt;Append(Slice(<span class="string">&quot;\x00\x00\x00\x00\x00\x00&quot;</span>, leftover)); </span><br><span class="line">      &#125;</span><br><span class="line">      block_offset_ = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 到这一步, block (可能因为不足 kHeaderSize 在上面已经切换到了下个 block)</span></span><br><span class="line">    <span class="comment">// 最终剩余字节必定大约等于 kHeaderSize</span></span><br><span class="line">    assert(kBlockSize - block_offset_ - kHeaderSize &gt;= <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// block 当前剩余空闲字节数.</span></span><br><span class="line">    <span class="comment">// 除了待写入 header, 当前 block 还剩多大空间, 可能为 0; </span></span><br><span class="line">    <span class="comment">// block 最后剩下空间可能只够写入一个新 record 的 header 了</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> avail = kBlockSize - block_offset_ - kHeaderSize;</span><br><span class="line">    <span class="comment">// 可以写入当前 block 的 record data 剩余内容的长度, 可能为 0</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> fragment_length = (left &lt; avail) ? left : avail;</span><br><span class="line"></span><br><span class="line">    RecordType type; </span><br><span class="line">    <span class="comment">// 判断是否将 record 剩余内容分片</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">bool</span> end = (left == fragment_length);</span><br><span class="line">    <span class="keyword">if</span> (begin &amp;&amp; end) &#123;</span><br><span class="line">      <span class="comment">// 如果该 record 内容第一次写入文件, 而且, </span></span><br><span class="line">      <span class="comment">// 如果 block 剩余空间可以容纳 record data 全部内容, </span></span><br><span class="line">      <span class="comment">// 则写入一个 full 类型 record</span></span><br><span class="line">      type = kFullType;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (begin) &#123;</span><br><span class="line">      <span class="comment">// 如果该 record 内容第一写入文件, 而且, </span></span><br><span class="line">      <span class="comment">// 如果 block 剩余空间无法容纳 record data 全部内容, </span></span><br><span class="line">      <span class="comment">// 则写入一个 first 类型 record. </span></span><br><span class="line">      <span class="comment">// 注意, 此时是 record 第一次写入即它是一个新 record, </span></span><br><span class="line">      <span class="comment">//    该 block 剩余空间可能只够容纳 header 了, </span></span><br><span class="line">      <span class="comment">//    则在 block 尾部写入一个 FIRST 类型 header, record data 不写入, </span></span><br><span class="line">      <span class="comment">//    等下次循环会切换到下个 block, 然后又会重新写入一个</span></span><br><span class="line">      <span class="comment">//    非 FIRST 类型的 header (注意下面会将 begin 置为 false)</span></span><br><span class="line">      <span class="comment">//    而不是紧接着在新 block 只写入 data 部分. </span></span><br><span class="line">      type = kFirstType;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (end) &#123;</span><br><span class="line">      <span class="comment">// 如果这不是该 record 内容第一写入文件, 而且, </span></span><br><span class="line">      <span class="comment">// 如果 block 剩余空间可以容纳 record data 剩余内容, </span></span><br><span class="line">      <span class="comment">// 则写入一个 last 类型 record</span></span><br><span class="line">      type = kLastType;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 如果这不是该 record 内容第一写入文件, 而且, </span></span><br><span class="line">      <span class="comment">// 如果 block 剩余空间无法容纳 record data 剩余内容, </span></span><br><span class="line">      <span class="comment">// 则写入一个 middle 类型 record</span></span><br><span class="line">      type = kMiddleType;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将类型为 type, data 长度为 fragment_length 的 record 写入 log 文件.</span></span><br><span class="line">    s = EmitPhysicalRecord(type, ptr, fragment_length);</span><br><span class="line">    ptr += fragment_length;</span><br><span class="line">    left -= fragment_length;</span><br><span class="line">    <span class="comment">// 即使当前 block 剩余空间只够写入一个新 record 的 FIRST 类型 header, </span></span><br><span class="line">    <span class="comment">// record 也算写入过了</span></span><br><span class="line">    begin = <span class="literal">false</span>; </span><br><span class="line">    <span class="comment">// 写入不出错且 record 再无剩余内容则写入完毕</span></span><br><span class="line">  &#125; <span class="keyword">while</span> (s.ok() &amp;&amp; left &gt; <span class="number">0</span>); </span><br><span class="line">  <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>‘AddRecord<code>写入 record 时依赖的辅助方法</code>EmitPhysicalRecord`. 该方法负责组装 record header, 然后连同 payload 写入文件.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">Writer::EmitPhysicalRecord</span><span class="params">(RecordType t, <span class="keyword">const</span> <span class="keyword">char</span>* ptr, <span class="keyword">size_t</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// data 大小必须能够被 16 位无符号整数表示, 因为 record 的 length 字段只有两字节</span></span><br><span class="line">  assert(n &lt;= <span class="number">0xffff</span>);</span><br><span class="line">  <span class="comment">// 要写入的内容不能超过当前 block 剩余空间大小</span></span><br><span class="line">  assert(block_offset_ + kHeaderSize + n &lt;= kBlockSize); </span><br><span class="line"></span><br><span class="line">  <span class="comment">// buf 用于组装 record header</span></span><br><span class="line">  <span class="keyword">char</span> buf[kHeaderSize];</span><br><span class="line">  <span class="comment">// 将数据长度编码到 length 字段, 小端字节序</span></span><br><span class="line">  <span class="comment">// length 低 8 位安排在低地址位置</span></span><br><span class="line">  buf[<span class="number">4</span>] = <span class="keyword">static_cast</span>&lt;<span class="keyword">char</span>&gt;(n &amp; <span class="number">0xff</span>); </span><br><span class="line">  <span class="comment">// 然后写入 length 高 8 位安排在高地址位置</span></span><br><span class="line">  buf[<span class="number">5</span>] = <span class="keyword">static_cast</span>&lt;<span class="keyword">char</span>&gt;(n &gt;&gt; <span class="number">8</span>); </span><br><span class="line">  <span class="comment">// 将 type 编码到 type 字段, type 紧随 length 之后 1 字节</span></span><br><span class="line">  buf[<span class="number">6</span>] = <span class="keyword">static_cast</span>&lt;<span class="keyword">char</span>&gt;(t); </span><br><span class="line"></span><br><span class="line">  <span class="comment">// 计算 type 和 data 的 crc 并编码安排在最前面 4 个字节</span></span><br><span class="line">  <span class="keyword">uint32_t</span> crc = crc32c::Extend(type_crc_[t], ptr, n);</span><br><span class="line">  crc = crc32c::Mask(crc);</span><br><span class="line">  <span class="comment">// 将 crc 写入到 header 前四个字节</span></span><br><span class="line">  EncodeFixed32(buf, crc);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 写入 header</span></span><br><span class="line">  Status s = dest_-&gt;Append(Slice(buf, kHeaderSize)); </span><br><span class="line">  <span class="keyword">if</span> (s.ok()) &#123;</span><br><span class="line">    <span class="comment">// 写入 payload</span></span><br><span class="line">    s = dest_-&gt;Append(Slice(ptr, n));</span><br><span class="line">    <span class="keyword">if</span> (s.ok()) &#123;</span><br><span class="line">      <span class="comment">// 刷入文件</span></span><br><span class="line">      s = dest_-&gt;Flush();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 当前 block 剩余空间起始偏移量. </span></span><br><span class="line">  <span class="comment">// 注意, 这里不管 header 和 data 是否写成功. </span></span><br><span class="line">  block_offset_ += kHeaderSize + n; </span><br><span class="line">  <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>–End–</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://chienlungcheung.github.io/2020/09/21/%E4%BD%BF%E7%94%A8-eBPF-%E8%B0%83%E8%AF%95%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E7%9A%84-Go-%E7%A8%8B%E5%BA%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chienlung Cheung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="programatrix">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/09/21/%E4%BD%BF%E7%94%A8-eBPF-%E8%B0%83%E8%AF%95%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E7%9A%84-Go-%E7%A8%8B%E5%BA%8F/" class="post-title-link" itemprop="url">使用 eBPF 调试生产环境的 Go 程序</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-09-21 22:43:27" itemprop="dateCreated datePublished" datetime="2020-09-21T22:43:27+00:00">2020-09-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-03 09:19:19" itemprop="dateModified" datetime="2021-03-03T09:19:19+00:00">2021-03-03</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/09/21/%E4%BD%BF%E7%94%A8-eBPF-%E8%B0%83%E8%AF%95%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E7%9A%84-Go-%E7%A8%8B%E5%BA%8F/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/09/21/使用-eBPF-调试生产环境的-Go-程序/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <!-- toc -->

<ul>
<li><a href="#%E4%BB%8B%E7%BB%8D">介绍</a></li>
<li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF-ebpf">什么是 eBPF</a></li>
<li><a href="#uprobes">Uprobes</a></li>
<li><a href="#%E6%9E%84%E5%BB%BA%E8%BF%BD%E8%B8%AA%E7%A8%8B%E5%BA%8F">构建追踪程序</a></li>
<li><a href="#%E7%95%AA%E5%A4%96">番外</a><ul>
<li><a href="#%E5%AE%89%E8%A3%85-bcc">安装 BCC</a></li>
<li><a href="#too-many-arguments-%E7%BC%96%E8%AF%91%E9%94%99%E8%AF%AF">too many arguments 编译错误</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

<p>最新的 Go Weekly 推送了<a target="_blank" rel="noopener" href="https://blog.pixielabs.ai/blog/ebpf-function-tracing/post/">这篇文章</a>, eBPF 作为新时代的剖析工具正在如火如荼发展, 读完感觉用来入门很好, 就根据自己理解编译了这篇文章. 做实验过程遇到一些问题, 在最后加了一个番外章节可参考.</p>
<p>下面正式开始.</p>
<p>不用重新编译/部署线上程序而是借助 eBPF 即可实现对程序进行调试, 接下来我们会用一个系列文章介绍我们是怎么做的, 这是开篇. 本篇描述了如何使用 <a target="_blank" rel="noopener" href="https://github.com/iovisor/gobpf">gobpf</a> 和 uprobe 来构建一个跟踪 Go 程序函数入口参数变化的应用. 这里介绍的技术可以扩展到其它编译型语言, 如 C++, Rust 等等. 本系列文章后续将会讨论如何使用 eBPF 来跟踪 HTTP/gRPC 数据和 SSL 等等.</p>
<h1><span id="介绍">介绍</span></h1><p>当调试程序时, 我们一般对捕获程序的运行时状态非常感兴趣. 因为这可以让我们检查程序在干什么, 并能让我们确定 bug 出现在程序的哪一块. 观察运行时状态的一个简单方式是使用调试器. 比如针对 Go 程序, 我们可以使用 Delve 和 gdb.</p>
<p>Delve 和 gdb 在开发环境中做调试表现没得说, 但是我们一般不会在线上使用此类工具. 它们的长处同时也是它们的短处, 因为调试器会导致线上程序中断, 甚至如果在调试过程中不小心改错某个变量的值而导致线上程序出现异常.</p>
<p>为了让线上调试过程的侵入和影响更小, 我们将会探索使用增强版的 BPF(<a target="_blank" rel="noopener" href="https://ebpf.io/">eBPF</a>, Linux 4.x+ 内核可用)和更高级的 Go 库 <a target="_blank" rel="noopener" href="https://github.com/iovisor/gobpf">gobpf</a> 来达成目标.</p>
<h1><span id="什么是-ebpf">什么是 eBPF</span></h1><p>扩展型 BPF(eBPF) 是一项在 Linux 4.x+ 内核可用的技术. 你可以把它看作一个轻量级的沙箱 VM, 它运行在 Linux 内核中并且提供了针对内核内存的可信访问.</p>
<p>就像下面要说的, eBPF 允许内核运行 BPF 字节码. 虽然可用的前端(这里指的是编译器前端)语言多样, 但通常都是 C 语言的真子集. 通常 C 代码先通过 Clang 被编译为 BPF 字节码, 然后字节被验证以确保可以安全执行. 这些严格的验证保证了机器码不会有意或无意地危及 Linux 内核, 同时也确保了 BPF 探针在每次被触发时将会执行有限数目的指令. 这些保证确保了 eBPF 可以被用于性能敏感的应用中, 比如包过滤, 网络监控等等.</p>
<p>从功能上说, eBPF 允许你针对某些事件(如定时器事件, 网络事件或是函数调用事件)运行受限的 C 代码. 当因为一个函数调用事件被触发时, 我们把这些 eBPF 代码叫做探针. 这些探针既可以针对内核函数调用事件被触发(这时叫 kprobe, k 即 kernelspace), 也可以针对用户空间的函数调用事件被触发(这时叫 uprobe, u 即 userspace). 本篇文章讲解如何通过 uprobe 实现函数参数的动态追踪.</p>
<h1><span id="uprobes">Uprobes</span></h1><p>Uprobes 允许我们通过插入一个 debug trap 指令(在 x86 上就是 <code>int3</code>)触发一个软中断从而实现对运行在用户空间的程序进行拦截. 这也是调试器的工作原理. uprobe 运行过程本质上与其它 BPF 程序一样, 可以总结为下面图示:<br><img src="http://www.brendangregg.com/eBPF/linux_ebpf_internals.png" alt="BPF for tracing(from Brendan Gregg)"></p>
<center style="font-size:14px;color:#C0C0C0;text-decoration:underline">用于跟踪的 BPF(来自 Brendan Gregg)</center> 

<p>编译和验证过的 BPF 程序作为 uprobe 的一部分被执行, 同时执行结果写入到一个 buffer 中.</p>
<p>下面让我们研究下 uprobes 如何起作用的. 为了演示部署 uprobes 并捕获函数参数, 我们会用到<a target="_blank" rel="noopener" href="https://github.com/pixie-labs/pixie/blob/main/demos/simple-gotracing/app.go">这个</a>简单的 demo 应用. 该 demo 相关部分下面介绍.</p>
<p><code>main()</code> 方法是一个简单的 HTTP server, 它暴露了一个监听 <em>/e</em> 端点的 <em>GET</em> 接口, 该接口通过迭代逼近计算自然常数 <code>e</code>(也叫欧拉数). <code>computeE</code> 方法有一个参数 <em>iters</em>, 它指定了逼近时的迭代次数. 迭代次数越多, 结果越精确, 当然耗费 CPU 也越多. 迭代逼近算法不是我们本次关注重点, 感兴趣的可以自己研究下. 我们仅对追踪调用 <code>computeE</code> 方法时的参数感兴趣.</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">computeE</span><span class="params">(iterations <span class="keyword">int64</span>)</span> <span class="title">float64</span></span> &#123;</span><br><span class="line">  res := <span class="number">2.0</span></span><br><span class="line">  fact := <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i := <span class="keyword">int64</span>(<span class="number">2</span>); i &lt; iterations; i++ &#123;</span><br><span class="line">    fact *= <span class="keyword">float64</span>(i)</span><br><span class="line">    res += <span class="number">1</span> / fact</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  http.HandleFunc(<span class="string">&quot;/e&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">    <span class="comment">// ... 省略代码用于从 get 请求中解析 iters 参数, 若为空则使用默认值</span></span><br><span class="line">    w.Write([]<span class="keyword">byte</span>(fmt.Sprintf(<span class="string">&quot;e = %0.4f\n&quot;</span>, computeE(iters))))</span><br><span class="line">  &#125;)</span><br><span class="line">  <span class="comment">// 启动 server...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>为了进行后面的实验以及为最后采用 gdb 验证修改生效, 我们采用如下指令编译该代码:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ go build  -gcflags <span class="string">&quot;-N -l&quot;</span> app.go</span><br></pre></td></tr></table></figure>

<p>为了理解 uprobe 如何工作的, 我们看看可执行文件中要追踪的符号. 既然 uprobes 通过插入一个 debug trap 指令到可执行文件来实现, 我们先要确定要追踪的函数地址是什么. Go 程序在 Linux 上的二进制采用 ELF 格式存储 debug 信息, 该信息甚至在优化过的二进制中也是存在的, 除非 debug 数据被裁剪掉了. 我们可以使用命令 <code>objdump</code> 来检查二进制文件中的符号:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 执行下面命令之前需要你先将上面 go 程序编译为名为 app 的二进制文件.</span></span><br><span class="line"><span class="comment"># objdump --syms 可以从可执行程序中导出全部符号, 然后通过 grep 查找 computeE.</span></span><br><span class="line"><span class="comment"># 具体输出可能与你机器上不同, 这没什么问题.</span></span><br><span class="line">$ objdump --syms app | grep computeE</span><br><span class="line">00000000000x6600e0 g     F .text  000000000000004b             main.computeE</span><br></pre></td></tr></table></figure>

<p>从上述输出可以看到, <code>computeE</code> 方法的入口地址为 <code>0x0x6600e0</code>. 为了看一下这个地址附近的指令, 我们可以通过 <code>objdump</code> 来反汇编该二进制文件(通过命令行选项 <code>-d</code>). 反汇编代码如下:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ objdump -d app | grep -A 1 0x6600e0</span><br><span class="line">00000000000x6600e0 &lt;main.computeE&gt;:</span><br><span class="line">  0x6600e0:       48 8b 44 24 08          mov    0x8(%rsp),%rax</span><br></pre></td></tr></table></figure>

<p>从上面汇编代码可以看到当 <code>computeE</code> 方法被调用时会执行哪些指令. 第一条指令是 <code>mov 0x8(%rsp),%rax</code>, 该指令将距寄存器 <code>rsp</code> 保存的地址(栈指针寄存器保存的是 <code>computeE</code> 方法的入口地址)相对偏移量为 <code>0x8</code> 处的内容移动到寄存器 <code>rax</code> 中. 这个被移动的值即为 <code>computeE</code> 方法的入参 <code>iterations</code> 的值. Go 程序的参数通过栈来传递.</p>
<p>好了, 记住上面提到的信息, 我们来看看如何实现针对 <code>computeE</code> 方法的参数追踪.</p>
<h1><span id="构建追踪程序">构建追踪程序</span></h1><p>我们给这个追踪程序起个名叫 Tracer. 为了捕获前面提到的事件, 我们需要注册一个 uprobe 函数, 并且还得有个用户态函数负责去读 uprobe 的输出, 具体如下图所示:</p>
<p><img src="https://blog.pixielabs.ai/static/9f8b26f88f9b132440ef1b9d48b5a341/app-tracer.svg" alt="High-level overview showing the Tracer binary listening to perf events generated from the App"></p>
<p>我们编写一个叫做 <code>tracer</code> 的应用, 由它负责注册 BPF 代码, 同时读取这些 BPF 代码的输出. 如上图所示, uprobe 将会简单地输出到一个 <code>perf-buffer</code> 中, 该结构体是用于 perf 事件的 linux 内核数据结构. </p>
<p>万事俱备, 我们来看看当我们增加一个 uprobe 时会发生哪些事情. 下面的图显示了 Linux 内核如何使用一个 uprobe 来修改一个已有的二进制程序. 前文提到的软中断 <code>int3</code> 作为第一条指令被插入到 <code>main.computeE</code> 方法中. 这条指令将会在执行时触发一个软中断, 从而允许 Linux 内核来执行 BPF 代码. 然后我们把 <code>computeE</code> 每次被调用时的参数输出到 perf-buffer 中, 这些值会被我们编写的 <code>tracer</code> 应用异步地读取.</p>
<p><img src="https://blog.pixielabs.ai/static/87301c7282e8f8270fee2afb9fe85c81/app-trace.svg" alt="Details of how a debug trap instruction is used call a BPF program"></p>
<p>就我们这个需求来说, 相应的 BPF 代码很简单, C 代码如下:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;uapi/linux/ptrace.h&gt;</span></span></span><br><span class="line">BPF_PERF_OUTPUT(trace);</span><br><span class="line"><span class="comment">// 该函数将会被注册, 以便每次 main.computeE 被调用时该函数也会被调用</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">computeECalled</span><span class="params">(struct pt_regs *ctx)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// main.computeE 的入参保存在了 ax 寄存器里.</span></span><br><span class="line">  <span class="keyword">long</span> val = ctx-&gt;ax;</span><br><span class="line">  trace.perf_submit(ctx, &amp;val, <span class="keyword">sizeof</span>(val));</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们注册上面代码以便 <code>main.computeE</code> 方法被调用它们也会被执行. 这些代码被执行时, 我们仅仅读取函数参数然后写到 perf-buffer 中. 实现这个功能需要很多样板代码, 为了方便示意这里都省掉了, 完整的例子见<a target="_blank" rel="noopener" href="https://github.com/pixie-labs/pixie/blob/main/demos/simple-gotracing/trace_example/trace.go">这里</a>.</p>
<p>好了, 我们现在有个针对 <code>main.computeE</code> 的功能齐全的端到端参数追踪器了! 执行结果见下面动图:<br><img src="https://blog.pixielabs.ai/static/4de8713a5b05e1f9132350f333572174/e2e-demo.gif" alt="End-to-End demo"></p>
<p>上述动图执行步骤如下:</p>
<ul>
<li>1 在 localhost:9090 启动待追踪程序 <code>./app</code>, 此时我们可以用 curl 访问该应用了, 具体命令为 <code>curl http://localhost:9090/e?iters=10</code></li>
<li>2 启动 trace 应用, 注意指定参数 <code>sudo ./trace --binary ../app/app</code>, 参数是第一步中待追踪程序对应的二进制文件的路径.</li>
<li>3 不停的执行 curl 命令, 使其 iters 参数取值不同, 则会看到 trace 应用输出你指定的 iters 值.</li>
</ul>
<p>还有个有意思的事情, 我们真的可以通过 GDB 看到针对二进制文件的修改. 下面我们 dump 出 <code>0x0x6600e0</code> 处的指令, 在我们运行 <code>trace</code> 之前是这样的:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ gdb ./app</span><br><span class="line">(gdb) display /4i 0x6600e0</span><br><span class="line">1: x/4i 0x6600e0</span><br><span class="line">   0x6600e0 &lt;main.computeE&gt;:    sub    <span class="variable">$0x20</span>,%rsp</span><br><span class="line">   0x6600e4 &lt;main.computeE+4&gt;:  mov    %rbp,0x18(%rsp)</span><br><span class="line">   0x6600e9 &lt;main.computeE+9&gt;:  lea    0x18(%rsp),%rbp</span><br><span class="line">   0x6600ee &lt;main.computeE+14&gt;: xorps  %xmm0,%xmm0</span><br></pre></td></tr></table></figure>

<p>在我们运行 <code>trace</code> 之后, 再次查看:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ gdb ./app</span><br><span class="line">(gdb) display /4i 0x65fecf</span><br><span class="line">2: x/4i 0x6600e0</span><br><span class="line">   0x6600e0 &lt;main.computeE&gt;:    int3   </span><br><span class="line">   0x6600e1 &lt;main.computeE+1&gt;:  sub    <span class="variable">$0x20</span>,%esp</span><br><span class="line">   0x6600e4 &lt;main.computeE+4&gt;:  mov    %rbp,0x18(%rsp)</span><br><span class="line">   0x6600e9 &lt;main.computeE+9&gt;:  lea    0x18(%rsp),%rbp</span><br></pre></td></tr></table></figure>

<p>看到了吗? <code>0x6600e0</code> 插入了 <code>int3</code> 指令.</p>
<h1><span id="番外">番外</span></h1><p>下面说一下实验过程遇到的问题以及解决办法.</p>
<h2><span id="安装-bcc">安装 BCC</span></h2><p>编译前文提到的 <code>trace</code> 应用之前需要安装 bcc. 以 Ubuntu 16.04 为例(其它系统请参考<a target="_blank" rel="noopener" href="https://github.com/iovisor/bcc/blob/master/INSTALL.md">这里</a>):</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4052245BD4284CDD</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;deb https://repo.iovisor.org/apt/<span class="subst">$(lsb_release -cs)</span> <span class="subst">$(lsb_release -cs)</span> main&quot;</span> | sudo tee /etc/apt/sources.list.d/iovisor.list</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install bcc-tools libbcc-examples linux-headers-$(uname -r)</span><br></pre></td></tr></table></figure>

<p>如果安装速度慢, 而且你设置了 http_proxy/https_proxy, 请编辑 <code>/etc/sudoers</code> 新增一行 <code>Defaults env_keep = &quot;http_proxy https_proxy&quot;</code>, 这样速度至少会有百倍提升.</p>
<h2><span id="too-many-arguments-编译错误">too many arguments 编译错误</span></h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># github.com/iovisor/gobpf/bcc</span><br><span class="line">../../../../<span class="keyword">go</span>/pkg/mod/github.com/iovisor/gobpf@v0<span class="number">.0</span><span class="number">.0</span><span class="number">-20200614202714</span>-e6b321d32103/bcc/module.<span class="keyword">go</span>:<span class="number">98</span>:<span class="number">40</span>: too many arguments in call to _Cfunc_bpf_module_create_c_from_string</span><br><span class="line">        have (*_Ctype_char, number, **_Ctype_char, _Ctype_int, _Ctype__Bool, <span class="literal">nil</span>)</span><br><span class="line">        want (*_Ctype_char, _Ctype_uint, **_Ctype_char, _Ctype_int, _Ctype__Bool)</span><br><span class="line">../../../../<span class="keyword">go</span>/pkg/mod/github.com/iovisor/gobpf@v0<span class="number">.0</span><span class="number">.0</span><span class="number">-20200614202714</span>-e6b321d32103/bcc/module.<span class="keyword">go</span>:<span class="number">230</span>:<span class="number">28</span>: too many arguments in call to _C2func_bcc_func_load</span><br><span class="line">        have (unsafe.Pointer, _Ctype_int, *_Ctype_char, *_Ctype_struct_bpf_insn, _Ctype_int, *_Ctype_char, _Ctype_uint, _Ctype_int, *_Ctype_char, _Ctype_uint, <span class="literal">nil</span>)</span><br><span class="line">        want (unsafe.Pointer, _Ctype_int, *_Ctype_char, *_Ctype_struct_bpf_insn, _Ctype_int, *_Ctype_char, _Ctype_uint, _Ctype_int, *_Ctype_char, _Ctype_uint)</span><br></pre></td></tr></table></figure>

<p>原因为<a target="_blank" rel="noopener" href="https://github.com/iovisor/gobpf/commit/3ecafd366e4b239946d03c17f5a4beb5aef4935e#diff-f11d8f44bec322f0ba3a2ee148c82966">这一行</a>增加的特性 <em>Update bcc_func_load to libbcc 0.11 with hardware offload support</em>, 以及<a target="_blank" rel="noopener" href="https://github.com/iovisor/gobpf/commit/cda73bdde3bf14fc898d07b8936073e1aa197708">这一行</a>增加的特性 <em>bcc: update bpf_module_create_c_from_string for bcc 0.11.0 (fixes #202)</em>. </p>
<p>我没有深究具体是什么导致的(初步怀疑是系统版本), 如果你急着看结果, 可以根据上面报错地址知道到 <code>module.go</code> 文件, 把涉及的两个函数的最后一个 <code>nil</code> 参数去掉就可以顺利编译了.</p>
<p>–End–</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://chienlungcheung.github.io/2020/09/11/leveldb-annotations-1-interfaces-and-files/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chienlung Cheung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="programatrix">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/09/11/leveldb-annotations-1-interfaces-and-files/" class="post-title-link" itemprop="url">Leveldb 源码详解系列之一: 接口与文件</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-09-11 23:13:08" itemprop="dateCreated datePublished" datetime="2020-09-11T23:13:08+00:00">2020-09-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-03 09:19:19" itemprop="dateModified" datetime="2021-03-03T09:19:19+00:00">2021-03-03</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/09/11/leveldb-annotations-1-interfaces-and-files/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/09/11/leveldb-annotations-1-interfaces-and-files/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <!-- toc -->

<ul>
<li><a href="#%E4%BB%8E%E5%93%AA%E9%87%8C%E7%9D%80%E6%89%8B%E5%88%86%E6%9E%90-leveldb-%E5%AE%9E%E7%8E%B0">从哪里着手分析 leveldb 实现</a></li>
<li><a href="#leveldb-%E5%B8%B8%E7%94%A8%E7%9A%84%E6%8E%A5%E5%8F%A3">leveldb 常用的接口</a><ul>
<li><a href="#open">Open</a></li>
<li><a href="#put">Put</a></li>
<li><a href="#delete">Delete</a></li>
<li><a href="#write">Write</a></li>
<li><a href="#get">Get</a></li>
<li><a href="#newiterator">NewIterator</a></li>
<li><a href="#getsnapshot">GetSnapshot</a></li>
<li><a href="#releasesnapshot">ReleaseSnapshot</a></li>
<li><a href="#getproperty">GetProperty</a></li>
<li><a href="#getappoximatesizes">GetAppoximateSizes</a></li>
<li><a href="#compactrange">CompactRange</a></li>
</ul>
</li>
<li><a href="#leveldb-%E7%9A%84%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B">leveldb 的文件类型</a><ul>
<li><a href="#log-%E6%96%87%E4%BB%B6">log 文件</a><ul>
<li><a href="#log-%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F">log 文件格式</a></li>
<li><a href="#log-%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E7%9A%84%E5%A5%BD%E5%A4%84">log 文件格式的好处</a></li>
<li><a href="#log-%E6%96%87%E4%BB%B6%E7%9A%84%E7%BC%BA%E7%82%B9%E5%B9%B6%E4%B8%8D%E6%98%AF">log 文件的缺点(并不是)</a></li>
<li><a href="#log-%E6%96%87%E4%BB%B6%E4%B8%BB%E8%A6%81%E6%8E%A5%E5%8F%A3">log 文件主要接口</a><ul>
<li><a href="#%E5%86%99-log">写 log</a></li>
<li><a href="#%E8%AF%BB-log">读 log</a></li>
</ul>
</li>
<li><a href="#%E4%B8%8E-log-%E6%96%87%E4%BB%B6%E9%85%8D%E5%A5%97%E7%9A%84-memtable">与 log 文件配套的 memtable</a><ul>
<li><a href="#%E7%BB%93%E6%9E%84">结构</a></li>
<li><a href="#%E7%94%A8%E9%80%94">用途</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#sorted-table-%E6%96%87%E4%BB%B6">sorted table 文件</a><ul>
<li><a href="#sorted-table-%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F">sorted table 文件格式</a></li>
<li><a href="#filter-meta-block">“filter” Meta Block</a></li>
<li><a href="#stats-meta-block">“stats” Meta Block</a></li>
<li><a href="#sorted-table-%E6%96%87%E4%BB%B6%E4%B8%BB%E8%A6%81%E6%8E%A5%E5%8F%A3">sorted table 文件主要接口</a><ul>
<li><a href="#sorted-table-%E6%96%87%E4%BB%B6%E8%AF%BB%E6%8E%A5%E5%8F%A3">sorted table 文件读接口</a></li>
<li><a href="#sorted-table-%E6%96%87%E4%BB%B6%E5%86%99%E6%8E%A5%E5%8F%A3">sorted table 文件写接口</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#manifest-%E6%96%87%E4%BB%B6">MANIFEST 文件</a><ul>
<li><a href="#%E4%B8%8E-manifest-%E7%9B%B8%E5%85%B3%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B-versionset">与 MANIFEST 相关的数据结构之 VersionSet</a></li>
<li><a href="#%E4%B8%8E-manifest-%E7%9B%B8%E5%85%B3%E7%9A%84-version-%E7%BB%93%E6%9E%84">与 MANIFEST 相关的 Version 结构</a></li>
<li><a href="#%E4%B8%8E-manifest-%E7%9B%B8%E5%85%B3%E7%9A%84-versionedit">与 MANIFEST 相关的 VersionEdit</a></li>
</ul>
</li>
<li><a href="#current-%E6%96%87%E4%BB%B6">CURRENT 文件</a></li>
<li><a href="#%E6%96%87%E4%BB%B6%E4%BD%8D%E7%BD%AE%E4%B8%8E%E5%91%BD%E5%90%8D">文件位置与命名</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

<p>[toc]</p>
<h2><span id="从哪里着手分析-leveldb-实现">从哪里着手分析 leveldb 实现</span></h2><p>在了解了其基本使用以后, 如果想理解 leveldb 基本原理, 则有两个抓手. 第一个是  <code>include</code> 目录下的头文件, 尤其是 <code>db.h</code> , 第二个就是它的文件类型及其格式.</p>
<p>下面我们就从接口和文件两个方向来切入 leveldb 的设计与实现.</p>
<h2><span id="leveldb-常用的接口">leveldb 常用的接口</span></h2><h3><span id="open">Open</span></h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 打开一个名为 name 的数据库. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 打开成功, 会把一个指向基于堆内存的数据库指针存储到 *dbptr, 同时返回 OK; 如果打开失败, </span></span><br><span class="line"><span class="comment"> * 存储 nullptr 到 *dbptr 同时返回一个错误状态. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 调用者不再使用这个数据库时需要负责释放 *dbptr 指向的内存. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param options 控制数据库行为和性能的参数配置</span></span><br><span class="line"><span class="comment"> * @param name 数据库名称</span></span><br><span class="line"><span class="comment"> * @param dbptr 存储指向堆内存中数据库的指针</span></span><br><span class="line"><span class="comment"> * @return</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> Status <span class="title">Open</span><span class="params">(<span class="keyword">const</span> Options&amp; options,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; name,</span></span></span><br><span class="line"><span class="function"><span class="params">                    DB** dbptr)</span></span>;</span><br></pre></td></tr></table></figure>

<p>该方法在数据库启动时调用, 主要工作由 <code>leveldb::DBImpl::Recover</code> 方法完成, 后者主要做如下事情:</p>
<ol>
<li><p>调用其 VersionSet 成员的 <code>leveldb::VersionSet::Recover</code> 方法. 该方法从磁盘读取 CURRENT 文件, 进而读取 MANIFEST 文件内容, 然后在内存重建 level 架构:</p>
<ul>
<li>读取 CURRENT 文件(不存在则新建)找到最新的 MANIFEST 文件(不存在则新建)的名称</li>
<li>读取该 MANIFEST 文件内容与当前 Version 保存的 level 架构合并保存到一个新建的 Version 中, 然后将这个新的 version 作为当前的 version, 即最新的 level 架构信息.</li>
<li>清理过期的文件</li>
<li>这一步我们可以打开全部 sstables, 但最好等会再打开</li>
<li>将 log 文件块转换为一个新的 level-0 sstable</li>
<li>将接下来的要写的数据写入一个新的 log 文件</li>
</ul>
</li>
<li><p>遍历数据库目录下全部文件. 筛选出 sorted table 文件, 验证 VersionSet 包含的 level 架构图有效性; 同时将全部 log 文件筛选换出来后续反序列化成 memtable. 恢复 log 文件时会按照从旧到新逐个 log 文件恢复, 这样新的修改会覆盖旧的, 如果对应 memtable 太大了, 将其转为 sorted table 文件写入磁盘, 同时将其对应的 table 对象放到 table_cache_ 缓存. 若发生 memtable 落盘表示 level 架构新增文件则将 save_manifest 标记为 true, 表示需要写变更日志到 manifest 文件. 恢复 log 文件主要由方法 <code>leveldb::DBImpl::RecoverLogFile</code> 负责完成.</p>
</li>
</ol>
<h3><span id="put">Put</span></h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将 &lt;key, value&gt; 对写入数据库, 成功返回 OK, 失败返回错误状态. </span></span><br><span class="line"><span class="comment"> * @param options 本次写操作相关的配置参数, 如果有需要可以将该参数中的 sync 置为 true, 不容易丢数据但更慢. </span></span><br><span class="line"><span class="comment"> * @param key Slice 类型的 key</span></span><br><span class="line"><span class="comment"> * @param value Slice 类型的 value</span></span><br><span class="line"><span class="comment"> * @return 返回类型为 Status</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">Put</span><span class="params">(<span class="keyword">const</span> WriteOptions&amp; options,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">const</span> Slice&amp; key,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">const</span> Slice&amp; value)</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>该方法主要依赖 <code>leveldb::DBImpl::Write</code> 实现.</p>
<h3><span id="delete">Delete</span></h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 从数据删除指定键为 key 的键值对. 如果 key 不存在不算错. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param options 本次写操作相关的配置参数, 如果有需要可以将该参数中的 sync 置为 true, 不容易丢数据但更慢. </span></span><br><span class="line"><span class="comment"> * @param key 要删除数据项对应的 key</span></span><br><span class="line"><span class="comment"> * @return</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">Delete</span><span class="params">(<span class="keyword">const</span> WriteOptions&amp; options, <span class="keyword">const</span> Slice&amp; key)</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>该方法主要依赖 <code>leveldb::DBImpl::Write</code> 实现.</p>
<h3><span id="write">Write</span></h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 对数据库进行批量更新写操作.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 该方法线程安全, 内部自带同步. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param options 本次写操作相关的配置参数, 如果有需要可以将该参数中的 sync 置为 true, 不容易丢数据但更慢. </span></span><br><span class="line"><span class="comment"> * @param updates 要进行的批量更新操作</span></span><br><span class="line"><span class="comment"> * @return</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">Write</span><span class="params">(<span class="keyword">const</span> WriteOptions&amp; options, WriteBatch* updates)</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>该方法是 <code>leveldb::DBImpl::Write</code> 原型.</p>
<p>针对调用 db 进行的写操作, 都会生成一个对应的 <code>struct leveldb::DBImpl::Writer</code>, 其封装了写入数据和写入进度. 新构造的 writer 会被放入一个队列. 循环检查, 若当前 writer 工作没完成并且不是队首元素, 则当前有其它 writer 在写, 挂起当前 writer 等待条件成熟. 当前 writer 如果被排在前面的 writer 给合并写入了, 那么它的 done 就被标记为完成了. 否则会被其它在写入的 writer 调用其 signal 将其唤醒执行写入工作.</p>
<p>当执行写入工作时(被前一个执行写入并完成工作的 writer 唤醒了), 首先确认是否为本次该 writer 写操作分配新的 log 文件, 如果需要则分配. 因为该 writer 成为队首 writer 了, 则它负责将队列前面若干 writers 的 batch 合并为一个(该工作由<code>leveldb::DBImpl::BuildBatchGroup</code> 负责完成), 注意, 被合并的 writers 不出队(待合并写入完成再出队, 具体见后面描述), 所以写 log 期间队首 writer 不变. 具体写入工作由 <code>leveldb::log::Writer::AddRecord</code> 负责, 就是将数据序列化为 record 写入 log 文件. 如果追加 log 文件成功,则将被追加的数据插入到内存中的 memtable 中. 待写入完毕, 该 writer 将参与前述 batch group 写入 log 文件的 writer 都取出来并设置为写入完成, 即将其出队, 将其 done 置为 true, 同时向其发送信号将其唤醒, 被唤醒后它会检查其 done 标识并返回. 最后唤醒队首 writer 执行下一个合并写入.</p>
<h3><span id="get">Get</span></h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 查询键为 key 的数据项, 如果存在则将对应的 value 地址存储到第二个参数中. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 如果 key 不存在, 第二个参数不变, 返回值为 IsNotFound Status. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param options 本次读操作对应的配置参数</span></span><br><span class="line"><span class="comment"> * @param key 要查询的 key, Slice 引用类型</span></span><br><span class="line"><span class="comment"> * @param value 存储与 key 对应的值的指针, string 指针类型</span></span><br><span class="line"><span class="comment"> * @return</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">Get</span><span class="params">(<span class="keyword">const</span> ReadOptions&amp; options,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">const</span> Slice&amp; key, <span class="built_in">std</span>::<span class="built_in">string</span>* value)</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<ol>
<li>先查询当前在用的 memtable(具体工作由 <code>leveldb::MemTable::Get</code> 负责, 本质就是 SkipList 查询, 速度很快)</li>
<li>如果没有则查询正在转换为 sorted table 的 memtable 中寻找</li>
<li>如果没有则我们在磁盘上采用从底向上 level-by-level 的寻找目标 key. </li>
</ol>
<p>针对上述第 3 步, 具体由 db VersionSet 的当前 Version 负责, 因为该结构保存了 db 当前最新的 level 架构信息, 即每个 level 及其对应的文件列表和每个文件的键范围. 对应方法为 <code>leveldb::Version::Get</code>, 具体为:</p>
<ul>
<li>从低 level 向高 level 寻找. 由于 level 越低数据越新, 因此, 当我们在一个较低的 level 找到数据的时候, 不用在更高的 levels 找了.</li>
<li>由于 level-0 文件之间可能存在重叠, 而且针对同一个 key, 后产生的文件数据更新所以先将包含 key 的文件找出来按照文件号从大到小(对应文件从新到老)排序查找 key;</li>
<li>针对 level-1 及其以上 level, 由于每个 level 内文件之间不存在重叠, 于是在每个 level 中直接采用二分查找定位 key.</li>
</ul>
<p>另外需要注意的的是, 参数 <code>options</code> 可以配置一个快照, 快照对应了数据库历史上的一个操作序列号, 查询时仅查询不大于该序列号的操作范围. 针对同样的 key, 如果历史上有多次更新操作, 而用户想查找特定更新, 这就是实现途径. 如果没有配置快照选项, 默认采用当前最大序列号进行查询.</p>
<h3><span id="newiterator">NewIterator</span></h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回基于堆内存的迭代器, 可以用该迭代器遍历整个数据库的内容. </span></span><br><span class="line"><span class="comment"> * 该函数返回的迭代器初始是无效的(在使用迭代器之前, 调用者必须在其上调用 Seek 方法). </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 当不再使用时, 调用者应该释放该迭代器对应的内存, 而且迭代器必须在数据库释放之前进行释放. </span></span><br><span class="line"><span class="comment"> * @param options 本次读操作对应的配置参数</span></span><br><span class="line"><span class="comment"> * @return</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">virtual Iterator* NewIterator(<span class="keyword">const</span> ReadOptions&amp; options) = <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>该方法负责将内存 memtable(可能有两个, 一个在写, 一个写完待存盘) 和磁盘 sorted table 文件全部数据结构串起来构造一个大一统迭代器, 可以遍历整个数据库.</p>
<p>上述工作其实是由 <code>leveldb::Iterator *leveldb::DBImpl::NewInternalIterator</code> 负责完成的. 该方法实现涉及到 leveldb 特别精巧的迭代器的实现. 这个单独可以写一篇文章来专门介绍. 这里大致说下处理流程:</p>
<ul>
<li>1 初始化一个列表</li>
<li>2 把当前 memtable 迭代器加入列表中</li>
<li>3 把待写盘 memtable 迭代器追加到列表中</li>
<li>4 将当前 version 维护的 level 架构中每个 sorted table 文件对应的迭代器追加到列表中. 针对 level-0 和其它 levels 处理方式不同.<ul>
<li>由于 level-0 文件之间可能存在重叠, 所以按照文件生成顺序(这极其重要, 其实就是按照 key 从小到大, 只有这样才能确保最后生成的迭代器能够从小到大按序遍历整个数据库) 为每个文件生成一个两级迭代器(<code>TwoLevelIterator</code>, 该结构巧妙地将索引块和数据块结合到了一起)追加到列表中. </li>
<li>针对 level-1 及其以上 level, 按照从低 level 到高 level(这极其重要, 原因同 level-0), 为每个 level 生成一个两级迭代器, 数据结构依然是 <code>TwoLevelIterator</code>, 不过这里把每个 level 的文件列表抽象成了第一级索引, 然后每个文件对应的 table 对象抽象层二级索引.</li>
</ul>
</li>
<li>最后将前述全部迭代器构成的迭代器列表再级联成一个大一统的迭代器 <code>MergingIterator</code>. 这其实也是一个两级迭代器, 第一级指向迭代器列表, 第二级是某个迭代器指向的内容的迭代器.</li>
</ul>
<p>最后返回给调用者的就是 <code>MergingIterator</code> 实例. 可以调用它的相关方法在整个数据库上寻找目标 key.</p>
<h3><span id="getsnapshot">GetSnapshot</span></h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回当前 DB 状态的一个快照. </span></span><br><span class="line"><span class="comment"> * 使用该快照创建的全部迭代器将会都指向一个当前 DB 的一个稳定快照. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 当不再使用该快照时, 调用者必须调用 ReleaseSnapshot 将其释放. </span></span><br><span class="line"><span class="comment"> * @return</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">const</span> Snapshot* <span class="title">GetSnapshot</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>用数据库当前最新的更新操作对应的序列号创建一个快照. 快照最核心的就是那个操作序列号, 因为查询时会把 用户提供的 key(我们叫做 user_key)和操作序列号一起构成一个 internal_key(数据库存储的 key 就是它), 针对 user_key 相等的情况比如针对 hello 这个 user_key Put 多次, 则每次序列号就不一样, 于是根据特定序列号可以查询到特定的那次 Put 写入的 value 值.</p>
<p>这个新生成的快照会被挂载到一个双向链表上, 用完后可以调用 <code>ReleaseSnapshot</code> 将其释放掉.</p>
<h3><span id="releasesnapshot">ReleaseSnapshot</span></h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 释放一个之前获取的快照, 释放后, 调用者不能再使用该快照了. </span></span><br><span class="line"><span class="comment"> * @param snapshot 指向要释放的快照的指针</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">ReleaseSnapshot</span><span class="params">(<span class="keyword">const</span> Snapshot* snapshot)</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>从双向链表上删除指定的快照.</p>
<h3><span id="getproperty">GetProperty</span></h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * DB 实现可以通过该方法导出自身状态相关的信息. 如果提供的属性可以被 DB 实现理解, </span></span><br><span class="line"><span class="comment"> * 那么第二个参数将会存储该属性对应的当前值同时该方法返回 true, 其它情况该方法返回 false. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 合法的属性名称包括: </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &quot;leveldb.num-files-at-level&lt;N&gt;&quot; - 返回 level &lt;N&gt; 的文件个数, 其中 &lt;N&gt; 是一个数字. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &quot;leveldb.stats&quot; - 返回多行字符串, 描述该 DB 内部操作相关的统计数据. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &quot;leveldb.sstables&quot; - 返回多行字符串, 描述构成该 DB 的全部 sstable 相关信息. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &quot;leveldb.approximate-memory-usage&quot; - 返回被该 DB 使用的内存字节数近似值</span></span><br><span class="line"><span class="comment"> * @param property 要查询的属性名称</span></span><br><span class="line"><span class="comment"> * @param value 保存属性名称对应的属性值</span></span><br><span class="line"><span class="comment"> * @return</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">bool</span> <span class="title">GetProperty</span><span class="params">(<span class="keyword">const</span> Slice&amp; property, <span class="built_in">std</span>::<span class="built_in">string</span>* value)</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>leveldb 实现在内部做了一些统计, 可以通过这个接口进行查询. 不过目前可查询状态不多, 具体如下:</p>
<ul>
<li>“leveldb.num-files-at-level<n>“ - 返回 level <n> 的文件个数, 其中 <n> 是一个 ASCII 格式的数字.</n></n></n></li>
<li>“leveldb.stats” - 返回多行字符串, 描述该 DB 内部操作相关的统计数据. </li>
<li>“leveldb.sstables” - 返回多行字符串, 描述构成该 DB 的全部 sstable 相关信息. </li>
<li>“leveldb.approximate-memory-usage” - 返回被该 DB 使用的内存字节数近似值</li>
</ul>
<h3><span id="getappoximatesizes">GetAppoximateSizes</span></h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 对于 [0, n-1] 中每个 i, 将位于 [range[i].start .. range[i].limit) </span></span><br><span class="line"><span class="comment"> * 中全部 keys 所占用文件系统空间近似大小存储到 sizes[i] 中. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 注意, 如果数据被压缩过了, 那么返回的 sizes 存储的就是压缩后数据所占用文件系统空间大小. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 返回结果可能不包含最近刚写入的数据所占用空间. </span></span><br><span class="line"><span class="comment"> * @param range 指定要查询一组 keys 范围</span></span><br><span class="line"><span class="comment"> * @param n range 和 sizes 两个数组的大小</span></span><br><span class="line"><span class="comment"> * @param sizes 存储查询到的每个 range 对应的文件系统空间近似大小</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">GetApproximateSizes</span><span class="params">(<span class="keyword">const</span> Range* range, <span class="keyword">int</span> n,</span></span></span><br><span class="line"><span class="function"><span class="params">                                  <span class="keyword">uint64_t</span>* sizes)</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>计算 range 包含的键区间在磁盘上占用的空间大小, 每个子区间占用会保存到 sizes 对应位置.</p>
<p>计算过程也很简单, 就是遍历 range 列表, 针对每个子区间起止 key, 去数据库中确认其大致字节偏移, 然后”止”-“始” 即为子区间占用空间的大致大小.</p>
<h3><span id="compactrange">CompactRange</span></h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将 key 范围 [*begin,*end] 对应的底层存储压紧, 注意范围是左闭右闭. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 尤其是, 压实过程会将已经删除或者复写过的数据会被丢弃, 同时会将数据</span></span><br><span class="line"><span class="comment"> * 重新安放以减少后续数据访问操作的成本. </span></span><br><span class="line"><span class="comment"> * 这个操作是为那些理解底层实现的用户准备的. </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 如果 begin==nullptr, 则从第一个键开始; 如果 end==nullptr 则到最后一个键为止. </span></span><br><span class="line"><span class="comment"> * 所以, 如果像下面这样做则意味着压紧整个数据库: </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * db-&gt;CompactRange(nullptr, nullptr);</span></span><br><span class="line"><span class="comment"> * @param begin 起始键</span></span><br><span class="line"><span class="comment"> * @param end 截止键</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">CompactRange</span><span class="params">(<span class="keyword">const</span> Slice* begin, <span class="keyword">const</span> Slice* end)</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>手动触发与目标键区间重叠的文件压实. 具体为:</p>
<ul>
<li>检查每个 level, 确认其包含的键区间释放与目标键区间有交集.</li>
<li>因为当前在写 memtable 可能与目标键区间有交集, 所以强制触发一次 memtable 压实(即将当前 memtable 文件转为 sorted table 文件并写入磁盘)并生成新 log 文件和对应的 memtable.</li>
<li>针对与目标键区间有交集的各个 level 触发一次手动压实</li>
</ul>
<p>具体压实过程后续会写一篇文章进行介绍.</p>
<h2><span id="leveldb-的文件类型">leveldb 的文件类型</span></h2><p>下面分别介绍 leveldb 最重要的几个文件类型.</p>
<h3><span id="log-文件">log 文件</span></h3><p>一个 log 文件(*.log)保存着最近一系列更新操作, 它相当于 leveldb 的 WAL(write-ahead log). 每个更新操作都被追加到当前的 log 文件中. 当 log 文件大小达到一个预定义的大小时(默认大约 4MB), 这个 log 文件就会被转换为一个 sorted table (见下文)然后一个新的 log 文件就会被创建以保存未来的更新操作. </p>
<p>当前 log 文件内容同时也会被记录到一个内存数据结构中(即 <code>memtable</code> ). 这个结构加上全部 sorted tables (*.ldb) 才是完整数据, 一起确保每个读操作都能查到当前最新. </p>
<h4><span id="log-文件格式">log 文件格式</span></h4><p>log 文件内容是一系列 blocks, 每个 block 大小为 32KB. 唯一的例外就是, log 文件末尾可能包含一个不完整的 block. </p>
<p>每个 block 由一系列 records 构成, 具体定义如下(熟悉编译原理的应该对下述写法不陌生): </p>
<pre><code>// 即 0 或多个 records, 0 或 1 个 trailer.
// 最大为 32768 字节.
block := record* trailer?
record :=
  // 下面提到的 type 和 data[] 的 crc32c 校验和, 小端字节序
  checksum: uint32
  // 下面的 data[] 的长度, 小端字节序
  length: uint16
  // 类型, FULL、FIRST、MIDDLE、LAST 取值之一
  type: uint8
  // 用户数据
  data: uint8[length]</code></pre>
<p>如果一个 block 剩余字节不超过 6 个(checksum 字段长度 + length 字段长度 + type 字段长度 = 7), 则不会再构造任何 record, 如前括号解释因为大小不合适. 这些剩余空间会被用于构造一个 trailer, reader 读取该文件时候会忽略之. </p>
<p>此外, 如果当前 block 恰好剩余 7 个字节(正好可以容纳 record 中的 checksum + length + type), 并且一个新的非 0 长度的 record 要被写入, 那么 writer 必须在此处写入一个 FIRST 类型的 record(但是 length 字段值为 0, data 字段为空. 用户数据 data 部分需要写入下个 block, 而且下个 block 起始还是要写入一个 header 不过其 type 为 middle)来填满该 block 尾部的 7 个字节, 然后在接下来的 blocks 中写入全部用户数据.</p>
<p>未来可能加入更多的 record 类型. Readers 可以跳过它们不理解的 record 类型, 也可以在跳过时进行报告. </p>
<pre><code>FULL == 1
FIRST == 2
MIDDLE == 3
LAST == 4</code></pre>
<p>FULL 类型的 record 包含了一个完整的用户 record 的内容. </p>
<p>FIRST、MIDDLE、LAST 这三个类型用于被分割成多个 fragments(典型的理由是某个 record 跨越了多个 block 边界) 的用户 record. FIRST 表示某个用户 record 的第一个 fragment, LAST 表示某个用户 record 的最后一个 fragment, MIDDLE 表示某个用户 record 的中间 fragments. </p>
<p>举例: 考虑下面一系列用户 records:<br>    A: 长度 1000<br>    B: 长度 97270<br>    C: 长度 8000<br><strong>A</strong> 会被作为 FULL 类型的 record 存储到第一个 block, 第一个 block 剩余空间为 32768 - 7 - 1000 = 31761; </p>
<p><strong>B</strong> 会被分割为 3 个 fragments: 第一个 fragment 占据第一个 block 剩余空间, 共存入 31761 - 7 = 31754, 剩余 65516; 第二个 fragment 占据第二个 block 的全部空间, 存入 32768 - 7 = 32761, 剩余 65516 - 32761 = 32755; 第三个 fragment 占据第三个 block 的起始空间共 7 + 32755 = 32762. 所以最后在第三个 block 剩下 32768 - 32762 = 6 个字节, 这几个字节会被填充 0 作为 trailer. </p>
<p><strong>C</strong> 将会被作为 FULL 类型的 record 存储到第四个 block 中. </p>
<p>MANIFEST 文件的格式同 log 文件, 只是记录的具体内容不同, 前者记录的针对 level 架构的文件级别变更(新增/删除), 后者记录的是用户数据 key-value 变更.</p>
<h4><span id="log-文件格式的好处">log 文件格式的好处</span></h4><p>log 文件格式的好处是(总结一句话就是容易划分边界): </p>
<ol>
<li>不必进行任何启发式地 resyncing(可以理解为寻找一个 block 的边界) —— 直接跳到下个 block 边界进行扫描即可, 因为每个 block 大小是固定的(32768 个字节, 除非文件尾部的 block 未写满). 如果数据有损坏, 直接跳到下个 block. 这个文件格式的附带好处是, 当一个 log 文件的部分内容作为一个 record 嵌入到另一个 log 文件时(即当一个逻辑 record 分为多个物理 records, 一部分 records 位于前一个 log 文件, 剩下 records 位于下个 log 文件), 我们不会分不清楚. </li>
<li>在估计出来的边界处做分割(比如为 mapreduce 应用)变得简单了: 找到下个 block 的边界, 如果起始是 MIDDLE 或者 LAST 类型的 record, 则跳过直到我们找到一个 FULL 或者 FIRST record 为止, 就可以在此处做分割, 一部分投递到一个计算任务, 另一部分(直到分界处)投递到另一个计算任务.</li>
</ol>
<h4><span id="log-文件的缺点并不是">log 文件的缺点(并不是)</span></h4><p>log 文件格式的缺点: </p>
<ol>
<li>没有打包小的 records. 通过增加一个新的 record 类型可以解决这个问题, 所以这个问题是当前实现的不足而不是 log 格式的缺陷. </li>
<li>没有压缩. 同样地, 这个也可以通过增加一个新的 record 类型来解决. </li>
</ol>
<h4><span id="log-文件主要接口">log 文件主要接口</span></h4><p>下面介绍下 log 文件的读写实现.</p>
<h5><span id="写-log">写 log</span></h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">leveldb::Status leveldb::<span class="built_in">log</span>::Writer::AddRecord(<span class="keyword">const</span> leveldb::Slice &amp;slice)</span><br></pre></td></tr></table></figure>

<p>该接口做的事情就是把外部传入的 Slice 封装成若干 records 追加到 log 文件中.</p>
<p>该方法会被 <code>leveldb::Status leveldb::DBImpl::Write(const leveldb::WriteOptions &amp;options, leveldb::WriteBatch *my_batch)</code> 调用以响应用户的写操作. <code>DBImpl</code> 是 <code>DB</code> 的派生类, 其 <code>Put</code> 和 <code>Delete</code> 方法真正工作是由派生类的 <code>Write</code> 负责的.</p>
<h5><span id="读-log">读 log</span></h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> leveldb::<span class="built_in">log</span>::Reader::ReadRecord(leveldb::Slice *record, <span class="built_in">string</span> *scratch)</span><br></pre></td></tr></table></figure>

<p>该方法负责从 log 文件读取内容并反序列化为 Record. 该方法会在 db 的 <code>Open</code> 方法中调用, 负责将磁盘上的 log 文件转换为内存中 memtable. 其它数据库恢复场景也会用到该方法.</p>
<h4><span id="与-log-文件配套的-memtable">与 log 文件配套的 memtable</span></h4><p>memtable 可以看作是 log 文件的内存形式, 但是格式不同.</p>
<h5><span id="结构">结构</span></h5><p>它的本质就是一个 SkipList.</p>
<h5><span id="用途">用途</span></h5><p>我们已经知道, 每个 log 文件在内存有一个对应的 memtable, 它和正在压实的 memtable 以及磁盘上的各个 level 包含的文件构成了数据全集. 所以当调用 DB 的 <code>Get</code> 方法查询某个 key 的时候, 具体步骤是这样的(具体实现位于 <code>leveldb::Status leveldb::Version::Get(const leveldb::ReadOptions &amp;options, const leveldb::LookupKey &amp;k, string *value, leveldb::Version::GetStats *stats)</code>, DB 的 <code>Get</code> 方法会调用前述实现.):</p>
<ol>
<li>先查询当前在用的 memtable, 查到返回, 未查到下一步</li>
<li>查询正在转换为 sorted table 的 memtable 中寻找, 查到返回, 未查到下一步 </li>
<li>在磁盘上采用从底向上 level-by-level 的寻找目标 key. <ul>
<li>由于 level 越低数据越新, 因此, 当我们在一个较低的 level 找到数据的时候, 不用在更高的 levels 找了.</li>
<li>由于 level-0 文件之间可能存在重叠, 而且针对同一个 key, 后产生的文件数据更新所以先将包含 key 的文件找出来按照文件号从大到小(对应文件从新到老)排序查找 key; 针对 level-1 及其以上 level, 由于每个 level 内文件之间不存在重叠, 于是在每个 level 中直接采用二分查找定位 key.</li>
</ul>
</li>
</ol>
<h3><span id="sorted-table-文件">sorted table 文件</span></h3><p>sorted table(*.ldb) 文件就是 leveldb 的数据库文件了. 每一个 level 都对应一组有序的 sorted table 文件. 每个 sorted table 文件保存着按 key 排序的一系列数据项. 每个数据项要么是一个与某个 key 对应的 value, 要么是某个 key 的删除标记. (删除标记其它地方又叫墓碑消息, 用于声明时间线上在此之前的同名 key 对应的记录都失效了, 后台线程负责对这类记录进行压实, 即拷贝到另一个文件时物理删除这类记录.). 注意, leveldb 是一个 append 类型而非 MySQL 那种 in-place 修改的数据库.</p>
<p>sorted tables 文件被组织成一系列 levels. 一个 log 文件生成的对应 sorted table 文件会被放到一个特殊的 <strong>young</strong> level(也被叫做 level-0). 当 young 文件数目超过某个阈值(当前是 4), 全部 young 文件就会和 level-1 与之重叠的全部文件进行合并, 进而生成一系列新的 level-1 文件(每 2MB 数据就会生成一个新的 level-1 文件). </p>
<p>level-0 的文件之间可能存在键区间重叠, 但是其它每层 level 内部文件之间是不存在重叠情况的. 我们下面来说下 level-1 及其以上的 level 的文件如何合并. 当 level-L (L &gt;= 1)的文件总大小超过了 $10^L$ MB(即 level-1 超过了 10MB, level-2 超过了 100MB, …), 此时一个 level-L 文件就会和 level-(L+1) 中与自己键区间重叠的全部文件进行合并, 然后为 level-(L+1) 生成一组新的文件. 这些合并操作可以实现将 young level 中新的 updates 一点一点搬到最高的那层 level, 这个迁移过程使用的都是块读写(最小化了昂贵的 seek 操作的时间消耗). </p>
<h4><span id="sorted-table-文件格式">sorted table 文件格式</span></h4><p>leveldb sorted table (又叫 sstable) 文件主要包含五个部分, 即多个 data blocks, 多个 meta blocks, 一个 metaindex block, 一个 index block 以及一个 footer, 具体格式如下: </p>
<pre><code>&lt;beginning_of_file&gt;
[data block 1]
[data block 2]
...
[data block N]
[meta block 1]
...
[meta block K]
[metaindex block]
[index block]
[Footer]        (fixed size; starts at file_size - sizeof(Footer))
&lt;end_of_file&gt;</code></pre>
<p>不像 kafka 存储结构数据文件和索引文件是各自独立的(在查询时索引文件用了根据具体 key 定位是哪个数据文件), 该文件把索引和数据保存到了一个文件中. 每次从文件查询数据时会先查询索引, 索引是指向数据的指针, 具体叫做 BlockHandle, 包含着下述信息: </p>
<pre><code>// 对应 block 起始位置在文件中的偏移量
offset: varint64
// 对应 block 的大小
size:   varint64</code></pre>
<p>如果你没用过 protobuf 之类的二进制编解码协议, 可能对 varint64 不太熟悉, 可以参考这里 <a target="_blank" rel="noopener" href="https://developers.google.com/protocol-buffers/docs/encoding#varints">varints</a> 了解一下. 本质就是对数据类型进行(二次)无损编码, 使其更加紧凑, 可以节省带宽或者存储空间.</p>
<p>下面详细解释下上面提到的文件格式: </p>
<ol>
<li><p>文件里存的是一系列 key/value 对, 而且按照 key 排过序了, 同时被划分到了多个 blocks 中. 这些 blocks 从文件起始位置开始一个接一个. 每个 data block 组织形式在 <code>block_builder.cc</code> 定义, 用户可以选择对 data block 进行压缩(注意前面讲 log 文件的时候说不支持对 block 进行压缩是 log 文件目前的缺点). </p>
</li>
<li><p>全部 data blocks 之后是一组 meta blocks. 已经支持的 meta block 类型见下面描述, 将来可能会加入更多的类型. 每个 meta block 组织形式在 <code>block_builder.cc</code> 定义, 同样地, 用户可以选择对其进行压缩. </p>
</li>
<li><p>全部 meta blocks 后是一个 metaindex block. 每个 meta block 都有一个对应的 entry 保存在该部分, 其中 key 就是某个 meta block 的名字, value 是一个指向该 meta block 的 BlockHandle. </p>
</li>
<li><p>紧随 metaindex block 之后是一个 index block. 针对每个 data block 都有一个对应的 entry 包含在该部分, 其中 key 为大于等于对应 data block 最后(也是最大的, 因为排序过了)一个 key 同时小于接下来的 data block 第一个 key 的字符串; value 是指向一个对应 data block 的 BlockHandle. </p>
</li>
<li><p>在每个文件的末尾是一个固定长度的 footer, 它非常关键, 它虽然位于文件尾部却是文件的入口. 固定长度的好处就是读取文件时, 用 file size 减去这个固定长度就能定位到 footer 起始偏移, 然后就可以解析了. 它包含了一个指向 metaindex block 的 BlockHandle 和一个指向 index block 的 BlockHandle 以及一个 magic number. 具体格式如下:</p>
<pre><code>   // 指向 metaindex 的 BlockHandle
   metaindex_handle: char[p];     
   // 指向 index 的 BlockHandle
   index_handle:     char[q];     
   // 用于维持固定长度的 padding 0,
   // (其中 40 == 2*BlockHandle::kMaxEncodedLength)
   padding:          char[40-p-q];
   // 具体内容为 0xdb4775248b80fb57 (小端字节序)
   magic:            fixed64;     </code></pre>
</li>
</ol>
<p>注意 footer 存的都是 index-of-xx, 找到 index 就可以找到 xx 了.</p>
<h4><span id="filter-meta-block">“filter” Meta Block</span></h4><p>目前 sstable 只有一种类型的 meta block, 那就是 filter.</p>
<p>如果打开(创建)数据库的时候指定了一个 <code>FilterPolicy</code>, 那么一个 filter block 就会被存储到每个 sstable 中. metaindex block 包含了一个 entry, 它是从 <code>filter.&lt;Name&gt;</code> 到 filter block 的 BlockHandle 的映射. 其中, <code>&lt;Name&gt;</code> 是一个由 filter policy 的 <code>Name()</code>方法返回的字符串. </p>
<p>filter block 保存着一系列 filters, 其中 filter i 包含了方法</p>
<pre><code class="c++">void leveldb::FilterPolicy::CreateFilter(const Slice *keys, int n, string *dst) const</code></pre>
<p>针对入参 keys 的计算结果(存储在输出型参数 <code>dst</code>). 参数 keys 属于一个 data block, 该 data block 对应的文件偏移量落在下面的范围里: </p>
<pre><code>[ i*base ... (i+1)*base-1 ]</code></pre>
<p>当前, 上面的 base 是 2KB. 举个例子, 如果 block X 和 block Y 起始地址落在 <code>[ 0KB .. 2KB ]</code> 范围内, 则 X 和 Y 中的全部 keys 将会在调用 <code>FilterPolicy::CreateFilter()</code> 时被转换为一个 filter, 然后这个 filter 会作为第一个(为啥是第一个, 因为 X、Y 起始地址落在第一个地址空间 <code>[ 0KB .. 2KB ]</code> 里) filter 被保存在 filter block 中. (用大白话再说一遍, 每个 FilterPolicy 都有一个唯一的名字, 在 metaindex block 通过这个名字就能找到对应的 filter block 了. 而 filter block 存的就是用这个 FilterPolicy 构造的一系列 filters, 为啥是一系列呢？因为 data blocks 太多了, 所以分了区间, 每几个 data blocks 对应一个 filter, 具体几个根据上面那个带 base 的公式来算. 再说说 filter 是怎么回事. data block 保存的不是键值对构成的 records 嘛, 根据前面说的键区间限制, 把每几个 blocks 的全部键根据某个 FilterPolicy 算一下就得到了一个 filter, 然后把这个 filter 保存到了 filter block 的第 i 个位置. )</p>
<p>具有 N 个 filter 的 filter block 格式如下: </p>
<pre><code>[filter 0]
[filter 1]
[filter 2]
...
[filter N-1]
// 下面的 [offset of filter X] 布局其实不太准确, 准确地
// 说, 除了 [offset of filter 0], 其它的都可能多出现一次.
// 具体原因见 leveldb::FilterBlockBuilder::GenerateFilter() 的疑问.
[offset of filter 0]                  : 4 bytes
[offset of filter 1]                  : 4 bytes
[offset of filter 2]                  : 4 bytes
...
[offset of filter N-1]                : 4 bytes
// 上面 [offset of filter 0] 相对于 filter block 首地址的相对偏移量, 
// 基于该值可以将 fiter 部分和 filter offset 部分分辨出来.
[offset of beginning of offset array] : 4 bytes
// base 以 2 为底的对数, 目前 base 是 2048, 则这里就是 11
lg(base)                              : 1 byte</code></pre>
<p>其中, 位于 filter block 尾部的 offset 数组可以使得我们快速定位到某个 filter. </p>
<p>由 <code>leveldb::Slice leveldb::FilterBlockBuilder::Finish()</code> 负责构造上述格式, 然后由 <code>leveldb::FilterBlockReader::FilterBlockReader()</code> 构造方法负责解析上述格式.</p>
<h4><span id="stats-meta-block">“stats” Meta Block</span></h4><p>下面的 meta block 保存着一组统计信息. key 是统计量的名称, value 是具体的统计值. </p>
<pre><code>data size
index size
key size (uncompressed)
value size (uncompressed)
number of entries
number of data blocks</code></pre>
<p>遗憾的是, 目前这个还没实现, 🤭.</p>
<h4><span id="sorted-table-文件主要接口">sorted table 文件主要接口</span></h4><p>下面说明一下 sorted table 文件主要的操作接口, 主要是读与写.</p>
<h5><span id="sorted-table-文件读接口">sorted table 文件读接口</span></h5><p>完成该工作的是 <code>class leveldb::Table</code>, 该类是对 sorted table 文件的抽象, 负责对 sorted table 文件进行读操作.</p>
<p>具体底层存储由 helper 类 <code>struct leveldb::Table::Rep</code> 负责.</p>
<p>打开一个 sstable 文件的入口为 <code>leveldb::Status leveldb::Table::Open</code>, 该方法依次动作为:</p>
<ul>
<li>1 读取文件末尾固定长度的 footer (具体长度为两个 BlockHandle 最大长度 + 固定的 8 字节魔数)</li>
<li>2 解析 footer 从而得到 index block 偏移量和大小以及 meta block 偏移量和大小.</li>
<li>3 将解析出来的 index block 放到 Table 对象中, 通过输出型参数返回.</li>
</ul>
<p>从外部(这里强调外部, 是因为还有一个私有方法 <code>leveldb::Status leveldb::Table::InternalGet</code> 可以访问 Table 对象内容)打开文件后如果要访问其内容, 需要一个迭代器, 该工作通过 <code>leveldb::Iterator *leveldb::Table::NewIterator</code> 完成. 返回的迭代器为一个 <code>leveldb::&lt;unnamed&gt;::TwoLevelIterator</code>, 该迭代器处于匿名的命名空间所以未直接对外暴露, 仅能通过返回的指针访问其从 <code>class leveldb::Iterator</code> 继承的方法. 该迭代器设计精巧, 会单独写文章介绍.</p>
<h5><span id="sorted-table-文件写接口">sorted table 文件写接口</span></h5><p>完成该工作的是 <code>class leveldb::TableBuilder</code>, 该类负责构造 sstable 文件构造.</p>
<p>主要方法有以下两个:</p>
<ul>
<li><code>void BlockBuilder::Add(const Slice&amp; key, const Slice&amp; value)</code> 负责向 TableBuilder 对象添加 (key, value), 该工作主要由 <code>class leveldb::BlockBuilder::Add()</code> 方法完成.</li>
<li><code>void leveldb::TableBuilder::Finish()</code> 负责将整个 Table 序列化为一个 sstable 文件并写入磁盘, 具体写入顺序为:<ul>
<li>写 data blocks</li>
<li>写 meta blocks(目前仅有过滤器)</li>
<li>写 meta-index block</li>
<li>写 data-index block</li>
<li>写 footer</li>
</ul>
</li>
</ul>
<h3><span id="manifest-文件">MANIFEST 文件</span></h3><p>MANIFEST 文件可以看作 leveldb 存储元数据的地方. 它列出了每一个 level 及其包含的全部 sorted table 文件, 每个 sorted table 文件对应的键区间, 以及其它重要的元数据. 每当重新打开数据库的时候, 就会创建一个新的 MANIFEST 文件(文件名中嵌有一个新生成的数字). MANIFEST 文件被格式化成形同 log 文件的格式, 针对它所服务的数据的变更都会被追加到该文件后面. 比如每当某个 level 发生文件新增或者删除操作时, 就会有一条日志被追加到 MANIFEST 中. </p>
<p>MANIFEST 文件在实现时又叫 descriptor 文件, 文件格式同 log 文件, 所以写入/读取方法就复用了. 其每条日志就是一个序列化后的 <code>leveldb::VersionEdit</code>. 每次针对 level 架构有文件增删时都要写日志到 manifest 文件.</p>
<h4><span id="与-manifest-相关的数据结构之-versionset">与 MANIFEST 相关的数据结构之 VersionSet</span></h4><p>每个 db 都有一个 <code>class leveldb::VersionSet</code> 实例, 它保存了 db 当前的 level 架构视图(具体存储结构为其 Version 成员). MANIFEST 文件可以看作是它所维护的信息的反映. 它的重要方法有:</p>
<ul>
<li><code>VersionSet::Recover</code> 负责在打开数据库时将 MANIFEST 文件反序列化构造 level 架构视图, 这个过程会依赖 VersionEdit 类.</li>
<li><code>VersionSet::LogAndApply</code> 负责将当前 VersionEdit 和当前 Version 进行合并, 然后序列化为一条日志记录到 MANIFEST 文件. 最后把新的 version 替换当前 version.</li>
</ul>
<h4><span id="与-manifest-相关的-version-结构">与 MANIFEST 相关的 Version 结构</span></h4><p><code>class leveldb::Version</code> 是 leveldb 数据库 level 架构的内存表示, 它存储了每一个 level 及其全部的文件信息(文件名, 键范围等等). 每次调用 db 的 Get 方法在 memtable 找不到目标 key 时就会到各个 level 的文件去搜寻, 这个搜寻过程所依赖的就是数据库 VersionSet(下面介绍) 保存的当前 Version 存储的 level 架构信息进行的, 具体实现见 <code>leveldb::Version::Get</code> 方法.</p>
<p>当条件满足时, VersionSet 会将当前 Version 和当前 VesionEdit 合并生成一个新的 Version 替换当前 Version.</p>
<h4><span id="与-manifest-相关的-versionedit">与 MANIFEST 相关的 VersionEdit</span></h4><p>MANIFEST 文件的每一条日志就是一个序列化的 <code>class leveldb::VersionEdit</code>. 它可以看作一个 on-fly 的 Version. 它会记录 db 运行过程中删除的文件列表和新增的文件列表.</p>
<h3><span id="current-文件">CURRENT 文件</span></h3><p>CURRENT 文件是一个简单的文本文件. 由于每次重新打开数据库都会生成一个 MANIFEST 文件, 所以需要一个地方记录最新的 MANIFEST 文件是哪个, CURRENT 就干这个事情, 它相当于一个指针, 其内容即是当前最新的 MANIFEST 文件的名称. </p>
<h3><span id="文件位置与命名">文件位置与命名</span></h3><p>各类型文件位置与命名如下:</p>
<pre><code>dbname/CURRENT
dbname/LOCK
dbname/LOG
dbname/LOG.old
dbname/MANIFEST-[0-9]+
dbname/[0-9]+.(log|sst|ldb)</code></pre>
<p>其中 dbname 为用户指定.</p>
<p>–End–</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://chienlungcheung.github.io/2020/09/11/leveldb-annotations-0-usage-and-examples/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chienlung Cheung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="programatrix">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/09/11/leveldb-annotations-0-usage-and-examples/" class="post-title-link" itemprop="url">Leveldb 源码详解系列之零: 基本介绍与使用举例</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-09-11 21:13:08" itemprop="dateCreated datePublished" datetime="2020-09-11T21:13:08+00:00">2020-09-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-03 09:19:19" itemprop="dateModified" datetime="2021-03-03T09:19:19+00:00">2021-03-03</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/09/11/leveldb-annotations-0-usage-and-examples/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/09/11/leveldb-annotations-0-usage-and-examples/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <!-- toc -->

<ul>
<li><a href="#%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D">基本介绍</a><ul>
<li><a href="#%E7%89%B9%E6%80%A7">特性</a></li>
<li><a href="#%E5%B1%80%E9%99%90%E6%80%A7">局限性</a></li>
<li><a href="#%E6%80%A7%E8%83%BD">性能</a><ul>
<li><a href="#%E6%B5%8B%E8%AF%95%E9%85%8D%E7%BD%AE">测试配置</a></li>
<li><a href="#%E5%86%99%E6%80%A7%E8%83%BD">写性能</a></li>
<li><a href="#%E8%AF%BB%E6%80%A7%E8%83%BD">读性能</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E4%BD%BF%E7%94%A8%E4%B8%BE%E4%BE%8B">使用举例</a><ul>
<li><a href="#%E6%9E%84%E5%BB%BA">构建</a></li>
<li><a href="#%E5%A4%B4%E6%96%87%E4%BB%B6%E4%BB%8B%E7%BB%8D">头文件介绍</a></li>
<li><a href="#%E6%89%93%E5%BC%80%E6%88%96%E6%96%B0%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%BA%93">打开(或新建)一个数据库</a></li>
<li><a href="#status-%E7%B1%BB%E5%9E%8B">Status 类型</a></li>
<li><a href="#%E5%85%B3%E9%97%AD%E6%95%B0%E6%8D%AE%E5%BA%93">关闭数据库</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E5%86%99">数据库读写</a></li>
<li><a href="#%E5%8E%9F%E5%AD%90%E6%9B%B4%E6%96%B0">原子更新</a></li>
<li><a href="#%E5%90%8C%E6%AD%A5%E5%86%99%E6%93%8D%E4%BD%9C">同步写操作</a></li>
<li><a href="#%E5%B9%B6%E5%8F%91">并发</a></li>
<li><a href="#%E8%BF%AD%E4%BB%A3%E6%95%B0%E6%8D%AE%E5%BA%93">迭代数据库</a></li>
<li><a href="#%E5%BF%AB%E7%85%A7">快照</a></li>
<li><a href="#slice-%E5%88%87%E7%89%87">Slice 切片</a></li>
<li><a href="#%E6%AF%94%E8%BE%83%E5%99%A8">比较器</a><ul>
<li><a href="#%E5%90%8E%E5%90%91%E5%85%BC%E5%AE%B9%E6%80%A7">后向兼容性</a></li>
</ul>
</li>
<li><a href="#%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98">性能调优</a><ul>
<li><a href="#block-%E5%A4%A7%E5%B0%8F">Block 大小</a></li>
<li><a href="#%E5%8E%8B%E7%BC%A9">压缩</a></li>
<li><a href="#%E7%BC%93%E5%AD%98">缓存</a></li>
<li><a href="#key-%E7%9A%84%E5%B8%83%E5%B1%80%E8%AE%BE%E8%AE%A1">Key 的布局设计</a></li>
<li><a href="#%E8%BF%87%E6%BB%A4%E5%99%A8">过滤器</a></li>
</ul>
</li>
<li><a href="#%E6%A0%A1%E9%AA%8C%E5%92%8C">校验和</a></li>
<li><a href="#%E8%BF%91%E4%BC%BC%E7%A9%BA%E9%97%B4%E5%A4%A7%E5%B0%8F">近似空间大小</a></li>
<li><a href="#%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">环境变量</a></li>
<li><a href="#%E7%A7%BB%E6%A4%8D%E6%80%A7">移植性</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->

<p><strong>Leveldb</strong> 是一个高速 KV 数据库, 它提供了一个持久性的 KV 存储. 其中 keys 和 values 都是随机字节数组, 并且存储时根据用户指定的比较函数对 keys 进行排序. </p>
<p>它由 Google 开发的, 其作者为大名鼎鼎的 Sanjay Ghemawat (<a href="mailto:&#x73;&#x61;&#x6e;&#x6a;&#x61;&#121;&#x40;&#103;&#111;&#111;&#103;&#x6c;&#101;&#46;&#99;&#111;&#109;">&#x73;&#x61;&#x6e;&#x6a;&#x61;&#121;&#x40;&#103;&#111;&#111;&#103;&#x6c;&#101;&#46;&#99;&#111;&#109;</a>) 和 Jeff Dean (<a href="mailto:&#106;&#101;&#x66;&#102;&#x40;&#103;&#x6f;&#x6f;&#x67;&#x6c;&#x65;&#46;&#x63;&#x6f;&#109;">&#106;&#101;&#x66;&#102;&#x40;&#103;&#x6f;&#x6f;&#x67;&#x6c;&#x65;&#46;&#x63;&#x6f;&#109;</a>). 感谢他们对人类的贡献.</p>
<h1><span id="基本介绍">基本介绍</span></h1><p>该部分主要介绍 leveldb 的功能, 局限性以及性能等.</p>
<h2><span id="特性">特性</span></h2><ul>
<li>keys 和 values 都可以是随机的字节数组. </li>
<li>数据被按照 key 的顺序进行存储. </li>
<li>调用者可以提供一个定制的比较函数来覆盖默认的比较器. </li>
<li>基础操作有 <code>Put(key,value)</code>, <code>Get(key)</code>, <code>Delete(key)</code>. </li>
<li>多个更改可以在一个原子批处理中一起生效. </li>
<li>用户可以创建一个瞬时快照来获取数据的一致性视图. </li>
<li>支持针对数据的前向和后向遍历. </li>
<li>数据通过 <a target="_blank" rel="noopener" href="http://google.github.io/snappy/">Snappy</a> 压缩程序库自动压缩. </li>
<li>与外部交互的操作都被抽象成了接口(如文件系统操作等), 所以用户可以根据接口定制自己期望的操作系统交互行为. </li>
</ul>
<h2><span id="局限性">局限性</span></h2><ul>
<li>LevelDB 不是 SQL 数据库. 它没有关系数据模型, 不支持 SQL 查询, 也不支持索引. </li>
<li>同时只能有一个进程(可能是具有多线程的进程)访问一个特定的数据库. </li>
<li>该程序库没有内置基于网络的 CS 架构, 有需求的用户可以自己封装. </li>
</ul>
<h2><span id="性能">性能</span></h2><p>下面是通过运行 db_bench 程序得出的性能测试报告. </p>
<h3><span id="测试配置">测试配置</span></h3><p>我们使用的是一个包含一百万数据项的数据库,<br>其中 key 是 16 字节, value 是 100 字节, value 压缩后大约是原来的一半, 测试配置如下:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">LevelDB:    version 1.1</span><br><span class="line">Date:       Sun May  1 12:11:26 2011</span><br><span class="line">CPU:        4 x Intel(R) Core(TM)2 Quad CPU    Q6600  @ 2.40GHz</span><br><span class="line">CPUCache:   4096 KB</span><br><span class="line">Keys:       16 bytes each</span><br><span class="line">Values:     100 bytes each (50 bytes after compression)</span><br><span class="line">Entries:    1000000</span><br><span class="line">Raw Size:   110.6 MB (estimated)</span><br><span class="line">File Size:  62.9 MB (estimated)</span><br></pre></td></tr></table></figure>

<h3><span id="写性能">写性能</span></h3><p>“fill” 基准测试创建了一个全新的数据库, 以顺序(下面 “seq” 结尾者)或者随机(下面 “random” 结尾者)方式写入. “fillsync” 基准测试每次写操作都将数据从操作系统刷到磁盘; 其它的操作会将数据保存在系统中一段时间. “overwrite” 基准测试做随机写, 这些操作会更新数据库中已有的键. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fillseq      :       1.765 micros/op;   62.7 MB/s</span><br><span class="line">fillsync     :     268.409 micros/op;    0.4 MB/s (10000 ops)</span><br><span class="line">fillrandom   :       2.460 micros/op;   45.0 MB/s</span><br><span class="line">overwrite    :       2.380 micros/op;   46.5 MB/s</span><br></pre></td></tr></table></figure>
<p>上述每个 “op” 对应一个 key/value 对的写操作. 也就是说, 一个随机写基准测试每秒大约进行四十万次写操作(1,000,000/2.46). </p>
<p>每个 “fillsync” 操作时间消耗(大约 0.3 毫秒)少于一次磁盘寻道(大约 10 毫秒). 我们怀疑这是因为磁盘本身将更新操作缓存到了内存, 并且在数据真正落盘前返回响应. 该方式是否安全取决于断电后磁盘是否有备用电力将数据落盘. </p>
<h3><span id="读性能">读性能</span></h3><p>我们分别给出正向顺序读、反向顺序读的性能以及随机查询的性能指标. 注意, 基准测试创建的数据库很小. 因此该性能报告描述的是 leveldb 的全部数据集能放入到内存的场景. 如果数据不在操作系统缓存中, 读取一点数据的性能消耗主要在于一到两次的磁盘寻道. 写性能基本不会受数据集是否能放入内存的影响. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">readrandom  : 16.677 micros/op;  (approximately 60,000 reads per second)</span><br><span class="line">readseq     :  0.476 micros/op;  232.3 MB/s</span><br><span class="line">readreverse :  0.724 micros/op;  152.9 MB/s</span><br></pre></td></tr></table></figure>
<p>LevelDB 会在后台压实底层的数据来改善读性能. 上面列出的结果是在经过一系列随机写操作后得出的. 如果经过压实(通常是自动触发), 那么上述指标会更好. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">readrandom  : 11.602 micros/op;  (approximately 85,000 reads per second)</span><br><span class="line">readseq     :  0.423 micros/op;  261.8 MB/s</span><br><span class="line">readreverse :  0.663 micros/op;  166.9 MB/s</span><br></pre></td></tr></table></figure>

<p>读操作消耗高的地方有一些来自重复解压从磁盘读取的数据块. 如果我们能提供足够的缓存给 leveldb 来将解压后的数据保存在内存中, 读性能会进一步改善: </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">readrandom  : 9.775 micros/op;  (approximately 100,000 reads per second before compaction)</span><br><span class="line">readrandom  : 5.215 micros/op;  (approximately 190,000 reads per second after compaction) </span><br></pre></td></tr></table></figure>

<h1><span id="使用举例">使用举例</span></h1><p>下面从构建和头文件介绍开始, 对 leveldb 的基本使用进行介绍.</p>
<h2><span id="构建">构建</span></h2><p>该工程开箱支持 CMake. </p>
<p>所以构建起来超简单: </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p build &amp;&amp; <span class="built_in">cd</span> build</span><br><span class="line">$ cmake -DCMAKE_BUILD_TYPE=Release .. &amp;&amp; cmake --build .</span><br><span class="line">$ sudo make install</span><br></pre></td></tr></table></figure>

<p>更多高级用法请请参照 CMake 文档和本项目的 CMakeLists.txt. </p>
<h2><span id="头文件介绍">头文件介绍</span></h2><p>LevelDB 对外的接口都包含在 include/*.h 中. 除了该目录下的文件, 用户不应该依赖其它目录下任何文件. </p>
<ul>
<li><p><strong>include/db.h</strong>: 主要的接口在这, 使用 leveldb 从这里开始. </p>
</li>
<li><p><strong>include/options.h</strong>: 使用 leveldb 过程各种操作包括读写有关的控制参数. </p>
</li>
<li><p><strong>include/comparator.h</strong>: 比较函数的抽象, 如果你想用逐字节比较 key 那么可以直接使用默认的比较器. 如果你想定制排序逻辑(如处理不同的字符编解码等)可以定制自己的比较函数. </p>
</li>
<li><p><strong>include/iterator.h</strong>: 迭代数据的接口. 你可以从一个 DB 对象获取到一个迭代器. </p>
</li>
<li><p><strong>include/write_batch.h</strong>: 原子地应用多个更新到一个数据库. </p>
</li>
<li><p><strong>include/slice.h</strong>: 类似 string, 维护着指向字节数组的一个指针和相应长度. </p>
</li>
<li><p><strong>include/status.h</strong>: 许多公共接口都会返回 <code>Status</code>, 用于指示成功或其它各种错误. </p>
</li>
<li><p><strong>include/env.h</strong>: 操作系统环境的抽象. 在 <code>util/env_posix.cc</code> 中有一个该接口的 posix 实现. </p>
</li>
<li><p><strong>include/table.h, include/table_builder.h</strong>: 底层的模块, 大多数客户端可能不会直接用到. </p>
</li>
</ul>
<h2><span id="打开或新建一个数据库">打开(或新建)一个数据库</span></h2><p>leveldb 数据库都有一个名字, 该名字对应了文件系统上一个目录, 而且该数据库内容全都存在该目录下. 下面的例子显示了如何打开一个数据库以及在必要情况下创建之. </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cassert&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;leveldb/db.h&quot;</span></span></span><br><span class="line"></span><br><span class="line">leveldb::DB* db;</span><br><span class="line">leveldb::Options options;</span><br><span class="line">options.create_if_missing = <span class="literal">true</span>;</span><br><span class="line">leveldb::Status status = leveldb::DB::Open(options, <span class="string">&quot;/tmp/testdb&quot;</span>, &amp;db);</span><br><span class="line">assert(status.ok());</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>如果你想在数据库已存在的时候触发一个异常, 将下面这行加到 <code>leveldb::DB::Open</code> 调用之前: </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">options.error_if_exists = <span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

<h2><span id="status-类型">Status 类型</span></h2><p>你可能注意到上面的 <code>leveldb::Status</code> 类型了. leveldb 中大部分方法在遇到错误的时候会返回该类型的值. 你可以检查它是否为 ok, 然后打印关联的错误信息即可: </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">leveldb::Status s = ...;</span><br><span class="line"><span class="keyword">if</span> (!s.ok()) <span class="built_in">cerr</span> &lt;&lt; s.ToString() &lt;&lt; <span class="built_in">endl</span>;</span><br></pre></td></tr></table></figure>

<h2><span id="关闭数据库">关闭数据库</span></h2><p>当数据库不再使用的时候, 像下面这样直接删除数据库对象就可以了: </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">... open the db as described above ...</span><br><span class="line">... <span class="keyword">do</span> something with db ...</span><br><span class="line"><span class="keyword">delete</span> db;</span><br></pre></td></tr></table></figure>

<p>非常简单是不是? 因为 <code>DB</code> 类的实现是基于 RAII 的, 在 delete 时触发析构方法自动进行清理工作.</p>
<h2><span id="数据库读写">数据库读写</span></h2><p>数据库提供了 <code>Put</code>、<code>Delete</code> 以及 <code>Get</code> 方法来修改、查询数据库. 下面的代码展示了将 key1 对应的 value 移动(先拷贝后删除)到 key2 下. </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">string</span> value;</span><br><span class="line">leveldb::Status s = db-&gt;Get(leveldb::ReadOptions(), key1, &amp;value);</span><br><span class="line"><span class="keyword">if</span> (s.ok()) s = db-&gt;Put(leveldb::WriteOptions(), key2, value);</span><br><span class="line"><span class="keyword">if</span> (s.ok()) s = db-&gt;Delete(leveldb::WriteOptions(), key1);</span><br></pre></td></tr></table></figure>

<h2><span id="原子更新">原子更新</span></h2><p>注意, 上一小节中如果进程在 Put 了 key2 之后但是删除 key1 之前挂了, 那么同样的 value 就出现在了多个 keys 之下. 该问题可以通过使用 <code>WriteBatch</code> 类原子地应用一组操作来避免. </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;leveldb/write_batch.h&quot;</span></span></span><br><span class="line">...</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">string</span> value;</span><br><span class="line">leveldb::Status s = db-&gt;Get(leveldb::ReadOptions(), key1, &amp;value);</span><br><span class="line"><span class="keyword">if</span> (s.ok()) &#123;</span><br><span class="line">  leveldb::WriteBatch batch;</span><br><span class="line">  batch.Delete(key1);</span><br><span class="line">  batch.Put(key2, value);</span><br><span class="line">  s = db-&gt;Write(leveldb::WriteOptions(), &amp;batch);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>WriteBatch</code> 保存着一系列将被应用到数据库的编辑操作, 这些操作会按照添加的顺序依次被执行. 注意, 我们先执行 Delete 后执行 Put, 这样如果 key1 和 key2 一样的情况下我们也不会错误地丢失数据. </p>
<p>除了原子性, <code>WriteBatch</code> 也能加速更新过程, 因为可以把一大批独立的操作添加到同一个 batch 中然后一次性执行. </p>
<h2><span id="同步写操作">同步写操作</span></h2><p>默认地, leveldb 每个写操作都是异步的: 进程把要写的内容 push 给操作系统后立马返回. 从操作系统内存到底层持久性存储的迁移异步地发生. 当然, 也可以把某个写操作的 sync 标识打开, 以等到数据真正被记录到持久化存储再让写操作返回. (在 Posix 系统上, 这是通过在写操作返回前调用 <code>fsync(...)</code> 或 <code>fdatasync(...)</code> 或 <code>msync(..., MS_SYNC)</code> 来实现的. )</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">leveldb::WriteOptions write_options;</span><br><span class="line">write_options.sync = <span class="literal">true</span>;</span><br><span class="line">db-&gt;Put(write_options, ...);</span><br></pre></td></tr></table></figure>

<p>异步写通常比同步写快 1000 倍. 异步写的缺点是, 一旦机器崩溃可能会导致最后几个更新操作丢失. 注意, 仅仅是写进程崩溃(而非机器重启)则不会引起任何更新操作丢失, 因为哪怕 sync 标识为 false, 在进程退出之前写操作也已经从进程内存 push 到了操作系统. </p>
<p>异步写总是可以安全使用. 比如你要将大量的数据写入数据库, 如果丢失了最后几个更新操作, 你可以重启整个写过程. 如果数据量非常大, 一个优化点是, 每进行 N 个异步写操作则进行一次同步地写操作, 如果期间发生了崩溃, 重启自从上一个成功的同步写操作以来的更新操作即可. (同步的写操作可以同时更新一个标识, 该标识用于描述崩溃重启后从何处开始重启更新操作. )</p>
<p><code>WriteBatch</code> 可以作为异步写操作的替代品. 多个更新操作可以放到同一个 WriteBatch 中然后通过一次同步写(即 <code>write_options.sync</code> 置为 true)一起应用. </p>
<h2><span id="并发">并发</span></h2><p>一个数据库同时只能被一个进程打开. LevelDB 会从操作系统获取一把锁来防止多进程同时打开同一个数据库. 在单个进程中, 同一个 <code>leveldb::DB</code> 对象可以被多个并发的线程安全地使用, 也就是说, 不同的线程可以写入或者获取迭代器, 或者针对同一个数据库调用 <code>Get</code>, 前述全部操作均不需要借助外部同步设施(leveldb 实现会自动地确保必要的同步). 但是其它对象, 比如 <code>Iterator</code> 或者 <code>WriteBatch</code> 需要外部自己提供同步保证. 如果两个线程共享此类对象, 需要使用锁进行互斥访问. 具体见对应的头文件. </p>
<h2><span id="迭代数据库">迭代数据库</span></h2><p>下面的用例展示了如何打印数据库中全部的 (key, value) 对. </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">leveldb::Iterator* it = db-&gt;NewIterator(leveldb::ReadOptions());</span><br><span class="line"><span class="keyword">for</span> (it-&gt;SeekToFirst(); it-&gt;Valid(); it-&gt;Next()) &#123;</span><br><span class="line">  <span class="built_in">cout</span> &lt;&lt; it-&gt;key().ToString() &lt;&lt; <span class="string">&quot;: &quot;</span>  &lt;&lt; it-&gt;value().ToString() &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line">assert(it-&gt;status().ok());  <span class="comment">// Check for any errors found during the scan</span></span><br><span class="line"><span class="keyword">delete</span> it;</span><br></pre></td></tr></table></figure>

<p>下面的用例展示了如何打印 <code>[start, limit)</code> 范围内数据:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (it-&gt;Seek(start);</span><br><span class="line">   it-&gt;Valid() &amp;&amp; it-&gt;key().ToString() &lt; limit;</span><br><span class="line">   it-&gt;Next()) &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当然你也可以反向遍历(注意, 反向遍历可能比正向遍历要慢一些, 具体见前面的读性能基准测试). </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (it-&gt;SeekToLast(); it-&gt;Valid(); it-&gt;Prev()) &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2><span id="快照">快照</span></h2><p>快照提供了针对整个 KV 存储的一致性只读视图. <code>ReadOptions::snapshot</code> 不为空表示读操作应该作用在 DB 的某个特定版本上; 若为空, 则读操作将会作用在当前版本的一个隐式的快照上.  </p>
<p>快照通过调用 <code>DB::GetSnapshot()</code> 方法创建:  </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">leveldb::ReadOptions options;</span><br><span class="line">options.snapshot = db-&gt;GetSnapshot();</span><br><span class="line">... apply some updates to db ...</span><br><span class="line"><span class="comment">// 获取与前面快照对应的数据库迭代器</span></span><br><span class="line">leveldb::Iterator* iter = db-&gt;NewIterator(options);</span><br><span class="line">... read <span class="keyword">using</span> iter to view the state when the snapshot was created ...</span><br><span class="line"><span class="keyword">delete</span> iter;</span><br><span class="line">db-&gt;ReleaseSnapshot(options.snapshot);</span><br></pre></td></tr></table></figure>

<p>注意, 当一个快照不再使用的时候, 应该通过 <code>DB::ReleaseSnapshot</code> 接口进行释放. </p>
<h2><span id="slice-切片">Slice 切片</span></h2><p><code>it-&gt;key()</code> 和 <code>it-&gt;value()</code> 调用返回的值是 <code>leveldb::Slice</code> 类型的实例. 熟悉 Golang 或者 Rust 的同学对 slice 应该不陌生. slice 是一个简单的数据结构, 包含一个长度和一个指向外部字节数组的指针. 返回一个切片比返回 <code>std::string</code> 更加高效, 因为不需要隐式地拷贝大量的 keys 和 values. 另外, leveldb 方法不返回空字符结尾的 C 风格地字符串, 因为 leveldb 的 keys 和 values 允许包含 <code>\0</code> 字节. </p>
<p>C++ 风格的 string 和 C 风格的空字符结尾的字符串很容易转换为一个切片: </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">leveldb::Slice s1 = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="built_in">std</span>::<span class="built_in">string</span> <span class="title">str</span><span class="params">(<span class="string">&quot;world&quot;</span>)</span></span>;</span><br><span class="line">leveldb::Slice s2 = str;</span><br></pre></td></tr></table></figure>

<p>一个切片也很容易转换回 C++ 风格的字符串: </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">string</span> str = s1.ToString();</span><br><span class="line">assert(str == <span class="built_in">std</span>::<span class="built_in">string</span>(<span class="string">&quot;hello&quot;</span>));</span><br></pre></td></tr></table></figure>

<p>注意, 当使用切片时, 调用者要确保它内部指针指向的外部字节数组保持存活. 比如, 下面的代码就有问题: </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">leveldb::Slice slice;</span><br><span class="line"><span class="keyword">if</span> (...) &#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">string</span> str = ...;</span><br><span class="line">  slice = str;</span><br><span class="line">&#125;</span><br><span class="line">Use(slice);</span><br></pre></td></tr></table></figure>

<p>当 if 语句结束的时候, str 将会被销毁, 切片的底层存储也随之消失了, 后面再用就出问题了. </p>
<h2><span id="比较器">比较器</span></h2><p>前面的例子中用的都是默认的比较函数, 即逐字节按照字典序比较. 你可以定制自己的比较函数, 然后在打开数据库的时候传入. 只需继承 <code>leveldb::Comparator</code> 然后定义相关逻辑即可, 下面是一个例子: </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoPartComparator</span> :</span> <span class="keyword">public</span> leveldb::Comparator &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// Three-way comparison function:</span></span><br><span class="line">  <span class="comment">//   if a &lt; b: negative result</span></span><br><span class="line">  <span class="comment">//   if a &gt; b: positive result</span></span><br><span class="line">  <span class="comment">//   else: zero result</span></span><br><span class="line">  <span class="function"><span class="keyword">int</span> <span class="title">Compare</span><span class="params">(<span class="keyword">const</span> leveldb::Slice&amp; a, <span class="keyword">const</span> leveldb::Slice&amp; b)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> a1, a2, b1, b2;</span><br><span class="line">    ParseKey(a, &amp;a1, &amp;a2);</span><br><span class="line">    ParseKey(b, &amp;b1, &amp;b2);</span><br><span class="line">    <span class="keyword">if</span> (a1 &lt; b1) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">if</span> (a1 &gt; b1) <span class="keyword">return</span> +<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (a2 &lt; b2) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">if</span> (a2 &gt; b2) <span class="keyword">return</span> +<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Ignore the following methods for now:</span></span><br><span class="line">  <span class="function"><span class="keyword">const</span> <span class="keyword">char</span>* <span class="title">Name</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> <span class="string">&quot;TwoPartComparator&quot;</span>; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">FindShortestSeparator</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">string</span>*, <span class="keyword">const</span> leveldb::Slice&amp;)</span> <span class="keyword">const</span> </span>&#123;&#125;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">FindShortSuccessor</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">string</span>*)</span> <span class="keyword">const</span> </span>&#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>然后使用上面定义的比较器打开数据库: </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 实例化比较器</span></span><br><span class="line">TwoPartComparator cmp;</span><br><span class="line">leveldb::DB* db;</span><br><span class="line">leveldb::Options options;</span><br><span class="line">options.create_if_missing = <span class="literal">true</span>;</span><br><span class="line"><span class="comment">// 将比较器赋值给 options.comparator</span></span><br><span class="line">options.comparator = &amp;cmp;</span><br><span class="line"><span class="comment">// 打开数据库</span></span><br><span class="line">leveldb::Status status = leveldb::DB::Open(options, <span class="string">&quot;/tmp/testdb&quot;</span>, &amp;db);</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3><span id="后向兼容性">后向兼容性</span></h3><p>比较器 <code>Name</code> 方法返回的结果在创建数据库时会被绑定到数据库上, 后续每次打开都会进行检查. 如果名称改了, 对 <code>leveldb::DB::Open</code> 的调用就会失败. 因此, 当且仅当在新的 key 格式和比较函数与已有的数据库不兼容而且已有数据不再被需要的时候再修改比较器名称. 总而言之, 一个数据库只能对应一个比较器, 而且比较器由名字唯一确定, 一旦修改名称或者比较器逻辑, 数据库的操作逻辑就统统会出错, 毕竟 leveldb 是一个有序的 KV 存储.</p>
<p>如果非要修改比较逻辑怎么办呢? 你可以根据预先规划一点一点的演进你的 key 格式, 注意, 事先的演进规划非常重要. 比如, 你可以存储一个版本号在每个 key 的结尾(大多数场景, 一个字节足够了). 当你想要切换到新的 key 格式的时候(比如新增 third-part 到上面例子 <code>TwoPartComparator</code> 处理的 keys 中), 那么你需要做的是:</p>
<ul>
<li>(a) 保持比较器名称不变</li>
<li>(b) 递增新 keys 的版本号</li>
<li>(c) 修改比较器函数以让其使用版本号来决定如何进行排序. </li>
</ul>
<h2><span id="性能调优">性能调优</span></h2><p>通过修改 <code>include/leveldb/options.h</code> 中定义的类型的默认值来对 leveldb 的性能进行调优. </p>
<h3><span id="block-大小">Block 大小</span></h3><p>Leveldb 把相邻的 keys 组织在同一个 block 中(具体见后面文章针对 sorted table 文件格式的描述), 而且 block 是 leveldb 把数据从内存到转移到持久化存储和从持久化存储转移到内存的基本单位. 默认的, 压缩前 block 大约为 4KB. 经常处理大块数据的应用可能希望把这个值调大, 而针对数据做”点读” 的应用可能希望这个值小一点, 这样性能可能会更高一些. 但是, 没有证据表明该值小于 1KB 或者大于几个 MB 的时候性能会表现更好. 同时要注意, 针对大的 block size, 压缩效率会更高一些. </p>
<h3><span id="压缩">压缩</span></h3><p>每个 block 在写入持久存储之前都会被单独压缩. 压缩默认是开启的, 因为默认的压缩算法非常快, 而且对于不可压缩的数据会自动关闭压缩功能. 极少有场景会让用户想要完全关闭压缩功能, 除非基准测试显示关闭压缩会显著改善性能. 按照下面方式做就关闭了压缩功能: </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">leveldb::Options options;</span><br><span class="line">options.compression = leveldb::kNoCompression;</span><br><span class="line">... leveldb::DB::Open(options, name, ...) ....</span><br></pre></td></tr></table></figure>

<h3><span id="缓存">缓存</span></h3><p>数据库的内容存储在文件系统的一组文件里, 每个文件保存着一系列压缩后的 blocks. 如果 <code>options.block_cache</code> 不为空, 它就会被用于缓存频繁被使用的 block 内容(已解压缩). </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;leveldb/cache.h&quot;</span></span></span><br><span class="line"></span><br><span class="line">leveldb::Options options;</span><br><span class="line"><span class="comment">// 打开数据库之前分配一个 100MB 的 LRU Cache 用于缓存解压的 blocks</span></span><br><span class="line">options.block_cache = leveldb::NewLRUCache(<span class="number">100</span> * <span class="number">1048576</span>);  <span class="comment">// 100MB cache</span></span><br><span class="line">leveldb::DB* db;</span><br><span class="line"><span class="comment">// 打开数据库</span></span><br><span class="line">leveldb::DB::Open(options, name, &amp;db);</span><br><span class="line">... use the db ...</span><br><span class="line"><span class="keyword">delete</span> db</span><br><span class="line"><span class="keyword">delete</span> options.block_cache;</span><br></pre></td></tr></table></figure>

<p>注意 cache 保存的是未压缩的数据, 因此应该根据应用程序所需的数据大小来设置它的大小. (已压缩数据的缓存工作交给操作系统的 buffer cache 或者用户提供的定制的 Env 实现去干. )</p>
<p>当执行一个大块数据读操作时, 应用程序可能想要取消缓存功能, 这样读进来的大块数据就不会导致 cache 中当前大部分数据被置换出去, 我们可以为它提供一个单独的 iterator 来达到该目的: </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">leveldb::ReadOptions options;</span><br><span class="line"><span class="comment">// 缓存设置为关闭</span></span><br><span class="line">options.fill_cache = <span class="literal">false</span>;</span><br><span class="line"><span class="comment">// 用该设置去创建一个新的迭代器</span></span><br><span class="line">leveldb::Iterator* it = db-&gt;NewIterator(options);</span><br><span class="line"><span class="comment">// 用该迭代器去处理大块数据</span></span><br><span class="line"><span class="keyword">for</span> (it-&gt;SeekToFirst(); it-&gt;Valid(); it-&gt;Next()) &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3><span id="key-的布局设计">Key 的布局设计</span></h3><p>注意, 磁盘传输的单位以及磁盘缓存的单位都是一个 block. 相邻的 keys(已排序)总是在同一个 block 中. 因此应用程序可以通过把需要一起访问的 keys 放在一起, 同时把不经常使用的 keys 放到一个独立的键空间区域来提升性能. </p>
<p>举个例子, 假设我们正基于 leveldb 实现一个简单的文件系统. 我们打算存储到这个文件系统的数据项类型如下: </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">filename -&gt; permission-bits, length, list of file_block_ids</span><br><span class="line">file_block_id -&gt; data</span><br></pre></td></tr></table></figure>

<p>我们可以给上面表示 <code>filename</code> 的 key 增加一个字符前缀, 比如 ‘/‘, 然后给表示 <code>file_block_id</code> 的 key 增加另一个不同的前缀, 比如 ‘0’, 这样这些不同用途的 key 就具有了各自独立的键空间区域, 扫描元数据的时候我们就不用读取和缓存大块文件内容数据了. </p>
<h3><span id="过滤器">过滤器</span></h3><p>鉴于 leveldb 数据在磁盘上的组织形式, 一次 <code>Get()</code> 调用可能涉及多次磁盘读操作. 可配置的 FilterPolicy 机制可以用来大幅减少磁盘读次数. </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">leveldb::Options options;</span><br><span class="line"><span class="comment">// 设置启用基于布隆过滤器的过滤策略</span></span><br><span class="line">options.filter_policy = NewBloomFilterPolicy(<span class="number">10</span>);</span><br><span class="line">leveldb::DB* db;</span><br><span class="line"><span class="comment">// 用该设置打开数据库</span></span><br><span class="line">leveldb::DB::Open(options, <span class="string">&quot;/tmp/testdb&quot;</span>, &amp;db);</span><br><span class="line">... use the database ...</span><br><span class="line"><span class="keyword">delete</span> db;</span><br><span class="line"><span class="keyword">delete</span> options.filter_policy;</span><br></pre></td></tr></table></figure>

<p>上述代码将一个基于布隆过滤器的过滤策略与数据库进行了关联. 基于布隆过滤器的过滤方式依赖于如下事实, 在内存中保存每个 key 的部分位(在上面例子中是 10 位, 因为我们传给 <code>NewBloomFilterPolicy</code> 的参数是 10). 这个过滤器将会使得 <code>Get()</code> 调用中非必须的磁盘读操作大约减少 100 倍. 每个 key 用于过滤器的位数增加将会进一步减少读磁盘次数, 当然也会占用更多内存空间. 我们推荐数据集无法全部放入内存同时又存在大量随机读的应用设置一个过滤器策略. </p>
<p>如果你在使用定制的比较器, 你应该确保你在用的过滤器策略与你的比较器兼容. 举个例子, 如果一个比较器在比较 key 的时候忽略结尾的空格, 那么<code>NewBloomFilterPolicy</code> 一定不能与此比较器共存. 相反, 应用应该提供一个定制的过滤器策略, 而且它也应该忽略键的尾部空格. 示例如下: </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomFilterPolicy</span> :</span> <span class="keyword">public</span> leveldb::FilterPolicy &#123;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  FilterPolicy* builtin_policy_;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  CustomFilterPolicy() : builtin_policy_(NewBloomFilterPolicy(<span class="number">10</span>)) &#123;&#125;</span><br><span class="line">  ~CustomFilterPolicy() &#123; <span class="keyword">delete</span> builtin_policy_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">const</span> <span class="keyword">char</span>* <span class="title">Name</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> <span class="string">&quot;IgnoreTrailingSpacesFilter&quot;</span>; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">CreateFilter</span><span class="params">(<span class="keyword">const</span> Slice* keys, <span class="keyword">int</span> n, <span class="built_in">std</span>::<span class="built_in">string</span>* dst)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Use builtin bloom filter code after removing trailing spaces</span></span><br><span class="line">    <span class="comment">// 将尾部空格移除后再使用内置的布隆过滤器</span></span><br><span class="line">    <span class="function"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Slice&gt; <span class="title">trimmed</span><span class="params">(n)</span></span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">      trimmed[i] = RemoveTrailingSpaces(keys[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> builtin_policy_-&gt;CreateFilter(&amp;trimmed[i], n, dst);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>当然也可以自己提供非基于布隆过滤器的过滤器策略, 具体见 <code>leveldb/filter_policy.h</code>. </p>
<h2><span id="校验和">校验和</span></h2><p>Leveldb 将一个校验和与它存储在文件系统中的全部数据进行关联. 根据激进程度有两种方式控制校验和的核对: </p>
<p><code>ReadOptions::verify_checksums</code> 可以设置为 true 来强制核对从文件系统读取的全部数据的进行校验和检查. 默认为 false. </p>
<p><code>Options::paranoid_checks</code> 在数据库打开之前设置为 true 可以使得数据库一旦检测到数据损毁即报错. 取决于数据库损坏部位, 报错时机可能是打开数据库后的时候, 也可能是在后续执行某个操作的时候. 该配置默认是关闭状态, 这样即使持久性存储部分虽坏数据库也能继续使用. </p>
<p>如果数据库损坏了(当开启 <code>Options::paranoid_checks</code> 的时候可能就打不开了), <code>leveldb::RepairDB</code> 函数可以用于对尽可能多的数据进行修复. </p>
<h2><span id="近似空间大小">近似空间大小</span></h2><p><code>GetApproximateSizes</code> 方法用于获取一个或多个键区间占据的文件系统近似大小(单位, 字节). </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">leveldb::Range ranges[<span class="number">2</span>];</span><br><span class="line">ranges[<span class="number">0</span>] = leveldb::Range(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;c&quot;</span>);</span><br><span class="line">ranges[<span class="number">1</span>] = leveldb::Range(<span class="string">&quot;x&quot;</span>, <span class="string">&quot;z&quot;</span>);</span><br><span class="line"><span class="keyword">uint64_t</span> sizes[<span class="number">2</span>];</span><br><span class="line">leveldb::Status s = db-&gt;GetApproximateSizes(ranges, <span class="number">2</span>, sizes);</span><br></pre></td></tr></table></figure>

<p>上述代码结果是, <code>size[0]</code> 保存 <code>[a..c)</code> 键区间对应的文件系统大致字节数, <code>size[1]</code> 保存 <code>[x..z)</code> 键区间对应的文件系统大致字节数. </p>
<h2><span id="环境变量">环境变量</span></h2><p>由 leveldb 发起的全部文件操作以及其它的操作系统调用最后都会被路由给一个 <code>leveldb::Env</code> 对象. 用户也可以提供自己的 <code>Env</code> 实现以达到更好的控制. 比如, 如果应用程序想要针对 leveldb 的文件 IO 引入一个人工延迟以限制 leveldb 对同一个系统中其它应用的影响:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定制自己的 Env </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SlowEnv</span> :</span> <span class="keyword">public</span> leveldb::Env &#123;</span><br><span class="line">  ... implementation of the Env interface ...</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">SlowEnv env;</span><br><span class="line">leveldb::Options options;</span><br><span class="line"><span class="comment">// 用定制的 Env 打开数据库</span></span><br><span class="line">options.env = &amp;env;</span><br><span class="line">Status s = leveldb::DB::Open(options, ...);</span><br></pre></td></tr></table></figure>

<h2><span id="移植性">移植性</span></h2><p>如果某个特定平台提供 <code>leveldb/port/port.h</code> 导出的类型/方法/函数实现, 那么 leveldb 可以被移植到该平台上, 更多细节见 <code>leveldb/port/port_example.h</code>. </p>
<p>另外, 新平台可能还需要一个新的默认的 <code>leveldb::Env</code> 实现. 具体可参考 <code>leveldb/util/env_posix.h</code> 实现. </p>
<p>–End–</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://chienlungcheung.github.io/2020/09/10/hello-world-again/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chienlung Cheung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="programatrix">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/09/10/hello-world-again/" class="post-title-link" itemprop="url">Hello World, Again</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-09-10 20:14:15" itemprop="dateCreated datePublished" datetime="2020-09-10T20:14:15+00:00">2020-09-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-03 09:19:19" itemprop="dateModified" datetime="2021-03-03T09:19:19+00:00">2021-03-03</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/09/10/hello-world-again/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/09/10/hello-world-again/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>之前的博客采用 OctoPress 搭建, 但是当时同步数据没有把 _post 下面的 md 原始文件同步, 导致这次迁移没法把之前几年积攒的文章搬过来.</p>
<p>Hello world, again!</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Chienlung Cheung</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chienlung Cheung</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  













<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'forest',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://Chienlung.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>

</body>
</html>
